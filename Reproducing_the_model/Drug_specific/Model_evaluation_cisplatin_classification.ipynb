{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a5a24c-9a93-4f07-9cb4-b9e0b5ca3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing as sk\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "from random import randint\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b8ac00-985e-42d9-befc-b0a08642dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_exprs.Cisplatin.eb_with.TCGA_exprs.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "GDSCE = pd.DataFrame.transpose(GDSCE)\n",
    "\n",
    "TCGAE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_exprs.Cisplatin.eb_with.GDSC_exprs.Cisplatin.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "TCGAE = pd.DataFrame.transpose(TCGAE)\n",
    "\n",
    "TCGAM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_mutations.Cisplatin.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "TCGAM = pd.DataFrame.transpose(TCGAM)\n",
    "TCGAM = TCGAM.loc[:,~TCGAM.columns.duplicated()]\n",
    "\n",
    "TCGAC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_CNA.Cisplatin.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "TCGAC = pd.DataFrame.transpose(TCGAC)\n",
    "TCGAC = TCGAC.loc[:,~TCGAC.columns.duplicated()]\n",
    "\n",
    "GDSCM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_mutations.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCM = pd.DataFrame.transpose(GDSCM)\n",
    "GDSCM = GDSCM.loc[:,~GDSCM.columns.duplicated()]\n",
    "\n",
    "GDSCC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_CNA.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCC.drop_duplicates(keep='last')\n",
    "GDSCC = pd.DataFrame.transpose(GDSCC)\n",
    "GDSCC = GDSCC.loc[:,~GDSCC.columns.duplicated()]\n",
    "\n",
    "selector = VarianceThreshold(0.05)\n",
    "selector.fit_transform(GDSCE)\n",
    "GDSCE = GDSCE[GDSCE.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "TCGAC = TCGAC.fillna(0)\n",
    "TCGAC[TCGAC != 0.0] = 1\n",
    "TCGAM = TCGAM.fillna(0)\n",
    "TCGAM[TCGAM != 0.0] = 1\n",
    "GDSCM = GDSCM.fillna(0)\n",
    "GDSCM[GDSCM != 0.0] = 1\n",
    "GDSCC = GDSCC.fillna(0)\n",
    "GDSCC[GDSCC != 0.0] = 1\n",
    "\n",
    "ls = set(GDSCE.columns.values).intersection(set(GDSCM.columns.values))\n",
    "ls = set(ls).intersection(set(GDSCC.columns.values))\n",
    "ls = set(ls).intersection(TCGAE.columns)\n",
    "ls = set(ls).intersection(TCGAM.columns)\n",
    "ls = set(ls).intersection(set(TCGAC.columns.values))\n",
    "ls2 = set(GDSCE.index.values).intersection(set(GDSCM.index.values))\n",
    "ls2 = set(ls2).intersection(set(GDSCC.index.values))\n",
    "ls3 = set(TCGAE.index.values).intersection(set(TCGAM.index.values))\n",
    "ls3 = set(ls3).intersection(set(TCGAC.index.values))\n",
    "#ls = pd.unique(ls)\n",
    "\n",
    "TCGAE = TCGAE.loc[ls3,ls]\n",
    "TCGAM = TCGAM.loc[ls3,ls]\n",
    "TCGAC = TCGAC.loc[ls3,ls]\n",
    "GDSCE = GDSCE.loc[ls2,ls]\n",
    "GDSCM = GDSCM.loc[ls2,ls]\n",
    "GDSCC = GDSCC.loc[ls2,ls]\n",
    "\n",
    "GDSCR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_response.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "TCGAR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_response.Cisplatin.tsv\", \n",
    "                       sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "\n",
    "\n",
    "GDSCR.rename(mapper = str, axis = 'index', inplace = True)\n",
    "GDSCR = GDSCR.loc[ls2,:]\n",
    "#GDSCR.loc[GDSCR.iloc[:,0] == 'R','response'] = 0\n",
    "#GDSCR.loc[GDSCR.iloc[:,0] == 'S','response'] = 1\n",
    "\n",
    "TCGAR = TCGAR.loc[ls3,:]\n",
    "#TCGAR.loc[TCGAR.iloc[:,1] == 'R','response'] = 0\n",
    "#TCGAR.loc[TCGAR.iloc[:,1] == 'S','response'] = 1\n",
    "\n",
    "d = {\"R\":0,\"S\":1}\n",
    "GDSCR[\"response\"] = GDSCR.loc[:,\"response\"].apply(lambda x: d[x])\n",
    "TCGAR[\"response\"] = TCGAR.loc[:,\"response\"].apply(lambda x: d[x])\n",
    "\n",
    "Y_train = GDSCR['response'].values\n",
    "Y_test = TCGAR['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd999995-ab87-4de1-815b-a9b35f541978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCGAR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ab724e-1539-4504-a982-4be4d65ad8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; Total loss: 0.6773\n",
      "Iter-1; Total loss: 0.6933\n",
      "Iter-2; Total loss: 0.6679\n",
      "Iter-3; Total loss: 0.6686\n",
      "Iter-4; Total loss: 0.6602\n",
      "Iter-5; Total loss: 0.6496\n",
      "Iter-6; Total loss: 0.6526\n",
      "Iter-7; Total loss: 0.6561\n",
      "Iter-8; Total loss: 0.6463\n",
      "Iter-9; Total loss: 0.6518\n",
      "Iter-10; Total loss: 0.6413\n",
      "Iter-11; Total loss: 0.6446\n",
      "Iter-12; Total loss: 0.6393\n",
      "Iter-13; Total loss: 0.6223\n",
      "Iter-14; Total loss: 0.6501\n",
      "Iter-15; Total loss: 0.6222\n",
      "Iter-16; Total loss: 0.6276\n",
      "Iter-17; Total loss: 0.6022\n",
      "Iter-18; Total loss: 0.6199\n",
      "Iter-19; Total loss: 0.6266\n",
      "Iter-20; Total loss: 0.6317\n",
      "Iter-21; Total loss: 0.6186\n",
      "Iter-22; Total loss: 0.6216\n",
      "Iter-23; Total loss: 0.6173\n",
      "Iter-24; Total loss: 0.5852\n",
      "Iter-25; Total loss: 0.6118\n",
      "Iter-26; Total loss: 0.6277\n",
      "Iter-27; Total loss: 0.5945\n",
      "Iter-28; Total loss: 0.5848\n",
      "Iter-29; Total loss: 0.6247\n",
      "Iter-30; Total loss: 0.5733\n",
      "Iter-31; Total loss: 0.5973\n",
      "Iter-32; Total loss: 0.5852\n",
      "Iter-33; Total loss: 0.5843\n",
      "Iter-34; Total loss: 0.5889\n",
      "Iter-35; Total loss: 0.5947\n",
      "Iter-36; Total loss: 0.5629\n",
      "Iter-37; Total loss: 0.5177\n",
      "Iter-38; Total loss: 0.5493\n",
      "Iter-39; Total loss: 0.613\n",
      "Iter-40; Total loss: 0.5927\n",
      "Iter-41; Total loss: 0.5257\n",
      "Iter-42; Total loss: 0.5302\n",
      "Iter-43; Total loss: 0.5596\n",
      "Iter-44; Total loss: 0.5439\n",
      "Iter-45; Total loss: 0.5466\n",
      "Iter-46; Total loss: 0.5204\n",
      "Iter-47; Total loss: 0.509\n",
      "Iter-48; Total loss: 0.5528\n",
      "Iter-49; Total loss: 0.5466\n",
      "Iter-50; Total loss: 0.4979\n",
      "Iter-51; Total loss: 0.5389\n",
      "Iter-52; Total loss: 0.5168\n",
      "Iter-53; Total loss: 0.4689\n",
      "Iter-54; Total loss: 0.5576\n",
      "Iter-55; Total loss: 0.4979\n",
      "Iter-56; Total loss: 0.5043\n",
      "Iter-57; Total loss: 0.4842\n",
      "Iter-58; Total loss: 0.4725\n",
      "Iter-59; Total loss: 0.5483\n"
     ]
    }
   ],
   "source": [
    "mbs = 60\n",
    "hdm = 256\n",
    "zdm = 256\n",
    "lre = 5e-05\n",
    "lrm = 0.0005\n",
    "lrc = 0.05\n",
    "lrCL = 0.005\n",
    "epch = 60\n",
    "wd = 0.01\n",
    "rate = 0.6\n",
    "\n",
    "\n",
    "X_trainE = GDSCE.values\n",
    "X_testE =  TCGAE.values\n",
    "X_trainM = GDSCM.values\n",
    "X_testM = TCGAM.values\n",
    "X_trainC = GDSCC.values\n",
    "X_testC = TCGAC.values\n",
    "y_trainE = Y_train\n",
    "y_testE = Y_test\n",
    "      \n",
    "# standardize the PDX data separate\n",
    "scalerGDSC = sk.StandardScaler()\n",
    "scalerGDSC.fit(X_trainE)\n",
    "X_trainE = scalerGDSC.transform(X_trainE)\n",
    "X_testE = scalerGDSC.transform(X_testE)\n",
    "# Notice that only expression data is standardized\n",
    "# This is as the mutation and the CNA data used here are binary\n",
    "\n",
    "X_trainM = np.nan_to_num(X_trainM)\n",
    "X_trainC = np.nan_to_num(X_trainC)\n",
    "X_testM = np.nan_to_num(X_testM)\n",
    "X_testC = np.nan_to_num(X_testC)\n",
    "# np.nan_to_numpy Replace NaN with zero and infinity with large finite numbers\n",
    "        \n",
    "TX_testE = torch.FloatTensor(X_testE)\n",
    "TX_testM = torch.FloatTensor(X_testM)\n",
    "TX_testC = torch.FloatTensor(X_testC)\n",
    "ty_testE = torch.FloatTensor(y_testE.astype(int))\n",
    "        \n",
    "        \n",
    "#Train\n",
    "class_sample_count = np.array([len(np.where(y_trainE==t)[0]) for t in np.unique(y_trainE)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in y_trainE])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight), replacement=True)\n",
    "\n",
    "mb_size = mbs\n",
    "\n",
    "trainDataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_trainE), torch.FloatTensor(X_trainM), \n",
    "                                                      torch.FloatTensor(X_trainC), torch.FloatTensor(y_trainE.astype(int)))\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset = trainDataset, batch_size=mb_size, shuffle=False, num_workers=1, sampler = sampler)\n",
    "\n",
    "n_sampE, IE_dim = X_trainE.shape\n",
    "n_sampM, IM_dim = X_trainM.shape\n",
    "n_sampC, IC_dim = X_trainC.shape\n",
    "\n",
    "h_dim = hdm\n",
    "Z_dim = zdm\n",
    "Z_in = h_dim + h_dim + h_dim\n",
    "lrE = lre\n",
    "lrM = lrm\n",
    "lrC = lrc\n",
    "epoch = epch\n",
    "\n",
    "costtr = []\n",
    "auctr = []\n",
    "costts = []\n",
    "aucts = []\n",
    "\n",
    "class AEE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEE, self).__init__()\n",
    "        self.EnE = torch.nn.Sequential(\n",
    "            nn.Linear(IE_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout())\n",
    "    def forward(self, x):\n",
    "        output = self.EnE(x)\n",
    "        return output\n",
    "\n",
    "class AEM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEM, self).__init__()\n",
    "        self.EnM = torch.nn.Sequential(\n",
    "            nn.Linear(IM_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout())\n",
    "    def forward(self, x):\n",
    "        output = self.EnM(x)\n",
    "        return output    \n",
    "\n",
    "\n",
    "class AEC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEC, self).__init__()\n",
    "        self.EnC = torch.nn.Sequential(\n",
    "            nn.Linear(IM_dim, h_dim),\n",
    "            nn.BatchNorm1d(h_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout())\n",
    "    def forward(self, x):\n",
    "        output = self.EnC(x)\n",
    "        return output   \n",
    "    \n",
    "    \n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.FC = torch.nn.Sequential(\n",
    "            nn.Linear(Z_in, Z_dim),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate),\n",
    "            nn.Linear(Z_dim, 1),\n",
    "            nn.Dropout(rate),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.FC(x)\n",
    "        \n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "AutoencoderE = AEE()\n",
    "AutoencoderM = AEM()\n",
    "AutoencoderC = AEC()\n",
    "\n",
    "solverE = optim.Adagrad(AutoencoderE.parameters(), lr=lrE)\n",
    "solverM = optim.Adagrad(AutoencoderM.parameters(), lr=lrM)\n",
    "solverC = optim.Adagrad(AutoencoderC.parameters(), lr=lrC)\n",
    "\n",
    "Clas = Classifier()\n",
    "SolverClass = optim.SGD(Clas.parameters(), lr=lrCL, weight_decay = wd)\n",
    "C_loss = torch.nn.BCELoss()\n",
    "\n",
    "for it in range(epoch):\n",
    "\n",
    "    epoch_cost4 = 0\n",
    "    epoch_cost3 = []\n",
    "    num_minibatches = int(n_sampE / mb_size) \n",
    "\n",
    "    for i, (dataE, dataM, dataC, target) in enumerate(trainLoader):\n",
    "        flag = 0\n",
    "        AutoencoderE.train()\n",
    "        AutoencoderM.train()\n",
    "        AutoencoderC.train()\n",
    "        Clas.train()\n",
    "                \n",
    "        if torch.mean(target)!=0. and torch.mean(target)!=1.:                      \n",
    "\n",
    "            ZEX = AutoencoderE(dataE)\n",
    "            ZMX = AutoencoderM(dataM)\n",
    "            ZCX = AutoencoderC(dataC)\n",
    "\n",
    "            ZT = torch.cat((ZEX, ZMX, ZCX), 1)\n",
    "            ZT = F.normalize(ZT, p=2, dim=0)\n",
    "\n",
    "            Pred = Clas(ZT)\n",
    "            loss = C_loss(Pred,target.view(-1,1))   \n",
    "\n",
    "            y_true = target.view(-1,1)\n",
    "            y_pred = Pred\n",
    "            AUC = roc_auc_score(y_true.detach().numpy(),y_pred.detach().numpy()) \n",
    "\n",
    "            solverE.zero_grad()\n",
    "            solverM.zero_grad()\n",
    "            solverC.zero_grad()\n",
    "            SolverClass.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            solverE.step()\n",
    "            solverM.step()\n",
    "            solverC.step()\n",
    "            SolverClass.step()\n",
    "                    \n",
    "            epoch_cost4 = epoch_cost4 + (loss / num_minibatches)\n",
    "            epoch_cost3.append(AUC)\n",
    "            flag = 1\n",
    "\n",
    "    if flag == 1:\n",
    "        costtr.append(torch.mean(epoch_cost4))\n",
    "        auctr.append(np.mean(epoch_cost3))\n",
    "        print('Iter-{}; Total loss: {:.4}'.format(it, loss))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    AutoencoderE.eval()\n",
    "    AutoencoderM.eval()\n",
    "    AutoencoderC.eval()\n",
    "    Clas.eval()\n",
    "\n",
    "    ZET = AutoencoderE(TX_testE)\n",
    "    ZMT = AutoencoderM(TX_testM)\n",
    "    ZCT = AutoencoderC(TX_testC)\n",
    "\n",
    "    ZTT = torch.cat((ZET, ZMT, ZCT), 1)\n",
    "    ZTT = F.normalize(ZTT, p=2, dim=0)\n",
    "\n",
    "    PredT = Clas(ZTT)\n",
    "    lossT = C_loss(PredT,ty_testE.view(-1,1))         \n",
    "\n",
    "    y_truet = ty_testE.view(-1,1)\n",
    "    y_predt = PredT\n",
    "    AUCt = roc_auc_score(y_truet.detach().numpy(),y_predt.detach().numpy())\n",
    "\n",
    "    costts.append(lossT)\n",
    "    aucts.append(AUCt)\n",
    "        #Train\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01602f3c-0d56-4352-81c1-e1903f2e2ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5972222222222222"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f87b5bd-5937-429e-8fed-6fa4311d982d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e87f570-eac4-425b-a04d-e564e567a1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f68acb-8250-47d1-afa3-e231fd8c892b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty_testE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a0912ba-55ad-46cb-82c3-6de759d5b7c3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch GPU 1.13 (py39)",
   "language": "python",
   "name": "pytorch-gpu-1.13-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
