{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "10a5a24c-9a93-4f07-9cb4-b9e0b5ca3160",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import the necessary packages\n",
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing as sk\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "from random import randint\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "48b8ac00-985e-42d9-befc-b0a08642dcf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_exprs.Cisplatin.eb_with.TCGA_exprs.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "GDSCE = pd.DataFrame.transpose(GDSCE)\n",
    "\n",
    "TCGAE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_exprs.Cisplatin.eb_with.GDSC_exprs.Cisplatin.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "TCGAE = pd.DataFrame.transpose(TCGAE)\n",
    "\n",
    "TCGAM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_mutations.Cisplatin.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "TCGAM = pd.DataFrame.transpose(TCGAM)\n",
    "TCGAM = TCGAM.loc[:,~TCGAM.columns.duplicated()]\n",
    "\n",
    "TCGAC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_CNA.Cisplatin.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "TCGAC = pd.DataFrame.transpose(TCGAC)\n",
    "TCGAC = TCGAC.loc[:,~TCGAC.columns.duplicated()]\n",
    "\n",
    "GDSCM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_mutations.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCM = pd.DataFrame.transpose(GDSCM)\n",
    "GDSCM = GDSCM.loc[:,~GDSCM.columns.duplicated()]\n",
    "\n",
    "GDSCC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_CNA.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCC.drop_duplicates(keep='last')\n",
    "GDSCC = pd.DataFrame.transpose(GDSCC)\n",
    "GDSCC = GDSCC.loc[:,~GDSCC.columns.duplicated()]\n",
    "\n",
    "selector = VarianceThreshold(0.05)\n",
    "selector.fit_transform(GDSCE)\n",
    "GDSCE = GDSCE[GDSCE.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "TCGAC = TCGAC.fillna(0)\n",
    "TCGAC[TCGAC != 0.0] = 1\n",
    "TCGAM = TCGAM.fillna(0)\n",
    "TCGAM[TCGAM != 0.0] = 1\n",
    "GDSCM = GDSCM.fillna(0)\n",
    "GDSCM[GDSCM != 0.0] = 1\n",
    "GDSCC = GDSCC.fillna(0)\n",
    "GDSCC[GDSCC != 0.0] = 1\n",
    "\n",
    "ls = set(GDSCE.columns.values).intersection(set(GDSCM.columns.values))\n",
    "ls = set(ls).intersection(set(GDSCC.columns.values))\n",
    "ls = set(ls).intersection(TCGAE.columns)\n",
    "ls = set(ls).intersection(TCGAM.columns)\n",
    "ls = set(ls).intersection(set(TCGAC.columns.values))\n",
    "ls2 = set(GDSCE.index.values).intersection(set(GDSCM.index.values))\n",
    "ls2 = set(ls2).intersection(set(GDSCC.index.values))\n",
    "ls3 = set(TCGAE.index.values).intersection(set(TCGAM.index.values))\n",
    "ls3 = set(ls3).intersection(set(TCGAC.index.values))\n",
    "#ls = pd.unique(ls)\n",
    "\n",
    "TCGAE = TCGAE.loc[ls3,ls]\n",
    "TCGAM = TCGAM.loc[ls3,ls]\n",
    "TCGAC = TCGAC.loc[ls3,ls]\n",
    "GDSCE = GDSCE.loc[ls2,ls]\n",
    "GDSCM = GDSCM.loc[ls2,ls]\n",
    "GDSCC = GDSCC.loc[ls2,ls]\n",
    "\n",
    "GDSCR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/GDSC_response.Cisplatin.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "TCGAR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cisplatin/all_data/TCGA_response.Cisplatin.tsv\", \n",
    "                       sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "\n",
    "\n",
    "GDSCR.rename(mapper = str, axis = 'index', inplace = True)\n",
    "GDSCR = GDSCR.loc[ls2,:]\n",
    "#GDSCR.loc[GDSCR.iloc[:,0] == 'R','response'] = 0\n",
    "#GDSCR.loc[GDSCR.iloc[:,0] == 'S','response'] = 1\n",
    "\n",
    "TCGAR = TCGAR.loc[ls3,:]\n",
    "#TCGAR.loc[TCGAR.iloc[:,1] == 'R','response'] = 0\n",
    "#TCGAR.loc[TCGAR.iloc[:,1] == 'S','response'] = 1\n",
    "\n",
    "d = {\"R\":0,\"S\":1}\n",
    "GDSCR[\"response\"] = GDSCR.loc[:,\"response\"].apply(lambda x: d[x])\n",
    "TCGAR[\"response\"] = TCGAR.loc[:,\"response\"].apply(lambda x: d[x])\n",
    "\n",
    "Y_train = GDSCR['response'].values\n",
    "Y_test = TCGAR['response'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bd999995-ab87-4de1-815b-a9b35f541978",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(66, 8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TCGAR.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "57ab724e-1539-4504-a982-4be4d65ad8ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; Total loss: 0.7157\n",
      "Iter-1; Total loss: 0.8986\n",
      "Iter-2; Total loss: 0.6898\n",
      "Iter-3; Total loss: 0.7652\n",
      "Iter-4; Total loss: 0.705\n",
      "Iter-5; Total loss: 0.8054\n",
      "Iter-6; Total loss: 0.4905\n",
      "Iter-7; Total loss: 0.7519\n",
      "Iter-8; Total loss: 0.4185\n",
      "Iter-9; Total loss: 0.4319\n",
      "Iter-10; Total loss: 0.6533\n",
      "Iter-11; Total loss: 0.7271\n",
      "Iter-12; Total loss: 0.7387\n",
      "Iter-13; Total loss: 0.7133\n",
      "Iter-14; Total loss: 0.2446\n",
      "Iter-15; Total loss: 0.5297\n",
      "Iter-16; Total loss: 0.6031\n",
      "Iter-17; Total loss: 0.4697\n",
      "Iter-18; Total loss: 0.2409\n"
     ]
    }
   ],
   "source": [
    "mbs = 15\n",
    "hdm1 = 128\n",
    "hdm2 = 128\n",
    "hdm3 = 128\n",
    "mrg = 0.5\n",
    "lre = 0.05\n",
    "lrm = 0.005\n",
    "lrc = 0.005\n",
    "lrCL = 0.0005\n",
    "epch = 20\n",
    "rate1 = 0.5\n",
    "rate2 = 0.6\n",
    "rate3 = 0.8\n",
    "rate4 = 0.6\n",
    "wd = 0.1\n",
    "lam = 0.2\n",
    "\n",
    "\n",
    "X_trainE = GDSCE.values\n",
    "X_testE =  TCGAE.values\n",
    "X_trainM = GDSCM.values\n",
    "X_testM = TCGAM.values\n",
    "X_trainC = GDSCC.values\n",
    "X_testC = TCGAC.values\n",
    "y_trainE = Y_train\n",
    "y_testE = Y_test\n",
    "      \n",
    "# standardize the PDX data separate\n",
    "scalerGDSC = sk.StandardScaler()\n",
    "scalerGDSC.fit(X_trainE)\n",
    "X_trainE = scalerGDSC.transform(X_trainE)\n",
    "X_testE = scalerGDSC.transform(X_testE)\n",
    "# Notice that only expression data is standardized\n",
    "# This is as the mutation and the CNA data used here are binary\n",
    "\n",
    "X_trainM = np.nan_to_num(X_trainM)\n",
    "X_trainC = np.nan_to_num(X_trainC)\n",
    "X_testM = np.nan_to_num(X_testM)\n",
    "X_testC = np.nan_to_num(X_testC)\n",
    "# np.nan_to_numpy Replace NaN with zero and infinity with large finite numbers\n",
    "        \n",
    "TX_testE = torch.FloatTensor(X_testE)\n",
    "TX_testM = torch.FloatTensor(X_testM)\n",
    "TX_testC = torch.FloatTensor(X_testC)\n",
    "ty_testE = torch.FloatTensor(y_testE.astype(int))\n",
    "        \n",
    "        \n",
    "        #Train\n",
    "class_sample_count = np.array([len(np.where(y_trainE==t)[0]) for t in np.unique(y_trainE)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in y_trainE])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight), replacement=True)\n",
    "\n",
    "mb_size = mbs\n",
    "\n",
    "trainDataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_trainE), torch.FloatTensor(X_trainM), \n",
    "                                                      torch.FloatTensor(X_trainC), torch.FloatTensor(y_trainE.astype(int)))\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset = trainDataset, batch_size=mb_size, shuffle=False, num_workers=1, sampler = sampler)\n",
    "\n",
    "n_sampE, IE_dim = X_trainE.shape\n",
    "n_sampM, IM_dim = X_trainM.shape\n",
    "n_sampC, IC_dim = X_trainC.shape\n",
    "\n",
    "h_dim1 = hdm1\n",
    "h_dim2 = hdm2\n",
    "h_dim3 = hdm3        \n",
    "Z_in = h_dim1 + h_dim2 + h_dim3\n",
    "marg = mrg\n",
    "lrE = lre\n",
    "lrM = lrm\n",
    "lrC = lrc\n",
    "epoch = epch\n",
    "\n",
    "costtr = []\n",
    "auctr = []\n",
    "costts = []\n",
    "aucts = []\n",
    "\n",
    "triplet_selector = RandomNegativeTripletSelector(marg)\n",
    "triplet_selector2 = AllTripletSelector()\n",
    "\n",
    "class AEE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEE, self).__init__()\n",
    "        self.EnE = torch.nn.Sequential(\n",
    "            nn.Linear(IE_dim, h_dim1),\n",
    "            nn.BatchNorm1d(h_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate1))\n",
    "    def forward(self, x):\n",
    "        output = self.EnE(x)\n",
    "        return output\n",
    "\n",
    "class AEM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEM, self).__init__()\n",
    "        self.EnM = torch.nn.Sequential(\n",
    "            nn.Linear(IM_dim, h_dim2),\n",
    "            nn.BatchNorm1d(h_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate2))\n",
    "    def forward(self, x):\n",
    "        output = self.EnM(x)\n",
    "        return output    \n",
    "\n",
    "\n",
    "class AEC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEC, self).__init__()\n",
    "        self.EnC = torch.nn.Sequential(\n",
    "            nn.Linear(IM_dim, h_dim3),\n",
    "            nn.BatchNorm1d(h_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate3))\n",
    "    def forward(self, x):\n",
    "        output = self.EnC(x)\n",
    "        return output    \n",
    "\n",
    "class OnlineTriplet(nn.Module):\n",
    "    def __init__(self, marg, triplet_selector):\n",
    "        super(OnlineTriplet, self).__init__()\n",
    "        self.marg = marg\n",
    "        self.triplet_selector = triplet_selector\n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "        return triplets\n",
    "\n",
    "class OnlineTestTriplet(nn.Module):\n",
    "    def __init__(self, marg, triplet_selector):\n",
    "        super(OnlineTestTriplet, self).__init__()\n",
    "        self.marg = marg\n",
    "        self.triplet_selector = triplet_selector\n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "        return triplets    \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.FC = torch.nn.Sequential(\n",
    "            nn.Linear(Z_in, 1),\n",
    "            nn.Dropout(rate4),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.FC(x)\n",
    "\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "AutoencoderE = AEE()\n",
    "AutoencoderM = AEM()\n",
    "AutoencoderC = AEC()\n",
    "\n",
    "solverE = optim.Adagrad(AutoencoderE.parameters(), lr=lrE)\n",
    "solverM = optim.Adagrad(AutoencoderM.parameters(), lr=lrM)\n",
    "solverC = optim.Adagrad(AutoencoderC.parameters(), lr=lrC)\n",
    "\n",
    "trip_criterion = torch.nn.TripletMarginLoss(margin=marg, p=2)\n",
    "TripSel = OnlineTriplet(marg, triplet_selector)\n",
    "TripSel2 = OnlineTestTriplet(marg, triplet_selector2)\n",
    "\n",
    "Clas = Classifier()\n",
    "SolverClass = optim.Adagrad(Clas.parameters(), lr=lrCL, weight_decay = wd)\n",
    "C_loss = torch.nn.BCELoss()\n",
    "\n",
    "for it in range(epoch):\n",
    "\n",
    "    epoch_cost4 = 0\n",
    "    epoch_cost3 = []\n",
    "    num_minibatches = int(n_sampE / mb_size) \n",
    "\n",
    "    for i, (dataE, dataM, dataC, target) in enumerate(trainLoader):\n",
    "        flag = 0\n",
    "        AutoencoderE.train()\n",
    "        AutoencoderM.train()\n",
    "        AutoencoderC.train()\n",
    "        Clas.train()\n",
    "\n",
    "        if torch.mean(target)!=0. and torch.mean(target)!=1.: \n",
    "            ZEX = AutoencoderE(dataE)\n",
    "            ZMX = AutoencoderM(dataM)\n",
    "            ZCX = AutoencoderC(dataC)\n",
    "\n",
    "            ZT = torch.cat((ZEX, ZMX, ZCX), 1)\n",
    "            ZT = F.normalize(ZT, p=2, dim=0)\n",
    "            Pred = Clas(ZT)\n",
    "\n",
    "            Triplets = TripSel2(ZT, target)\n",
    "            loss = lam * trip_criterion(ZT[Triplets[:,0],:],ZT[Triplets[:,1],:],ZT[Triplets[:,2],:]) + C_loss(Pred,target.view(-1,1))     \n",
    "\n",
    "            y_true = target.view(-1,1)\n",
    "            y_pred = Pred\n",
    "            AUC = roc_auc_score(y_true.detach().numpy(),y_pred.detach().numpy()) \n",
    "\n",
    "            solverE.zero_grad()\n",
    "            solverM.zero_grad()\n",
    "            solverC.zero_grad()\n",
    "            SolverClass.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            solverE.step()\n",
    "            solverM.step()\n",
    "            solverC.step()\n",
    "            SolverClass.step()\n",
    "\n",
    "            epoch_cost4 = epoch_cost4 + (loss / num_minibatches)\n",
    "            epoch_cost3.append(AUC)\n",
    "            flag = 1\n",
    "\n",
    "    if flag == 1:\n",
    "        costtr.append(torch.mean(epoch_cost4))\n",
    "        auctr.append(np.mean(epoch_cost3))\n",
    "        print('Iter-{}; Total loss: {:.4}'.format(it, loss))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    AutoencoderE.eval()\n",
    "    AutoencoderM.eval()\n",
    "    AutoencoderC.eval()\n",
    "    Clas.eval()\n",
    "\n",
    "    ZET = AutoencoderE(TX_testE)\n",
    "    ZMT = AutoencoderM(TX_testM)\n",
    "    ZCT = AutoencoderC(TX_testC)\n",
    "\n",
    "    ZTT = torch.cat((ZET, ZMT, ZCT), 1)\n",
    "    ZTT = F.normalize(ZTT, p=2, dim=0)\n",
    "    PredT = Clas(ZTT)\n",
    "\n",
    "    TripletsT = TripSel2(ZTT, ty_testE)\n",
    "    lossT = lam * trip_criterion(ZTT[TripletsT[:,0],:], ZTT[TripletsT[:,1],:], ZTT[TripletsT[:,2],:]) + C_loss(PredT,ty_testE.view(-1,1))\n",
    "\n",
    "    y_truet = ty_testE.view(-1,1)\n",
    "    y_predt = PredT\n",
    "    AUCt = roc_auc_score(y_truet.detach().numpy(),y_predt.detach().numpy())        \n",
    "\n",
    "    costts.append(lossT)\n",
    "    aucts.append(AUCt)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "01602f3c-0d56-4352-81c1-e1903f2e2ab9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6361111111111111"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1f87b5bd-5937-429e-8fed-6fa4311d982d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 1])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PredT.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1e87f570-eac4-425b-a04d-e564e567a1a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66, 1])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_truet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "67f68acb-8250-47d1-afa3-e231fd8c892b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([66])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ty_testE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5110ab6-1f79-4896-8882-765bbac73c12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch GPU 1.13 (py39)",
   "language": "python",
   "name": "pytorch-gpu-1.13-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
