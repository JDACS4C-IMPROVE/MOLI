{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "0fa169bc-fdc1-4478-b75f-c27817af68a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing as sk\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "from random import randint\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "41cc4dad-15a8-494f-85da-afc84a61f86e",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.manual_seed(42)\n",
    "\n",
    "\n",
    "\n",
    "GDSCE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/GDSC_exprs.Gemcitabine.eb_with.PDX_exprs.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "GDSCE = pd.DataFrame.transpose(GDSCE)\n",
    "# Load GDSC response\n",
    "GDSCR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/GDSC_response.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "# load pdxr response\n",
    "PDXR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/PDX_response.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "\n",
    "PDXE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/PDX_exprs.Gemcitabine.eb_with.GDSC_exprs.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "PDXE = pd.DataFrame.transpose(PDXE)\n",
    "\n",
    "PDXM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/PDX_mutations.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "PDXM = pd.DataFrame.transpose(PDXM)\n",
    "\n",
    "PDXC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/PDX_CNA.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "PDXC = pd.DataFrame.transpose(PDXC)\n",
    "\n",
    "GDSCM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/GDSC_mutations.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCM = pd.DataFrame.transpose(GDSCM)\n",
    "\n",
    "GDSCC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Gemcitabine_PDX/all_data/GDSC_CNA.Gemcitabine.tsv\", sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCC.drop_duplicates(keep='last')\n",
    "PDXC = PDXC.loc[:,~PDXC.columns.duplicated()]\n",
    "GDSCC = pd.DataFrame.transpose(GDSCC)\n",
    "selector = VarianceThreshold(0.05)\n",
    "selector.fit_transform(GDSCE)\n",
    "GDSCE = GDSCE[GDSCE.columns[selector.get_support(indices=True)]]\n",
    "\n",
    "PDXC = PDXC.fillna(0)\n",
    "PDXC[PDXC != 0.0] = 1\n",
    "PDXM = PDXM.fillna(0)\n",
    "PDXM[PDXM != 0.0] = 1\n",
    "GDSCM = GDSCM.fillna(0)\n",
    "GDSCM[GDSCM != 0.0] = 1\n",
    "GDSCC = GDSCC.fillna(0)\n",
    "GDSCC[GDSCC != 0.0] = 1\n",
    "\n",
    "ls = GDSCE.columns.intersection(GDSCM.columns)\n",
    "ls = ls.intersection(GDSCC.columns)\n",
    "ls = ls.intersection(PDXE.columns)\n",
    "ls = ls.intersection(PDXM.columns)\n",
    "ls = ls.intersection(PDXC.columns)\n",
    "ls2 = GDSCE.index.intersection(GDSCM.index)\n",
    "ls2 = ls2.intersection(GDSCC.index)\n",
    "ls3 = PDXE.index.intersection(PDXM.index)\n",
    "ls3 = ls3.intersection(PDXC.index)\n",
    "ls = pd.unique(ls)\n",
    "\n",
    "PDXE = PDXE.loc[ls3,ls]\n",
    "PDXM = PDXM.loc[ls3,ls]\n",
    "PDXC = PDXC.loc[ls3,ls]\n",
    "GDSCE = GDSCE.loc[ls2,ls]\n",
    "GDSCM = GDSCM.loc[ls2,ls]\n",
    "GDSCC = GDSCC.loc[ls2,ls]\n",
    "\n",
    "GDSCR.rename(mapper = str, axis = 'index', inplace = True)\n",
    "GDSCR = GDSCR.loc[ls2,:]\n",
    "#GDSCR.loc[GDSCR.iloc[:,0] == 'R','response'] = 0\n",
    "#GDSCR.loc[GDSCR.iloc[:,0] == 'S','response'] = 1\n",
    "\n",
    "# TCGAR = TCGAR.loc[ls3,:]\n",
    "#TCGAR.loc[TCGAR.iloc[:,1] == 'R','response'] = 0\n",
    "#TCGAR.loc[TCGAR.iloc[:,1] == 'S','response'] = 1\n",
    "\n",
    "d = {\"R\":0,\"S\":1}\n",
    "GDSCR[\"response\"] = GDSCR.loc[:,\"response\"].apply(lambda x: d[x])\n",
    "PDXR[\"response\"] = PDXR.loc[:,\"response\"].apply(lambda x: d[x])\n",
    "\n",
    "Y_train = GDSCR['response'].values\n",
    "Y_test = PDXR['response'].values\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "ce5c3898-2641-4e2b-89c5-884b182b6935",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; Total loss: 1.012\n",
      "Iter-1; Total loss: 0.8978\n",
      "Iter-2; Total loss: 0.812\n",
      "Iter-3; Total loss: 0.888\n",
      "Iter-4; Total loss: 1.138\n"
     ]
    }
   ],
   "source": [
    "mbs = 13\n",
    "hdm1 = 256\n",
    "hdm2 = 32\n",
    "hdm3 = 64 \n",
    "mrg = 1.5\n",
    "lre = 0.05\n",
    "lrm = 1e-05\n",
    "lrc = 0.0005\n",
    "lrCL = 0.001\n",
    "epch = 5\n",
    "rate1 = 0.4\n",
    "rate2 = 0.6\n",
    "rate3 =0.3\n",
    "rate4 = 0.6  \n",
    "wd = 0.01\n",
    "lam = 0.3  \n",
    "\n",
    "X_trainE = GDSCE.values\n",
    "X_testE =  PDXE.values\n",
    "X_trainM = GDSCM.values\n",
    "X_testM = PDXM.values\n",
    "X_trainC = GDSCC.values\n",
    "X_testC = PDXC.values\n",
    "y_trainE = Y_train\n",
    "y_testE = Y_test\n",
    "      \n",
    "# standardize the PDX data separate\n",
    "scalerGDSC = sk.StandardScaler()\n",
    "scalerGDSC.fit(X_trainE)\n",
    "X_trainE = scalerGDSC.transform(X_trainE)\n",
    "X_testE = scalerGDSC.transform(X_testE)\n",
    "# Notice that only expression data is standardized\n",
    "# This is as the mutation and the CNA data used here are binary\n",
    "\n",
    "X_trainM = np.nan_to_num(X_trainM)\n",
    "X_trainC = np.nan_to_num(X_trainC)\n",
    "X_testM = np.nan_to_num(X_testM)\n",
    "X_testC = np.nan_to_num(X_testC)\n",
    "# np.nan_to_numpy Replace NaN with zero and infinity with large finite numbers\n",
    "        \n",
    "TX_testE = torch.FloatTensor(X_testE)\n",
    "TX_testM = torch.FloatTensor(X_testM)\n",
    "TX_testC = torch.FloatTensor(X_testC)\n",
    "ty_testE = torch.FloatTensor(y_testE.astype(int))\n",
    "        \n",
    "#Train\n",
    "class_sample_count = np.array([len(np.where(y_trainE==t)[0]) for t in np.unique(y_trainE)])\n",
    "weight = 1. / class_sample_count\n",
    "samples_weight = np.array([weight[t] for t in y_trainE])\n",
    "\n",
    "samples_weight = torch.from_numpy(samples_weight)\n",
    "sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight), replacement=True)\n",
    "\n",
    "mb_size = mbs\n",
    "\n",
    "trainDataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_trainE), torch.FloatTensor(X_trainM), \n",
    "                                                      torch.FloatTensor(X_trainC), torch.FloatTensor(y_trainE.astype(int)))\n",
    "\n",
    "trainLoader = torch.utils.data.DataLoader(dataset = trainDataset, batch_size=mb_size, shuffle=False, num_workers=1, sampler = sampler)\n",
    "\n",
    "n_sampE, IE_dim = X_trainE.shape\n",
    "n_sampM, IM_dim = X_trainM.shape\n",
    "n_sampC, IC_dim = X_trainC.shape\n",
    "\n",
    "h_dim1 = hdm1\n",
    "h_dim2 = hdm2\n",
    "h_dim3 = hdm3        \n",
    "Z_in = h_dim1 + h_dim2 + h_dim3\n",
    "marg = mrg\n",
    "lrE = lre\n",
    "lrM = lrm\n",
    "lrC = lrc\n",
    "epoch = epch\n",
    "\n",
    "costtr = []\n",
    "auctr = []\n",
    "costts = []\n",
    "aucts = []\n",
    "\n",
    "triplet_selector = RandomNegativeTripletSelector(marg)\n",
    "triplet_selector2 = AllTripletSelector()\n",
    "\n",
    "class AEE(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEE, self).__init__()\n",
    "        self.EnE = torch.nn.Sequential(\n",
    "            nn.Linear(IE_dim, h_dim1),\n",
    "            nn.BatchNorm1d(h_dim1),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate1))\n",
    "    def forward(self, x):\n",
    "        output = self.EnE(x)\n",
    "        return output\n",
    "\n",
    "class AEM(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEM, self).__init__()\n",
    "        self.EnM = torch.nn.Sequential(\n",
    "            nn.Linear(IM_dim, h_dim2),\n",
    "            nn.BatchNorm1d(h_dim2),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate2))\n",
    "    def forward(self, x):\n",
    "        output = self.EnM(x)\n",
    "        return output    \n",
    "\n",
    "\n",
    "class AEC(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(AEC, self).__init__()\n",
    "        self.EnC = torch.nn.Sequential(\n",
    "            nn.Linear(IM_dim, h_dim3),\n",
    "            nn.BatchNorm1d(h_dim3),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(rate3))\n",
    "    def forward(self, x):\n",
    "        output = self.EnC(x)\n",
    "        return output    \n",
    "\n",
    "class OnlineTriplet(nn.Module):\n",
    "    def __init__(self, marg, triplet_selector):\n",
    "        super(OnlineTriplet, self).__init__()\n",
    "        self.marg = marg\n",
    "        self.triplet_selector = triplet_selector\n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "        return triplets\n",
    "\n",
    "class OnlineTestTriplet(nn.Module):\n",
    "    def __init__(self, marg, triplet_selector):\n",
    "        super(OnlineTestTriplet, self).__init__()\n",
    "        self.marg = marg\n",
    "        self.triplet_selector = triplet_selector\n",
    "    def forward(self, embeddings, target):\n",
    "        triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "        return triplets    \n",
    "\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Classifier, self).__init__()\n",
    "        self.FC = torch.nn.Sequential(\n",
    "            nn.Linear(Z_in, 1),\n",
    "            nn.Dropout(rate4),\n",
    "            nn.Sigmoid())\n",
    "    def forward(self, x):\n",
    "        return self.FC(x)\n",
    "\n",
    "torch.cuda.manual_seed_all(42)\n",
    "\n",
    "AutoencoderE = AEE()\n",
    "AutoencoderM = AEM()\n",
    "AutoencoderC = AEC()\n",
    "\n",
    "solverE = optim.Adagrad(AutoencoderE.parameters(), lr=lrE)\n",
    "solverM = optim.Adagrad(AutoencoderM.parameters(), lr=lrM)\n",
    "solverC = optim.Adagrad(AutoencoderC.parameters(), lr=lrC)\n",
    "\n",
    "trip_criterion = torch.nn.TripletMarginLoss(margin=marg, p=2)\n",
    "TripSel = OnlineTriplet(marg, triplet_selector)\n",
    "TripSel2 = OnlineTestTriplet(marg, triplet_selector2)\n",
    "\n",
    "Clas = Classifier()\n",
    "SolverClass = optim.Adagrad(Clas.parameters(), lr=lrCL, weight_decay = wd)\n",
    "C_loss = torch.nn.BCELoss()\n",
    "\n",
    "for it in range(epoch):\n",
    "\n",
    "    epoch_cost4 = 0\n",
    "    epoch_cost3 = []\n",
    "    num_minibatches = int(n_sampE / mb_size) \n",
    "\n",
    "    for i, (dataE, dataM, dataC, target) in enumerate(trainLoader):\n",
    "        flag = 0\n",
    "        AutoencoderE.train()\n",
    "        AutoencoderM.train()\n",
    "        AutoencoderC.train()\n",
    "        Clas.train()\n",
    "\n",
    "        if torch.mean(target)!=0. and torch.mean(target)!=1.: \n",
    "            ZEX = AutoencoderE(dataE)\n",
    "            ZMX = AutoencoderM(dataM)\n",
    "            ZCX = AutoencoderC(dataC)\n",
    "\n",
    "            ZT = torch.cat((ZEX, ZMX, ZCX), 1)\n",
    "            ZT = F.normalize(ZT, p=2, dim=0)\n",
    "            Pred = Clas(ZT)\n",
    "\n",
    "            Triplets = TripSel2(ZT, target)\n",
    "            loss = lam * trip_criterion(ZT[Triplets[:,0],:],ZT[Triplets[:,1],:],ZT[Triplets[:,2],:]) + C_loss(Pred,target.view(-1,1))     \n",
    "\n",
    "            y_true = target.view(-1,1)\n",
    "            y_pred = Pred\n",
    "            AUC = roc_auc_score(y_true.detach().numpy(),y_pred.detach().numpy()) \n",
    "\n",
    "            solverE.zero_grad()\n",
    "            solverM.zero_grad()\n",
    "            solverC.zero_grad()\n",
    "            SolverClass.zero_grad()\n",
    "\n",
    "            loss.backward()\n",
    "\n",
    "            solverE.step()\n",
    "            solverM.step()\n",
    "            solverC.step()\n",
    "            SolverClass.step()\n",
    "\n",
    "            epoch_cost4 = epoch_cost4 + (loss / num_minibatches)\n",
    "            epoch_cost3.append(AUC)\n",
    "            flag = 1\n",
    "\n",
    "    if flag == 1:\n",
    "        costtr.append(torch.mean(epoch_cost4))\n",
    "        auctr.append(np.mean(epoch_cost3))\n",
    "        print('Iter-{}; Total loss: {:.4}'.format(it, loss))\n",
    "\n",
    "with torch.no_grad():\n",
    "\n",
    "    AutoencoderE.eval()\n",
    "    AutoencoderM.eval()\n",
    "    AutoencoderC.eval()\n",
    "    Clas.eval()\n",
    "\n",
    "    ZET = AutoencoderE(TX_testE)\n",
    "    ZMT = AutoencoderM(TX_testM)\n",
    "    ZCT = AutoencoderC(TX_testC)\n",
    "\n",
    "    ZTT = torch.cat((ZET, ZMT, ZCT), 1)\n",
    "    ZTT = F.normalize(ZTT, p=2, dim=0)\n",
    "    PredT = Clas(ZTT)\n",
    "\n",
    "    TripletsT = TripSel2(ZTT, ty_testE)\n",
    "    lossT = lam * trip_criterion(ZTT[TripletsT[:,0],:], ZTT[TripletsT[:,1],:], ZTT[TripletsT[:,2],:]) + C_loss(PredT,ty_testE.view(-1,1))\n",
    "\n",
    "    y_truet = ty_testE.view(-1,1)\n",
    "    y_predt = PredT\n",
    "    AUCt = roc_auc_score(y_truet.detach().numpy(),y_predt.detach().numpy())        \n",
    "\n",
    "    costts.append(lossT)\n",
    "    aucts.append(AUCt)\n",
    "                "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e8e424c4-9ce6-4cd7-a1bd-e2bde7cd063a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6349206349206349"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "AUCt"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch GPU 1.13 (py310)",
   "language": "python",
   "name": "pytorch-gpu-1.13-py310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
