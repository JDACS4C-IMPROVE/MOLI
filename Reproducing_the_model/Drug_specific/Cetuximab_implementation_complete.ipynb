{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "4bf6d8d8-ee20-4288-b79f-25a376b230e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib.gridspec as gridspec\n",
    "import pandas as pd\n",
    "import math\n",
    "import sklearn.preprocessing as sk\n",
    "import seaborn as sns\n",
    "from sklearn import metrics\n",
    "from sklearn.feature_selection import VarianceThreshold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from utils import AllTripletSelector,HardestNegativeTripletSelector, RandomNegativeTripletSelector, SemihardNegativeTripletSelector # Strategies for selecting triplets within a minibatch\n",
    "from metrics import AverageNonzeroTripletsMetric\n",
    "from torch.utils.data.sampler import WeightedRandomSampler\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import average_precision_score\n",
    "import random\n",
    "from random import randint\n",
    "from sklearn.model_selection import StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3490fb03-219c-479e-b537-6ed8de2c1b2e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x150bb801eaf0>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "save_results_to = '/common/statsgeneral/gayara/MOLI/Cetuximab/results/complete/'\n",
    "torch.manual_seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "518957f3-f699-4a87-8167-8e41f04877cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "max_iter = 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a556c231-996b-45bf-a5a0-d48790196f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/GDSC_exprs.Cetuximab.eb_with.PDX_exprs.Cetuximab.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "GDSCE = pd.DataFrame.transpose(GDSCE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d0934ad4-36bb-4b4c-8d7f-54c112c99339",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCE = GDSCE.drop_duplicates()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "81a5b42f-7231-4838-a9e3-515db2004670",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ENTREZID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>100507206</th>\n",
       "      <th>100507254</th>\n",
       "      <th>100507436</th>\n",
       "      <th>100507472</th>\n",
       "      <th>100526773</th>\n",
       "      <th>100527978</th>\n",
       "      <th>100532746</th>\n",
       "      <th>100820829</th>\n",
       "      <th>102724473</th>\n",
       "      <th>105375355</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>3.567759</td>\n",
       "      <td>3.444390</td>\n",
       "      <td>7.410196</td>\n",
       "      <td>2.901726</td>\n",
       "      <td>2.981935</td>\n",
       "      <td>2.807028</td>\n",
       "      <td>7.649455</td>\n",
       "      <td>2.829688</td>\n",
       "      <td>7.895537</td>\n",
       "      <td>3.102168</td>\n",
       "      <td>...</td>\n",
       "      <td>2.711407</td>\n",
       "      <td>2.788156</td>\n",
       "      <td>5.850589</td>\n",
       "      <td>2.987299</td>\n",
       "      <td>2.895857</td>\n",
       "      <td>2.686677</td>\n",
       "      <td>2.586782</td>\n",
       "      <td>2.949731</td>\n",
       "      <td>5.572678</td>\n",
       "      <td>2.960097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>4.031647</td>\n",
       "      <td>3.119876</td>\n",
       "      <td>5.348844</td>\n",
       "      <td>3.039942</td>\n",
       "      <td>2.826096</td>\n",
       "      <td>2.767429</td>\n",
       "      <td>8.136493</td>\n",
       "      <td>2.738326</td>\n",
       "      <td>9.482195</td>\n",
       "      <td>5.646555</td>\n",
       "      <td>...</td>\n",
       "      <td>2.530302</td>\n",
       "      <td>2.880834</td>\n",
       "      <td>7.653155</td>\n",
       "      <td>3.062286</td>\n",
       "      <td>2.923641</td>\n",
       "      <td>2.318554</td>\n",
       "      <td>2.840805</td>\n",
       "      <td>3.177785</td>\n",
       "      <td>3.865416</td>\n",
       "      <td>2.374161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>5.422951</td>\n",
       "      <td>3.289388</td>\n",
       "      <td>6.266940</td>\n",
       "      <td>2.990110</td>\n",
       "      <td>2.788320</td>\n",
       "      <td>2.614472</td>\n",
       "      <td>8.263573</td>\n",
       "      <td>2.336854</td>\n",
       "      <td>10.224379</td>\n",
       "      <td>5.981012</td>\n",
       "      <td>...</td>\n",
       "      <td>2.596334</td>\n",
       "      <td>2.857835</td>\n",
       "      <td>5.780610</td>\n",
       "      <td>2.614800</td>\n",
       "      <td>2.939208</td>\n",
       "      <td>2.995160</td>\n",
       "      <td>2.063917</td>\n",
       "      <td>2.724124</td>\n",
       "      <td>3.812784</td>\n",
       "      <td>2.655778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>4.706813</td>\n",
       "      <td>6.557659</td>\n",
       "      <td>5.506414</td>\n",
       "      <td>3.092901</td>\n",
       "      <td>3.016461</td>\n",
       "      <td>2.970122</td>\n",
       "      <td>8.513847</td>\n",
       "      <td>2.744526</td>\n",
       "      <td>8.400158</td>\n",
       "      <td>3.482531</td>\n",
       "      <td>...</td>\n",
       "      <td>2.601068</td>\n",
       "      <td>3.211715</td>\n",
       "      <td>8.236083</td>\n",
       "      <td>2.799498</td>\n",
       "      <td>2.933778</td>\n",
       "      <td>2.320755</td>\n",
       "      <td>2.259224</td>\n",
       "      <td>3.034710</td>\n",
       "      <td>3.892887</td>\n",
       "      <td>2.542773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>4.504268</td>\n",
       "      <td>4.843109</td>\n",
       "      <td>5.670954</td>\n",
       "      <td>2.978294</td>\n",
       "      <td>2.952328</td>\n",
       "      <td>3.317617</td>\n",
       "      <td>7.819232</td>\n",
       "      <td>2.642423</td>\n",
       "      <td>9.457529</td>\n",
       "      <td>3.797871</td>\n",
       "      <td>...</td>\n",
       "      <td>2.599445</td>\n",
       "      <td>3.187923</td>\n",
       "      <td>7.290323</td>\n",
       "      <td>3.002865</td>\n",
       "      <td>2.940937</td>\n",
       "      <td>2.837265</td>\n",
       "      <td>2.964874</td>\n",
       "      <td>2.668278</td>\n",
       "      <td>3.869515</td>\n",
       "      <td>2.719021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18232 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ENTREZID  1          2          9          10         12         13         \\\n",
       "683665     3.567759   3.444390   7.410196   2.901726   2.981935   2.807028   \n",
       "684052     4.031647   3.119876   5.348844   3.039942   2.826096   2.767429   \n",
       "684055     5.422951   3.289388   6.266940   2.990110   2.788320   2.614472   \n",
       "684057     4.706813   6.557659   5.506414   3.092901   3.016461   2.970122   \n",
       "684059     4.504268   4.843109   5.670954   2.978294   2.952328   3.317617   \n",
       "\n",
       "ENTREZID  14         15         16         18         ...  100507206  \\\n",
       "683665     7.649455   2.829688   7.895537   3.102168  ...   2.711407   \n",
       "684052     8.136493   2.738326   9.482195   5.646555  ...   2.530302   \n",
       "684055     8.263573   2.336854  10.224379   5.981012  ...   2.596334   \n",
       "684057     8.513847   2.744526   8.400158   3.482531  ...   2.601068   \n",
       "684059     7.819232   2.642423   9.457529   3.797871  ...   2.599445   \n",
       "\n",
       "ENTREZID  100507254  100507436  100507472  100526773  100527978  100532746  \\\n",
       "683665     2.788156   5.850589   2.987299   2.895857   2.686677   2.586782   \n",
       "684052     2.880834   7.653155   3.062286   2.923641   2.318554   2.840805   \n",
       "684055     2.857835   5.780610   2.614800   2.939208   2.995160   2.063917   \n",
       "684057     3.211715   8.236083   2.799498   2.933778   2.320755   2.259224   \n",
       "684059     3.187923   7.290323   3.002865   2.940937   2.837265   2.964874   \n",
       "\n",
       "ENTREZID  100820829  102724473  105375355  \n",
       "683665     2.949731   5.572678   2.960097  \n",
       "684052     3.177785   3.865416   2.374161  \n",
       "684055     2.724124   3.812784   2.655778  \n",
       "684057     3.034710   3.892887   2.542773  \n",
       "684059     2.668278   3.869515   2.719021  \n",
       "\n",
       "[5 rows x 18232 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cfb1434e-caa0-4279-b4cb-92174f1ab28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(861, 18232)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b8807acf-d4a6-4736-98ed-d4efa7ebfb21",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCR = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/GDSC_response.Cetuximab.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "5650166e-143f-406e-a965-d92c79bd7d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>logIC50</th>\n",
       "      <th>drug</th>\n",
       "      <th>exprs</th>\n",
       "      <th>CNA</th>\n",
       "      <th>mutations</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>sample_name</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>R</td>\n",
       "      <td>6.29444657935625</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>R</td>\n",
       "      <td>6.3873236983719</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>S</td>\n",
       "      <td>4.9521245559495</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>R</td>\n",
       "      <td>6.3935613853243</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>R</td>\n",
       "      <td>5.9189028381580595</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            response             logIC50       drug  exprs  CNA  mutations\n",
       "sample_name                                                               \n",
       "683665             R    6.29444657935625  Cetuximab      1    1          1\n",
       "684052             R     6.3873236983719  Cetuximab      1    1          1\n",
       "684055             S     4.9521245559495  Cetuximab      1    1          1\n",
       "684057             R     6.3935613853243  Cetuximab      1    1          1\n",
       "684059             R  5.9189028381580595  Cetuximab      1    1          1"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "fd9254a6-de38-4249-9992-7a018b7d132d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that the index in then two dataframes are the unique rows "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "753278c8-bf9b-4fd7-8e4f-4e09dd6f31bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCR_index = list(GDSCR.index.unique())\n",
    "GDSCE_index = list(GDSCE.index.unique())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "da7a666c-ea58-4757-a727-f5ab6f008651",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDSCR_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "9606fea3-903e-45b0-9dfc-1f1921fe4927",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "861\n",
      "856\n"
     ]
    }
   ],
   "source": [
    "print(len(GDSCE_index))\n",
    "print(len(GDSCR_index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "7e01b905-7632-4dab-8207-1a8a2861081f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note that common elements are shared but one list is trings and the other is integers, therefore a conversion to a single type is necessary before trying to get the\n",
    "# common elements - make the index of GDSCR a character."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "f9a2876d-94fe-4b8e-887c-4819ee18811b",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCR.index = GDSCR.index.map(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "624d5b14-ffef-4291-b187-e1deddcae049",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['683665', '684052', '684055', '684057', '684059', '684062', '684072',\n",
       "       '684681', '687452', '687455',\n",
       "       ...\n",
       "       '1524416', '1524417', '1524418', '1524419', '1659817', '1659823',\n",
       "       '1660034', '1660035', '1660036', '1674021'],\n",
       "      dtype='object', name='sample_name', length=856)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCR.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "238e2764-de52-4712-bd6c-4a15149fb6a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDXE = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/PDX_exprs.Cetuximab.eb_with.GDSC_exprs.Cetuximab.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \",\")\n",
    "PDXE = pd.DataFrame.transpose(PDXE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b694bbbe-7f9b-4f69-ad54-02dedd44dddd",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDXM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/PDX_mutations.Cetuximab.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "PDXM = pd.DataFrame.transpose(PDXM)\n",
    "\n",
    "PDXC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/PDX_CNA.Cetuximab.tsv\", \n",
    "                   sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "PDXC.drop_duplicates(keep='last')\n",
    "PDXC = pd.DataFrame.transpose(PDXC)\n",
    "\n",
    "GDSCM = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/GDSC_mutations.Cetuximab.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCM = pd.DataFrame.transpose(GDSCM)\n",
    "\n",
    "\n",
    "GDSCC = pd.read_csv(\"/common/statsgeneral/gayara/MOLI/Cetuximab/all_data/GDSC_CNA.Cetuximab.tsv\", \n",
    "                    sep = \"\\t\", index_col=0, decimal = \".\")\n",
    "GDSCC.drop_duplicates(keep='last')\n",
    "GDSCC = pd.DataFrame.transpose(GDSCC)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b0ac283f-13ae-4f0c-9d74-cd50ee19de35",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 18421)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCM.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e4196819-87ab-4dba-879b-c4a3c1c7589c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>101060321</th>\n",
       "      <th>101927546</th>\n",
       "      <th>101927722</th>\n",
       "      <th>101928638</th>\n",
       "      <th>102724473</th>\n",
       "      <th>102724928</th>\n",
       "      <th>105375355</th>\n",
       "      <th>105378803</th>\n",
       "      <th>107403068</th>\n",
       "      <th>109731405</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 18421 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        1          2          9          10         12         13         \\\n",
       "683665          0          0          0          0          0          0   \n",
       "684052          0          0          0          0          0          0   \n",
       "684055          0          0          0          0          0          0   \n",
       "684057          0          0          0          0          0          0   \n",
       "684059          0          0          0          0          0          0   \n",
       "\n",
       "        14         15         16         18         ...  101060321  101927546  \\\n",
       "683665          0          0          0          1  ...          0          0   \n",
       "684052          0          0          0          0  ...          0          0   \n",
       "684055          0          0          0          0  ...          0          0   \n",
       "684057          0          0          0          0  ...          0          0   \n",
       "684059          0          0          0          0  ...          0          0   \n",
       "\n",
       "        101927722  101928638  102724473  102724928  105375355  105378803  \\\n",
       "683665          0          0          0          0          0          0   \n",
       "684052          0          0          0          0          0          0   \n",
       "684055          0          0          0          0          0          0   \n",
       "684057          0          0          0          0          0          0   \n",
       "684059          0          0          0          0          0          0   \n",
       "\n",
       "        107403068  109731405  \n",
       "683665          0          0  \n",
       "684052          0          0  \n",
       "684055          0          0  \n",
       "684057          1          0  \n",
       "684059          0          0  \n",
       "\n",
       "[5 rows x 18421 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCM.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "530f4313-a521-4920-9a26-7962c71157ea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 24452)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCC.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7c377fc8-0892-4729-abee-0431cd181ec5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>gene_id</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>107133486</th>\n",
       "      <th>107133502</th>\n",
       "      <th>107133524</th>\n",
       "      <th>107161145</th>\n",
       "      <th>107985535</th>\n",
       "      <th>107986809</th>\n",
       "      <th>107987337</th>\n",
       "      <th>107987341</th>\n",
       "      <th>109731405</th>\n",
       "      <th>112441434</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 24452 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "gene_id  1          2          9          10         12         13         \\\n",
       "683665           0          0          0          0          0          0   \n",
       "684052           0          0          0          0          0          0   \n",
       "684055           0          1          1          1          0          0   \n",
       "684057          -1          0          1          1         -1          0   \n",
       "684059           0          0          0          0          0          1   \n",
       "\n",
       "gene_id  14         15         16         18         ...  107133486  \\\n",
       "683665           0          0          0          0  ...          0   \n",
       "684052           0          0          0          0  ...          0   \n",
       "684055           0          0          0          0  ...          0   \n",
       "684057           0          0         -1         -1  ...         -1   \n",
       "684059           0          0          0          1  ...          1   \n",
       "\n",
       "gene_id  107133502  107133524  107161145  107985535  107986809  107987337  \\\n",
       "683665           1          0          0          0          0          0   \n",
       "684052           0          0          0          0          0         -1   \n",
       "684055           1          0          1          0          1         -1   \n",
       "684057           1         -1          0         -1          0         -1   \n",
       "684059           0         -1          0          0          0         -1   \n",
       "\n",
       "gene_id  107987341  109731405  112441434  \n",
       "683665           1          0          0  \n",
       "684052          -1          0          0  \n",
       "684055          -1          0          0  \n",
       "684057          -1         -1         -1  \n",
       "684059          -1          0          0  \n",
       "\n",
       "[5 rows x 24452 columns]"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "612eb0d7-ee05-4714-8558-a06f4bbdd55b",
   "metadata": {},
   "outputs": [],
   "source": [
    "selector = VarianceThreshold(0.05)\n",
    "selector.fit_transform(GDSCE)\n",
    "GDSCE = GDSCE[GDSCE.columns[selector.get_support(indices=True)]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "df943a16-eab1-4503-96cb-b8ea32ffba45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(861, 16244)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "debbfb82-3257-4e7f-92cf-24521f2ac6e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ENTREZID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>18</th>\n",
       "      <th>...</th>\n",
       "      <th>100506548</th>\n",
       "      <th>100507117</th>\n",
       "      <th>100507254</th>\n",
       "      <th>100507436</th>\n",
       "      <th>100507472</th>\n",
       "      <th>100527978</th>\n",
       "      <th>100532746</th>\n",
       "      <th>100820829</th>\n",
       "      <th>102724473</th>\n",
       "      <th>105375355</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>3.567759</td>\n",
       "      <td>3.444390</td>\n",
       "      <td>7.410196</td>\n",
       "      <td>2.901726</td>\n",
       "      <td>2.981935</td>\n",
       "      <td>2.807028</td>\n",
       "      <td>7.649455</td>\n",
       "      <td>2.829688</td>\n",
       "      <td>7.895537</td>\n",
       "      <td>3.102168</td>\n",
       "      <td>...</td>\n",
       "      <td>6.123125</td>\n",
       "      <td>3.383855</td>\n",
       "      <td>2.788156</td>\n",
       "      <td>5.850589</td>\n",
       "      <td>2.987299</td>\n",
       "      <td>2.686677</td>\n",
       "      <td>2.586782</td>\n",
       "      <td>2.949731</td>\n",
       "      <td>5.572678</td>\n",
       "      <td>2.960097</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>4.031647</td>\n",
       "      <td>3.119876</td>\n",
       "      <td>5.348844</td>\n",
       "      <td>3.039942</td>\n",
       "      <td>2.826096</td>\n",
       "      <td>2.767429</td>\n",
       "      <td>8.136493</td>\n",
       "      <td>2.738326</td>\n",
       "      <td>9.482195</td>\n",
       "      <td>5.646555</td>\n",
       "      <td>...</td>\n",
       "      <td>6.426264</td>\n",
       "      <td>4.941407</td>\n",
       "      <td>2.880834</td>\n",
       "      <td>7.653155</td>\n",
       "      <td>3.062286</td>\n",
       "      <td>2.318554</td>\n",
       "      <td>2.840805</td>\n",
       "      <td>3.177785</td>\n",
       "      <td>3.865416</td>\n",
       "      <td>2.374161</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>5.422951</td>\n",
       "      <td>3.289388</td>\n",
       "      <td>6.266940</td>\n",
       "      <td>2.990110</td>\n",
       "      <td>2.788320</td>\n",
       "      <td>2.614472</td>\n",
       "      <td>8.263573</td>\n",
       "      <td>2.336854</td>\n",
       "      <td>10.224379</td>\n",
       "      <td>5.981012</td>\n",
       "      <td>...</td>\n",
       "      <td>7.968420</td>\n",
       "      <td>3.090929</td>\n",
       "      <td>2.857835</td>\n",
       "      <td>5.780610</td>\n",
       "      <td>2.614800</td>\n",
       "      <td>2.995160</td>\n",
       "      <td>2.063917</td>\n",
       "      <td>2.724124</td>\n",
       "      <td>3.812784</td>\n",
       "      <td>2.655778</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>4.706813</td>\n",
       "      <td>6.557659</td>\n",
       "      <td>5.506414</td>\n",
       "      <td>3.092901</td>\n",
       "      <td>3.016461</td>\n",
       "      <td>2.970122</td>\n",
       "      <td>8.513847</td>\n",
       "      <td>2.744526</td>\n",
       "      <td>8.400158</td>\n",
       "      <td>3.482531</td>\n",
       "      <td>...</td>\n",
       "      <td>8.037666</td>\n",
       "      <td>4.957676</td>\n",
       "      <td>3.211715</td>\n",
       "      <td>8.236083</td>\n",
       "      <td>2.799498</td>\n",
       "      <td>2.320755</td>\n",
       "      <td>2.259224</td>\n",
       "      <td>3.034710</td>\n",
       "      <td>3.892887</td>\n",
       "      <td>2.542773</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>4.504268</td>\n",
       "      <td>4.843109</td>\n",
       "      <td>5.670954</td>\n",
       "      <td>2.978294</td>\n",
       "      <td>2.952328</td>\n",
       "      <td>3.317617</td>\n",
       "      <td>7.819232</td>\n",
       "      <td>2.642423</td>\n",
       "      <td>9.457529</td>\n",
       "      <td>3.797871</td>\n",
       "      <td>...</td>\n",
       "      <td>8.096685</td>\n",
       "      <td>4.448424</td>\n",
       "      <td>3.187923</td>\n",
       "      <td>7.290323</td>\n",
       "      <td>3.002865</td>\n",
       "      <td>2.837265</td>\n",
       "      <td>2.964874</td>\n",
       "      <td>2.668278</td>\n",
       "      <td>3.869515</td>\n",
       "      <td>2.719021</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16244 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ENTREZID  1          2          9          10         12         13         \\\n",
       "683665     3.567759   3.444390   7.410196   2.901726   2.981935   2.807028   \n",
       "684052     4.031647   3.119876   5.348844   3.039942   2.826096   2.767429   \n",
       "684055     5.422951   3.289388   6.266940   2.990110   2.788320   2.614472   \n",
       "684057     4.706813   6.557659   5.506414   3.092901   3.016461   2.970122   \n",
       "684059     4.504268   4.843109   5.670954   2.978294   2.952328   3.317617   \n",
       "\n",
       "ENTREZID  14         15         16         18         ...  100506548  \\\n",
       "683665     7.649455   2.829688   7.895537   3.102168  ...   6.123125   \n",
       "684052     8.136493   2.738326   9.482195   5.646555  ...   6.426264   \n",
       "684055     8.263573   2.336854  10.224379   5.981012  ...   7.968420   \n",
       "684057     8.513847   2.744526   8.400158   3.482531  ...   8.037666   \n",
       "684059     7.819232   2.642423   9.457529   3.797871  ...   8.096685   \n",
       "\n",
       "ENTREZID  100507117  100507254  100507436  100507472  100527978  100532746  \\\n",
       "683665     3.383855   2.788156   5.850589   2.987299   2.686677   2.586782   \n",
       "684052     4.941407   2.880834   7.653155   3.062286   2.318554   2.840805   \n",
       "684055     3.090929   2.857835   5.780610   2.614800   2.995160   2.063917   \n",
       "684057     4.957676   3.211715   8.236083   2.799498   2.320755   2.259224   \n",
       "684059     4.448424   3.187923   7.290323   3.002865   2.837265   2.964874   \n",
       "\n",
       "ENTREZID  100820829  102724473  105375355  \n",
       "683665     2.949731   5.572678   2.960097  \n",
       "684052     3.177785   3.865416   2.374161  \n",
       "684055     2.724124   3.812784   2.655778  \n",
       "684057     3.034710   3.892887   2.542773  \n",
       "684059     2.668278   3.869515   2.719021  \n",
       "\n",
       "[5 rows x 16244 columns]"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ed07e3a2-e543-4106-81e9-9978ebffa674",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>ENTREZID</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "      <th>14</th>\n",
       "      <th>15</th>\n",
       "      <th>16</th>\n",
       "      <th>...</th>\n",
       "      <th>101060321</th>\n",
       "      <th>101340250</th>\n",
       "      <th>101340251</th>\n",
       "      <th>101340252</th>\n",
       "      <th>102723547</th>\n",
       "      <th>102724473</th>\n",
       "      <th>103091865</th>\n",
       "      <th>105375355</th>\n",
       "      <th>109623460</th>\n",
       "      <th>109731405</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>X-1027</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X-1119</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X-1156</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>...</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X-1167</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>X-1172</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 23271 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "ENTREZID  1          2          3          9          10         12         \\\n",
       "X-1027            0          0          0          0          0          0   \n",
       "X-1119            0          0          0          0          0          0   \n",
       "X-1156            1          1          1         -1         -1         -1   \n",
       "X-1167            0          0          0          0          0          0   \n",
       "X-1172            0          1          1         -1         -1          1   \n",
       "\n",
       "ENTREZID  13         14         15         16         ...  101060321  \\\n",
       "X-1027            0          0          0          0  ...          0   \n",
       "X-1119            0          0          0          0  ...          0   \n",
       "X-1156            1          1         -1         -1  ...         -1   \n",
       "X-1167            0          0          0          0  ...          0   \n",
       "X-1172            1          1          1          0  ...          1   \n",
       "\n",
       "ENTREZID  101340250  101340251  101340252  102723547  102724473  103091865  \\\n",
       "X-1027            0          0          0          0          0          0   \n",
       "X-1119            0          0          0          0          0          0   \n",
       "X-1156           -1         -1          1          0         -1         -1   \n",
       "X-1167            0          0          0          0          0          0   \n",
       "X-1172            1          1         -1         -1          1         -1   \n",
       "\n",
       "ENTREZID  105375355  109623460  109731405  \n",
       "X-1027            0          0          0  \n",
       "X-1119            1          0          0  \n",
       "X-1156            0         -1         -1  \n",
       "X-1167            0          0          0  \n",
       "X-1172            1         -1          0  \n",
       "\n",
       "[5 rows x 23271 columns]"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDXC.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "85999da0-c0e4-47de-ad5a-b65b9407c57a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "PDXC.isna().sum().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "e42ac8a1-fc17-42e8-bd3d-2e744b74e125",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDXC = PDXC.fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "eec065a6-85ff-4104-b337-707666d19649",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDXC[PDXC != 0.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "664ea8dc-e49c-47c3-bbac-bc9061898de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDXC = PDXC.fillna(0)\n",
    "PDXC[PDXC != 0.0] = 1\n",
    "PDXM = PDXM.fillna(0)\n",
    "PDXM[PDXM != 0.0] = 1\n",
    "GDSCM = GDSCM.fillna(0)\n",
    "GDSCM[GDSCM != 0.0] = 1\n",
    "GDSCC = GDSCC.fillna(0)\n",
    "GDSCC[GDSCC != 0.0] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "48c919d9-283c-4d25-b42a-5632e813a09f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([        1,         2,         9,        10,        12,        13,\n",
       "                   14,        15,        16,        18,\n",
       "            ...\n",
       "            100506548, 100507117, 100507254, 100507436, 100507472, 100527978,\n",
       "            100532746, 100820829, 102724473, 105375355],\n",
       "           dtype='int64', name='ENTREZID', length=16244)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "f14746d9-8f75-45bb-8ccb-bb32344b9e1b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([        1,         2,         9,        10,        12,        13,\n",
       "                   14,        15,        16,        18,\n",
       "            ...\n",
       "            101060321, 101927546, 101927722, 101928638, 102724473, 102724928,\n",
       "            105375355, 105378803, 107403068, 109731405],\n",
       "           dtype='int64', length=18421)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCM.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "21ac59f2-c7e7-431b-adff-557dd00227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = GDSCE.columns.intersection(GDSCM.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "691e80d1-d1c3-4387-b5e5-2681d9b3c8d2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([        1,         2,         9,        10,        12,        13,\n",
       "                   14,        15,        16,        18,\n",
       "            ...\n",
       "            100188893, 100190949, 100271715, 100289635, 100423062, 100505929,\n",
       "            100506144, 100507436, 102724473, 105375355],\n",
       "           dtype='int64', length=15633)"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d4099d5f-1057-4657-b93a-92dcfcb9440e",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = ls.intersection(GDSCC.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "8305639e-25f4-4806-8a65-2211649e8092",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([        1,         2,         9,        10,        12,        13,\n",
       "                   14,        15,        16,        18,\n",
       "            ...\n",
       "            100170765, 100188893, 100190949, 100271715, 100289635, 100423062,\n",
       "            100505929, 100507436, 102724473, 105375355],\n",
       "           dtype='int64', length=15563)"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "beed3438-7a6c-480f-b8fb-5ecf6585eae7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Int64Index([        1,         2,         9,        10,        12,        13,\n",
       "                   14,        15,        16,        18,\n",
       "            ...\n",
       "            100507206, 100507254, 100507436, 100507472, 100526773, 100527978,\n",
       "            100532746, 100820829, 102724473, 105375355],\n",
       "           dtype='int64', name='ENTREZID', length=18232)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(PDXE.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ce07164b-7a72-4b57-bc6c-af18df1a5218",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls = GDSCE.columns.intersection(GDSCM.columns)\n",
    "ls = ls.intersection(GDSCC.columns)\n",
    "ls = ls.intersection(PDXE.columns)\n",
    "ls = ls.intersection(PDXM.columns)\n",
    "ls = ls.intersection(PDXC.columns)\n",
    "ls2 = GDSCE.index.intersection(GDSCM.index)\n",
    "ls2 = ls2.intersection(GDSCC.index)\n",
    "ls3 = PDXE.index.intersection(PDXM.index)\n",
    "ls3 = ls3.intersection(PDXC.index)\n",
    "ls = pd.unique(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "566a0001-3260-4e26-a79e-0394c4baecf7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(13348,)"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "32cc2e40-6d55-475f-94e5-a944c375b8b8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856,)"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls2.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "86c08f60-df05-4c8f-abc3-50ef324d782a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(60,)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ls3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "9993581c-b8d6-4651-8627-546748d3c3cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "13348"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(ls)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "c7fe82f5-28d5-43f9-a111-14687b477d0c",
   "metadata": {},
   "outputs": [],
   "source": [
    "PDXE = PDXE.loc[ls3,ls]\n",
    "PDXM = PDXM.loc[ls3,ls]\n",
    "PDXC = PDXC.loc[ls3,ls]\n",
    "GDSCE = GDSCE.loc[ls2,ls]\n",
    "GDSCM = GDSCM.loc[ls2,ls]\n",
    "GDSCC = GDSCC.loc[ls2,ls]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "2fea8369-c93d-4810-99fb-43579b252c38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(856, 13348)\n",
      "(856, 13348)\n",
      "(856, 13348)\n"
     ]
    }
   ],
   "source": [
    "print(GDSCE.shape)\n",
    "print(GDSCM.shape)\n",
    "print(GDSCC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "6b1c087c-6353-4224-acf2-3d5b2743c5c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(60, 13348)\n",
      "(60, 13348)\n",
      "(60, 13348)\n"
     ]
    }
   ],
   "source": [
    "print(PDXE.shape)\n",
    "print(PDXM.shape)\n",
    "print(PDXC.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eeb1096-ca79-4cd8-b8d2-8094f5e55cc2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response</th>\n",
       "      <th>logIC50</th>\n",
       "      <th>drug</th>\n",
       "      <th>exprs</th>\n",
       "      <th>CNA</th>\n",
       "      <th>mutations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>R</td>\n",
       "      <td>6.29444657935625</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>R</td>\n",
       "      <td>6.3873236983719</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>S</td>\n",
       "      <td>4.9521245559495</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>R</td>\n",
       "      <td>6.3935613853243</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>R</td>\n",
       "      <td>5.9189028381580595</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1659823</th>\n",
       "      <td>R</td>\n",
       "      <td>5.956999885891481</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660034</th>\n",
       "      <td>R</td>\n",
       "      <td>5.76380890614975</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660035</th>\n",
       "      <td>R</td>\n",
       "      <td>6.90606210542992</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1660036</th>\n",
       "      <td>R</td>\n",
       "      <td>6.967316136884709</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1674021</th>\n",
       "      <td>R</td>\n",
       "      <td>6.97473174625189</td>\n",
       "      <td>Cetuximab</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>856 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        response             logIC50       drug  exprs  CNA  mutations\n",
       "683665         R    6.29444657935625  Cetuximab      1    1          1\n",
       "684052         R     6.3873236983719  Cetuximab      1    1          1\n",
       "684055         S     4.9521245559495  Cetuximab      1    1          1\n",
       "684057         R     6.3935613853243  Cetuximab      1    1          1\n",
       "684059         R  5.9189028381580595  Cetuximab      1    1          1\n",
       "...          ...                 ...        ...    ...  ...        ...\n",
       "1659823        R   5.956999885891481  Cetuximab      1    1          1\n",
       "1660034        R    5.76380890614975  Cetuximab      1    1          1\n",
       "1660035        R    6.90606210542992  Cetuximab      1    1          1\n",
       "1660036        R   6.967316136884709  Cetuximab      1    1          1\n",
       "1674021        R    6.97473174625189  Cetuximab      1    1          1\n",
       "\n",
       "[856 rows x 6 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCR.loc[ls2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "0b089c01-548d-4d64-b4f2-4aab5127b6f4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# GDSCR.loc[GDSCR.iloc[:,0] == 'R'] = 0\n",
    "# GDSCR.loc[GDSCR.iloc[:,0] == 'S'] = 1\n",
    "# GDSCR.columns = ['targets']\n",
    "# GDSCR = GDSCR.loc[ls2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "42457d09-8005-4682-a926-5252f36b4955",
   "metadata": {},
   "outputs": [],
   "source": [
    "GDSCR.loc[GDSCR.iloc[:,0] == 'R'] = 0\n",
    "GDSCR.loc[GDSCR.iloc[:,0] == 'S'] = 1\n",
    "GDSCR.columns = ['targets', 'target', 'target', 'target', 'target', 'target']\n",
    "GDSCR = GDSCR.loc[ls2,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "b057a382-8db6-421b-add4-a59a5ada5c75",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>targets</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "      <th>target</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>683665</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684052</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684055</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684057</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>684059</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       targets  target  target  target  target  target\n",
       "683665       0       0       0       0       0       0\n",
       "684052       0       0       0       0       0       0\n",
       "684055       1       1       1       1       1       1\n",
       "684057       0       0       0       0       0       0\n",
       "684059       0       0       0       0       0       0"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCR.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "da48f7ef-9a59-49c9-ab94-fedaf0834920",
   "metadata": {},
   "outputs": [],
   "source": [
    "ls_mb_size = [14, 30, 64]\n",
    "ls_h_dim = [1024, 512, 256, 128, 64]\n",
    "ls_marg = [0.5, 1, 1.5, 2, 2.5]\n",
    "ls_lr = [0.0005, 0.0001, 0.005, 0.001]\n",
    "ls_epoch = [20, 50, 10, 15, 30, 40, 60, 70, 80, 90, 100]\n",
    "ls_rate = [0.3, 0.4, 0.5, 0.6, 0.7, 0.8]\n",
    "ls_wd = [0.01, 0.001, 0.1, 0.0001]\n",
    "ls_lam = [0.1, 0.2, 0.3, 0.4, 0.5, 0.6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "05c3a75d-bb79-473d-8630-45c34886d0ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[3.56775873, 3.44439014, 7.41019589, ..., 5.85058879, 5.57267804,\n",
       "        2.96009738],\n",
       "       [4.03164707, 3.11987584, 5.3488438 , ..., 7.65315471, 3.8654164 ,\n",
       "        2.37416136],\n",
       "       [5.42295082, 3.28938844, 6.26693971, ..., 5.78060951, 3.81278384,\n",
       "        2.6557783 ],\n",
       "       ...,\n",
       "       [2.70806456, 3.14862421, 5.94831572, ..., 7.0695774 , 3.78244484,\n",
       "        2.82115151],\n",
       "       [2.91275768, 3.17798918, 8.17174068, ..., 8.34340214, 3.73778225,\n",
       "        2.84997499],\n",
       "       [2.70695449, 2.92070173, 5.37992093, ..., 8.55308982, 4.03446832,\n",
       "        2.88364658]])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "500227d9-f802-4b6d-a8d3-a05fa2091200",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = GDSCR['targets'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "8a5bcbd3-24c4-4e8a-9934-a1843eb6e773",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(GDSCE.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "5fd44821-a56c-4cd9-8890-b53fa224a399",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(856, 13348)"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "GDSCE.values.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "54f8813d-ed94-497e-aee5-c594a19f3561",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y = Y.astype('int64')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "50a0aaab-a784-4e1b-89c8-5280bc1c9caf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.int64"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(Y[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "8b016f20-4d8b-4a9c-ba65-920f5ff3e4bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, random_state = 42, shuffle = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "c71b28a3-be72-4abd-a698-18002ec9a26c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iter-0; Total loss: 0.7931\n",
      "Iter-1; Total loss: 0.5894\n",
      "Iter-2; Total loss: 0.7836\n",
      "Iter-3; Total loss: 0.5647\n",
      "Iter-4; Total loss: 0.5803\n",
      "Iter-5; Total loss: 0.5458\n",
      "Iter-6; Total loss: 0.4745\n",
      "Iter-7; Total loss: 0.5246\n",
      "Iter-8; Total loss: 0.6285\n",
      "Iter-9; Total loss: 0.5642\n",
      "Iter-10; Total loss: 0.4527\n",
      "Iter-11; Total loss: 0.5573\n",
      "Iter-12; Total loss: 0.4938\n",
      "Iter-13; Total loss: 0.5872\n",
      "Iter-14; Total loss: 0.54\n",
      "Iter-15; Total loss: 0.5664\n",
      "Iter-16; Total loss: 0.4352\n",
      "Iter-17; Total loss: 0.5798\n",
      "Iter-18; Total loss: 0.6429\n",
      "Iter-19; Total loss: 0.5269\n",
      "Iter-20; Total loss: 0.4593\n",
      "Iter-21; Total loss: 0.4236\n",
      "Iter-22; Total loss: 0.4236\n",
      "Iter-23; Total loss: 0.5849\n",
      "Iter-24; Total loss: 0.388\n",
      "Iter-25; Total loss: 0.5299\n",
      "Iter-26; Total loss: 0.2637\n",
      "Iter-27; Total loss: 0.5013\n",
      "Iter-28; Total loss: 0.5524\n",
      "Iter-29; Total loss: 0.538\n",
      "Iter-30; Total loss: 0.615\n",
      "Iter-31; Total loss: 0.4415\n",
      "Iter-32; Total loss: 0.4788\n",
      "Iter-33; Total loss: 0.4949\n",
      "Iter-34; Total loss: 0.5201\n",
      "Iter-35; Total loss: 0.3675\n",
      "Iter-36; Total loss: 0.4172\n",
      "Iter-37; Total loss: 0.4963\n",
      "Iter-38; Total loss: 0.6098\n",
      "Iter-39; Total loss: 0.4951\n",
      "Iter-40; Total loss: 0.5468\n",
      "Iter-41; Total loss: 0.4623\n",
      "Iter-42; Total loss: 0.4604\n",
      "Iter-43; Total loss: 0.4083\n",
      "Iter-44; Total loss: 0.3338\n",
      "Iter-45; Total loss: 0.3262\n",
      "Iter-46; Total loss: 0.3441\n",
      "Iter-47; Total loss: 0.3941\n",
      "Iter-48; Total loss: 0.4169\n",
      "Iter-49; Total loss: 0.4265\n",
      "Iter-50; Total loss: 0.5078\n",
      "Iter-51; Total loss: 0.4782\n",
      "Iter-52; Total loss: 0.5182\n",
      "Iter-53; Total loss: 0.5306\n",
      "Iter-54; Total loss: 0.2225\n",
      "Iter-55; Total loss: 0.4158\n",
      "Iter-56; Total loss: 0.422\n",
      "Iter-57; Total loss: 0.4289\n",
      "Iter-58; Total loss: 0.5637\n",
      "Iter-59; Total loss: 0.3368\n",
      "Iter-60; Total loss: 0.3866\n",
      "Iter-61; Total loss: 0.3217\n",
      "Iter-62; Total loss: 0.5015\n",
      "Iter-63; Total loss: 0.4563\n",
      "Iter-64; Total loss: 0.3923\n",
      "Iter-65; Total loss: 0.5049\n",
      "Iter-66; Total loss: 0.5326\n",
      "Iter-67; Total loss: 0.4314\n",
      "Iter-68; Total loss: 0.3742\n",
      "Iter-69; Total loss: 0.5316\n",
      "Iter-0; Total loss: 0.6716\n",
      "Iter-1; Total loss: 0.6189\n",
      "Iter-2; Total loss: 0.6479\n",
      "Iter-3; Total loss: 0.7552\n",
      "Iter-4; Total loss: 0.5111\n",
      "Iter-5; Total loss: 0.5353\n",
      "Iter-6; Total loss: 0.5265\n",
      "Iter-7; Total loss: 0.529\n",
      "Iter-8; Total loss: 0.5964\n",
      "Iter-9; Total loss: 0.4952\n",
      "Iter-10; Total loss: 0.3979\n",
      "Iter-11; Total loss: 0.3855\n",
      "Iter-12; Total loss: 0.5537\n",
      "Iter-13; Total loss: 0.516\n",
      "Iter-14; Total loss: 0.5529\n",
      "Iter-15; Total loss: 0.4594\n",
      "Iter-16; Total loss: 0.5084\n",
      "Iter-17; Total loss: 0.4085\n",
      "Iter-18; Total loss: 0.5081\n",
      "Iter-19; Total loss: 0.455\n",
      "Iter-20; Total loss: 0.392\n",
      "Iter-21; Total loss: 0.5088\n",
      "Iter-22; Total loss: 0.4902\n",
      "Iter-23; Total loss: 0.442\n",
      "Iter-24; Total loss: 0.5131\n",
      "Iter-25; Total loss: 0.4239\n",
      "Iter-26; Total loss: 0.5674\n",
      "Iter-27; Total loss: 0.3865\n",
      "Iter-28; Total loss: 0.5223\n",
      "Iter-29; Total loss: 0.4729\n",
      "Iter-30; Total loss: 0.5519\n",
      "Iter-31; Total loss: 0.4896\n",
      "Iter-32; Total loss: 0.4386\n",
      "Iter-33; Total loss: 0.4092\n",
      "Iter-34; Total loss: 0.5311\n",
      "Iter-35; Total loss: 0.4158\n",
      "Iter-36; Total loss: 0.4146\n",
      "Iter-37; Total loss: 0.4613\n",
      "Iter-38; Total loss: 0.4328\n",
      "Iter-39; Total loss: 0.354\n",
      "Iter-40; Total loss: 0.4973\n",
      "Iter-41; Total loss: 0.4832\n",
      "Iter-42; Total loss: 0.5004\n",
      "Iter-43; Total loss: 0.3886\n",
      "Iter-44; Total loss: 0.4329\n",
      "Iter-45; Total loss: 0.4394\n",
      "Iter-46; Total loss: 0.496\n",
      "Iter-47; Total loss: 0.6189\n",
      "Iter-48; Total loss: 0.6106\n",
      "Iter-49; Total loss: 0.425\n",
      "Iter-50; Total loss: 0.4585\n",
      "Iter-51; Total loss: 0.4536\n",
      "Iter-52; Total loss: 0.3806\n",
      "Iter-53; Total loss: 0.5165\n",
      "Iter-54; Total loss: 0.552\n",
      "Iter-55; Total loss: 0.429\n",
      "Iter-56; Total loss: 0.4573\n",
      "Iter-57; Total loss: 0.5078\n",
      "Iter-58; Total loss: 0.4619\n",
      "Iter-59; Total loss: 0.5148\n",
      "Iter-60; Total loss: 0.5199\n",
      "Iter-61; Total loss: 0.5712\n",
      "Iter-62; Total loss: 0.4833\n",
      "Iter-63; Total loss: 0.4556\n",
      "Iter-64; Total loss: 0.4416\n",
      "Iter-65; Total loss: 0.5574\n",
      "Iter-66; Total loss: 0.4972\n",
      "Iter-67; Total loss: 0.3425\n",
      "Iter-68; Total loss: 0.4538\n",
      "Iter-69; Total loss: 0.4584\n",
      "Iter-0; Total loss: 0.9168\n",
      "Iter-1; Total loss: 0.7719\n",
      "Iter-2; Total loss: 0.6581\n",
      "Iter-3; Total loss: 0.6969\n",
      "Iter-4; Total loss: 0.544\n",
      "Iter-5; Total loss: 0.5698\n",
      "Iter-6; Total loss: 0.7211\n",
      "Iter-7; Total loss: 0.5912\n",
      "Iter-8; Total loss: 0.5294\n",
      "Iter-9; Total loss: 0.4749\n",
      "Iter-10; Total loss: 0.6179\n",
      "Iter-11; Total loss: 0.5483\n",
      "Iter-12; Total loss: 0.536\n",
      "Iter-13; Total loss: 0.605\n",
      "Iter-14; Total loss: 0.4893\n",
      "Iter-15; Total loss: 0.4972\n",
      "Iter-16; Total loss: 0.4337\n",
      "Iter-17; Total loss: 0.4478\n",
      "Iter-18; Total loss: 0.4608\n",
      "Iter-19; Total loss: 0.5579\n",
      "Iter-20; Total loss: 0.3568\n",
      "Iter-21; Total loss: 0.3791\n",
      "Iter-22; Total loss: 0.4595\n",
      "Iter-23; Total loss: 0.4553\n",
      "Iter-24; Total loss: 0.3872\n",
      "Iter-25; Total loss: 0.5854\n",
      "Iter-26; Total loss: 0.3747\n",
      "Iter-27; Total loss: 0.3466\n",
      "Iter-28; Total loss: 0.4154\n",
      "Iter-29; Total loss: 0.4815\n",
      "Iter-30; Total loss: 0.4241\n",
      "Iter-31; Total loss: 0.4858\n",
      "Iter-32; Total loss: 0.5616\n",
      "Iter-33; Total loss: 0.5053\n",
      "Iter-34; Total loss: 0.4665\n",
      "Iter-35; Total loss: 0.5494\n",
      "Iter-36; Total loss: 0.4605\n",
      "Iter-37; Total loss: 0.4318\n",
      "Iter-38; Total loss: 0.5517\n",
      "Iter-39; Total loss: 0.6006\n",
      "Iter-40; Total loss: 0.4981\n",
      "Iter-41; Total loss: 0.3962\n",
      "Iter-42; Total loss: 0.5187\n",
      "Iter-43; Total loss: 0.4736\n",
      "Iter-44; Total loss: 0.4504\n",
      "Iter-45; Total loss: 0.4111\n",
      "Iter-46; Total loss: 0.4757\n",
      "Iter-47; Total loss: 0.4907\n",
      "Iter-48; Total loss: 0.4907\n",
      "Iter-49; Total loss: 0.5222\n",
      "Iter-50; Total loss: 0.5074\n",
      "Iter-51; Total loss: 0.4951\n",
      "Iter-52; Total loss: 0.52\n",
      "Iter-53; Total loss: 0.5375\n",
      "Iter-54; Total loss: 0.3694\n",
      "Iter-55; Total loss: 0.3298\n",
      "Iter-56; Total loss: 0.5354\n",
      "Iter-57; Total loss: 0.4947\n",
      "Iter-58; Total loss: 0.3788\n",
      "Iter-59; Total loss: 0.4427\n",
      "Iter-60; Total loss: 0.3818\n",
      "Iter-61; Total loss: 0.512\n",
      "Iter-62; Total loss: 0.3735\n",
      "Iter-63; Total loss: 0.4868\n",
      "Iter-64; Total loss: 0.5756\n",
      "Iter-65; Total loss: 0.4414\n",
      "Iter-66; Total loss: 0.4283\n",
      "Iter-67; Total loss: 0.457\n",
      "Iter-68; Total loss: 0.328\n",
      "Iter-69; Total loss: 0.4826\n",
      "Iter-0; Total loss: 0.9003\n",
      "Iter-1; Total loss: 0.8419\n",
      "Iter-2; Total loss: 0.7505\n",
      "Iter-3; Total loss: 0.5607\n",
      "Iter-4; Total loss: 0.5962\n",
      "Iter-5; Total loss: 0.5266\n",
      "Iter-6; Total loss: 0.6449\n",
      "Iter-7; Total loss: 0.534\n",
      "Iter-8; Total loss: 0.4785\n",
      "Iter-9; Total loss: 0.4642\n",
      "Iter-10; Total loss: 0.4699\n",
      "Iter-11; Total loss: 0.6199\n",
      "Iter-12; Total loss: 0.5602\n",
      "Iter-13; Total loss: 0.4732\n",
      "Iter-14; Total loss: 0.577\n",
      "Iter-15; Total loss: 0.4143\n",
      "Iter-16; Total loss: 0.4082\n",
      "Iter-17; Total loss: 0.4428\n",
      "Iter-18; Total loss: 0.496\n",
      "Iter-19; Total loss: 0.4813\n",
      "Iter-20; Total loss: 0.4901\n",
      "Iter-21; Total loss: 0.508\n",
      "Iter-22; Total loss: 0.5662\n",
      "Iter-23; Total loss: 0.4494\n",
      "Iter-24; Total loss: 0.4335\n",
      "Iter-25; Total loss: 0.5164\n",
      "Iter-26; Total loss: 0.3761\n",
      "Iter-27; Total loss: 0.5256\n",
      "Iter-28; Total loss: 0.3402\n",
      "Iter-29; Total loss: 0.515\n",
      "Iter-30; Total loss: 0.4329\n",
      "Iter-31; Total loss: 0.4862\n",
      "Iter-32; Total loss: 0.4273\n",
      "Iter-33; Total loss: 0.4391\n",
      "Iter-34; Total loss: 0.4743\n",
      "Iter-35; Total loss: 0.5702\n",
      "Iter-36; Total loss: 0.5185\n",
      "Iter-37; Total loss: 0.4531\n",
      "Iter-38; Total loss: 0.4075\n",
      "Iter-39; Total loss: 0.2561\n",
      "Iter-40; Total loss: 0.3855\n",
      "Iter-41; Total loss: 0.4489\n",
      "Iter-42; Total loss: 0.4612\n",
      "Iter-43; Total loss: 0.5028\n",
      "Iter-44; Total loss: 0.4408\n",
      "Iter-45; Total loss: 0.577\n",
      "Iter-46; Total loss: 0.4639\n",
      "Iter-47; Total loss: 0.4552\n",
      "Iter-48; Total loss: 0.5056\n",
      "Iter-49; Total loss: 0.4122\n",
      "Iter-50; Total loss: 0.4022\n",
      "Iter-51; Total loss: 0.3295\n",
      "Iter-52; Total loss: 0.4274\n",
      "Iter-53; Total loss: 0.3932\n",
      "Iter-54; Total loss: 0.4639\n",
      "Iter-55; Total loss: 0.4323\n",
      "Iter-56; Total loss: 0.4271\n",
      "Iter-57; Total loss: 0.488\n",
      "Iter-58; Total loss: 0.3774\n",
      "Iter-59; Total loss: 0.446\n",
      "Iter-60; Total loss: 0.3374\n",
      "Iter-61; Total loss: 0.3236\n",
      "Iter-62; Total loss: 0.5613\n",
      "Iter-63; Total loss: 0.3043\n",
      "Iter-64; Total loss: 0.4757\n",
      "Iter-65; Total loss: 0.4255\n",
      "Iter-66; Total loss: 0.4969\n",
      "Iter-67; Total loss: 0.4356\n",
      "Iter-68; Total loss: 0.5233\n",
      "Iter-69; Total loss: 0.4225\n",
      "Iter-0; Total loss: 0.8041\n",
      "Iter-1; Total loss: 0.5873\n",
      "Iter-2; Total loss: 0.617\n",
      "Iter-3; Total loss: 0.6655\n",
      "Iter-4; Total loss: 0.6156\n",
      "Iter-5; Total loss: 0.7148\n",
      "Iter-6; Total loss: 0.4356\n",
      "Iter-7; Total loss: 0.7174\n",
      "Iter-8; Total loss: 0.4822\n",
      "Iter-9; Total loss: 0.4361\n",
      "Iter-10; Total loss: 0.5073\n",
      "Iter-11; Total loss: 0.5802\n",
      "Iter-12; Total loss: 0.357\n",
      "Iter-13; Total loss: 0.5339\n",
      "Iter-14; Total loss: 0.5289\n",
      "Iter-15; Total loss: 0.5914\n",
      "Iter-16; Total loss: 0.4898\n",
      "Iter-17; Total loss: 0.4759\n",
      "Iter-18; Total loss: 0.5594\n",
      "Iter-19; Total loss: 0.4366\n",
      "Iter-20; Total loss: 0.4464\n",
      "Iter-21; Total loss: 0.4554\n",
      "Iter-22; Total loss: 0.3978\n",
      "Iter-23; Total loss: 0.5355\n",
      "Iter-24; Total loss: 0.5522\n",
      "Iter-25; Total loss: 0.4833\n",
      "Iter-26; Total loss: 0.3553\n",
      "Iter-27; Total loss: 0.4626\n",
      "Iter-28; Total loss: 0.5496\n",
      "Iter-29; Total loss: 0.368\n",
      "Iter-30; Total loss: 0.38\n",
      "Iter-31; Total loss: 0.5202\n",
      "Iter-32; Total loss: 0.4792\n",
      "Iter-33; Total loss: 0.4961\n",
      "Iter-34; Total loss: 0.5098\n",
      "Iter-35; Total loss: 0.4165\n",
      "Iter-36; Total loss: 0.5027\n",
      "Iter-37; Total loss: 0.4553\n",
      "Iter-38; Total loss: 0.4495\n",
      "Iter-39; Total loss: 0.4278\n",
      "Iter-40; Total loss: 0.4401\n",
      "Iter-41; Total loss: 0.4225\n",
      "Iter-42; Total loss: 0.3834\n",
      "Iter-43; Total loss: 0.4057\n",
      "Iter-44; Total loss: 0.3824\n",
      "Iter-45; Total loss: 0.549\n",
      "Iter-46; Total loss: 0.5554\n",
      "Iter-47; Total loss: 0.4072\n",
      "Iter-48; Total loss: 0.4309\n",
      "Iter-49; Total loss: 0.5478\n",
      "Iter-50; Total loss: 0.403\n",
      "Iter-51; Total loss: 0.4466\n",
      "Iter-52; Total loss: 0.3936\n",
      "Iter-53; Total loss: 0.5887\n",
      "Iter-54; Total loss: 0.4807\n",
      "Iter-55; Total loss: 0.44\n",
      "Iter-56; Total loss: 0.523\n",
      "Iter-57; Total loss: 0.4677\n",
      "Iter-58; Total loss: 0.398\n",
      "Iter-59; Total loss: 0.4331\n",
      "Iter-60; Total loss: 0.36\n",
      "Iter-61; Total loss: 0.4861\n",
      "Iter-62; Total loss: 0.3121\n",
      "Iter-63; Total loss: 0.3999\n",
      "Iter-64; Total loss: 0.4907\n",
      "Iter-65; Total loss: 0.457\n",
      "Iter-66; Total loss: 0.4601\n",
      "Iter-67; Total loss: 0.5013\n",
      "Iter-68; Total loss: 0.4549\n",
      "Iter-69; Total loss: 0.5298\n",
      "Iter-0; Total loss: 1.402\n",
      "Iter-1; Total loss: 1.118\n",
      "Iter-2; Total loss: 1.1\n",
      "Iter-3; Total loss: 1.175\n",
      "Iter-4; Total loss: 1.163\n",
      "Iter-5; Total loss: 1.044\n",
      "Iter-6; Total loss: 0.9897\n",
      "Iter-7; Total loss: 1.078\n",
      "Iter-8; Total loss: 0.9905\n",
      "Iter-9; Total loss: 1.04\n",
      "Iter-10; Total loss: 1.131\n",
      "Iter-11; Total loss: 1.067\n",
      "Iter-12; Total loss: 0.9737\n",
      "Iter-13; Total loss: 0.9842\n",
      "Iter-14; Total loss: 1.006\n",
      "Iter-15; Total loss: 0.9812\n",
      "Iter-16; Total loss: 0.9762\n",
      "Iter-17; Total loss: 0.79\n",
      "Iter-18; Total loss: 0.9171\n",
      "Iter-19; Total loss: 0.9374\n",
      "Iter-0; Total loss: 1.145\n",
      "Iter-1; Total loss: 1.121\n",
      "Iter-2; Total loss: 1.076\n",
      "Iter-3; Total loss: 0.9541\n",
      "Iter-4; Total loss: 1.109\n",
      "Iter-5; Total loss: 1.151\n",
      "Iter-6; Total loss: 1.096\n",
      "Iter-7; Total loss: 1.065\n",
      "Iter-8; Total loss: 1.076\n",
      "Iter-9; Total loss: 1.094\n",
      "Iter-10; Total loss: 0.9009\n",
      "Iter-11; Total loss: 0.9606\n",
      "Iter-12; Total loss: 1.058\n",
      "Iter-13; Total loss: 1.045\n",
      "Iter-14; Total loss: 0.9691\n",
      "Iter-15; Total loss: 0.9059\n",
      "Iter-16; Total loss: 0.9876\n",
      "Iter-17; Total loss: 0.9647\n",
      "Iter-18; Total loss: 1.006\n",
      "Iter-19; Total loss: 1.037\n",
      "Iter-0; Total loss: 1.259\n",
      "Iter-1; Total loss: 1.132\n",
      "Iter-2; Total loss: 1.075\n",
      "Iter-3; Total loss: 0.9909\n",
      "Iter-4; Total loss: 1.181\n",
      "Iter-5; Total loss: 1.083\n",
      "Iter-6; Total loss: 0.974\n",
      "Iter-7; Total loss: 0.9939\n",
      "Iter-8; Total loss: 1.149\n",
      "Iter-9; Total loss: 1.032\n",
      "Iter-10; Total loss: 0.9094\n",
      "Iter-11; Total loss: 1.082\n",
      "Iter-12; Total loss: 1.034\n",
      "Iter-13; Total loss: 0.8872\n",
      "Iter-14; Total loss: 0.9702\n",
      "Iter-15; Total loss: 0.9771\n",
      "Iter-16; Total loss: 0.8899\n",
      "Iter-17; Total loss: 0.8834\n",
      "Iter-18; Total loss: 0.7335\n",
      "Iter-19; Total loss: 0.6446\n",
      "Iter-0; Total loss: 1.128\n",
      "Iter-1; Total loss: 1.081\n",
      "Iter-2; Total loss: 1.198\n",
      "Iter-3; Total loss: 1.162\n",
      "Iter-4; Total loss: 1.075\n",
      "Iter-5; Total loss: 1.083\n",
      "Iter-6; Total loss: 1.11\n",
      "Iter-7; Total loss: 0.9488\n",
      "Iter-8; Total loss: 1.03\n",
      "Iter-9; Total loss: 0.8585\n",
      "Iter-10; Total loss: 1.008\n",
      "Iter-11; Total loss: 1.07\n",
      "Iter-12; Total loss: 0.9959\n",
      "Iter-13; Total loss: 1.01\n",
      "Iter-14; Total loss: 0.9421\n",
      "Iter-15; Total loss: 1.07\n",
      "Iter-16; Total loss: 0.9492\n",
      "Iter-17; Total loss: 0.8777\n",
      "Iter-18; Total loss: 0.9512\n",
      "Iter-19; Total loss: 0.84\n",
      "Iter-0; Total loss: 1.175\n",
      "Iter-1; Total loss: 1.221\n",
      "Iter-2; Total loss: 1.18\n",
      "Iter-3; Total loss: 1.135\n",
      "Iter-4; Total loss: 1.04\n",
      "Iter-5; Total loss: 1.021\n",
      "Iter-6; Total loss: 1.095\n",
      "Iter-7; Total loss: 0.9269\n",
      "Iter-8; Total loss: 0.9496\n",
      "Iter-9; Total loss: 1.035\n",
      "Iter-10; Total loss: 0.856\n",
      "Iter-11; Total loss: 1.063\n",
      "Iter-12; Total loss: 0.9838\n",
      "Iter-13; Total loss: 0.9272\n",
      "Iter-14; Total loss: 0.8626\n",
      "Iter-15; Total loss: 0.9714\n",
      "Iter-16; Total loss: 1.038\n",
      "Iter-17; Total loss: 1.05\n",
      "Iter-18; Total loss: 0.934\n",
      "Iter-19; Total loss: 1.062\n",
      "Iter-0; Total loss: 1.804\n",
      "Iter-1; Total loss: 1.594\n",
      "Iter-2; Total loss: 1.587\n",
      "Iter-3; Total loss: 1.812\n",
      "Iter-4; Total loss: 1.508\n",
      "Iter-5; Total loss: 1.362\n",
      "Iter-6; Total loss: 1.254\n",
      "Iter-7; Total loss: 1.418\n",
      "Iter-8; Total loss: 1.491\n",
      "Iter-9; Total loss: 1.251\n",
      "Iter-10; Total loss: 1.178\n",
      "Iter-11; Total loss: 1.32\n",
      "Iter-12; Total loss: 1.385\n",
      "Iter-13; Total loss: 1.278\n",
      "Iter-14; Total loss: 1.08\n",
      "Iter-15; Total loss: 1.285\n",
      "Iter-16; Total loss: 1.293\n",
      "Iter-17; Total loss: 1.142\n",
      "Iter-18; Total loss: 1.122\n",
      "Iter-19; Total loss: 1.22\n",
      "Iter-20; Total loss: 1.129\n",
      "Iter-21; Total loss: 1.17\n",
      "Iter-22; Total loss: 1.03\n",
      "Iter-23; Total loss: 0.9054\n",
      "Iter-24; Total loss: 1.021\n",
      "Iter-25; Total loss: 0.9914\n",
      "Iter-26; Total loss: 1.084\n",
      "Iter-27; Total loss: 1.009\n",
      "Iter-28; Total loss: 1.023\n",
      "Iter-29; Total loss: 0.878\n",
      "Iter-30; Total loss: 0.9873\n",
      "Iter-31; Total loss: 0.8795\n",
      "Iter-32; Total loss: 0.9208\n",
      "Iter-33; Total loss: 0.8718\n",
      "Iter-34; Total loss: 0.9863\n",
      "Iter-35; Total loss: 0.779\n",
      "Iter-36; Total loss: 1.0\n",
      "Iter-37; Total loss: 0.8833\n",
      "Iter-38; Total loss: 0.8452\n",
      "Iter-39; Total loss: 0.8738\n",
      "Iter-0; Total loss: 1.882\n",
      "Iter-1; Total loss: 1.717\n",
      "Iter-2; Total loss: 1.573\n",
      "Iter-3; Total loss: 1.655\n",
      "Iter-4; Total loss: 1.184\n",
      "Iter-5; Total loss: 1.578\n",
      "Iter-6; Total loss: 1.478\n",
      "Iter-7; Total loss: 1.339\n",
      "Iter-8; Total loss: 1.381\n",
      "Iter-9; Total loss: 1.255\n",
      "Iter-10; Total loss: 1.203\n",
      "Iter-11; Total loss: 1.164\n",
      "Iter-12; Total loss: 1.173\n",
      "Iter-13; Total loss: 1.42\n",
      "Iter-14; Total loss: 1.376\n",
      "Iter-15; Total loss: 1.199\n",
      "Iter-16; Total loss: 1.273\n",
      "Iter-17; Total loss: 1.203\n",
      "Iter-18; Total loss: 1.07\n",
      "Iter-19; Total loss: 1.167\n",
      "Iter-20; Total loss: 0.7942\n",
      "Iter-21; Total loss: 1.099\n",
      "Iter-22; Total loss: 1.137\n",
      "Iter-23; Total loss: 1.095\n",
      "Iter-24; Total loss: 1.178\n",
      "Iter-25; Total loss: 1.01\n",
      "Iter-26; Total loss: 1.287\n",
      "Iter-27; Total loss: 1.033\n",
      "Iter-28; Total loss: 0.983\n",
      "Iter-29; Total loss: 0.9193\n",
      "Iter-30; Total loss: 1.096\n",
      "Iter-31; Total loss: 1.26\n",
      "Iter-32; Total loss: 1.078\n",
      "Iter-33; Total loss: 0.9595\n",
      "Iter-34; Total loss: 0.8226\n",
      "Iter-35; Total loss: 1.153\n",
      "Iter-36; Total loss: 0.9357\n",
      "Iter-37; Total loss: 1.176\n",
      "Iter-38; Total loss: 0.969\n",
      "Iter-39; Total loss: 0.937\n",
      "Iter-0; Total loss: 1.897\n",
      "Iter-1; Total loss: 1.63\n",
      "Iter-2; Total loss: 1.582\n",
      "Iter-3; Total loss: 1.462\n",
      "Iter-4; Total loss: 1.485\n",
      "Iter-5; Total loss: 1.39\n",
      "Iter-6; Total loss: 1.423\n",
      "Iter-7; Total loss: 1.409\n",
      "Iter-8; Total loss: 1.193\n",
      "Iter-9; Total loss: 1.422\n",
      "Iter-10; Total loss: 1.5\n",
      "Iter-11; Total loss: 1.238\n",
      "Iter-12; Total loss: 1.376\n",
      "Iter-13; Total loss: 1.319\n",
      "Iter-14; Total loss: 1.147\n",
      "Iter-15; Total loss: 1.208\n",
      "Iter-16; Total loss: 1.042\n",
      "Iter-17; Total loss: 1.024\n",
      "Iter-18; Total loss: 1.206\n",
      "Iter-19; Total loss: 1.373\n",
      "Iter-20; Total loss: 1.308\n",
      "Iter-21; Total loss: 1.139\n",
      "Iter-22; Total loss: 0.9019\n",
      "Iter-23; Total loss: 1.025\n",
      "Iter-24; Total loss: 1.012\n",
      "Iter-25; Total loss: 1.075\n",
      "Iter-26; Total loss: 1.049\n",
      "Iter-27; Total loss: 0.8709\n",
      "Iter-28; Total loss: 0.9523\n",
      "Iter-29; Total loss: 1.055\n",
      "Iter-30; Total loss: 0.7808\n",
      "Iter-31; Total loss: 0.7693\n",
      "Iter-32; Total loss: 0.9077\n",
      "Iter-33; Total loss: 1.158\n",
      "Iter-34; Total loss: 0.984\n",
      "Iter-35; Total loss: 1.08\n",
      "Iter-36; Total loss: 0.7674\n",
      "Iter-37; Total loss: 0.8902\n",
      "Iter-38; Total loss: 1.121\n",
      "Iter-39; Total loss: 0.7409\n",
      "Iter-0; Total loss: 1.685\n",
      "Iter-1; Total loss: 1.499\n",
      "Iter-2; Total loss: 1.517\n",
      "Iter-3; Total loss: 1.614\n",
      "Iter-4; Total loss: 1.619\n",
      "Iter-5; Total loss: 1.513\n",
      "Iter-6; Total loss: 1.437\n",
      "Iter-7; Total loss: 1.346\n",
      "Iter-8; Total loss: 1.434\n",
      "Iter-9; Total loss: 1.26\n",
      "Iter-10; Total loss: 1.125\n",
      "Iter-11; Total loss: 1.463\n",
      "Iter-12; Total loss: 1.357\n",
      "Iter-13; Total loss: 1.298\n",
      "Iter-14; Total loss: 1.144\n",
      "Iter-15; Total loss: 1.036\n",
      "Iter-16; Total loss: 1.299\n",
      "Iter-17; Total loss: 1.277\n",
      "Iter-18; Total loss: 1.051\n",
      "Iter-19; Total loss: 1.281\n",
      "Iter-20; Total loss: 0.9696\n",
      "Iter-21; Total loss: 0.9989\n",
      "Iter-22; Total loss: 1.058\n",
      "Iter-23; Total loss: 1.055\n",
      "Iter-24; Total loss: 1.06\n",
      "Iter-25; Total loss: 1.034\n",
      "Iter-26; Total loss: 1.03\n",
      "Iter-27; Total loss: 1.226\n",
      "Iter-28; Total loss: 1.309\n",
      "Iter-29; Total loss: 1.157\n",
      "Iter-30; Total loss: 1.098\n",
      "Iter-31; Total loss: 1.172\n",
      "Iter-32; Total loss: 0.9508\n",
      "Iter-33; Total loss: 1.089\n",
      "Iter-34; Total loss: 0.8235\n",
      "Iter-35; Total loss: 1.155\n",
      "Iter-36; Total loss: 1.087\n",
      "Iter-37; Total loss: 0.9996\n",
      "Iter-38; Total loss: 1.017\n",
      "Iter-39; Total loss: 0.9436\n",
      "Iter-0; Total loss: 1.42\n",
      "Iter-1; Total loss: 1.591\n",
      "Iter-2; Total loss: 1.561\n",
      "Iter-3; Total loss: 1.61\n",
      "Iter-4; Total loss: 1.582\n",
      "Iter-5; Total loss: 1.29\n",
      "Iter-6; Total loss: 1.335\n",
      "Iter-7; Total loss: 1.505\n",
      "Iter-8; Total loss: 1.172\n",
      "Iter-9; Total loss: 1.021\n",
      "Iter-10; Total loss: 1.508\n",
      "Iter-11; Total loss: 1.272\n",
      "Iter-12; Total loss: 1.215\n",
      "Iter-13; Total loss: 1.391\n",
      "Iter-14; Total loss: 1.239\n",
      "Iter-15; Total loss: 0.8486\n",
      "Iter-16; Total loss: 1.148\n",
      "Iter-17; Total loss: 1.286\n",
      "Iter-18; Total loss: 1.238\n",
      "Iter-19; Total loss: 0.7223\n",
      "Iter-20; Total loss: 1.095\n",
      "Iter-21; Total loss: 1.003\n",
      "Iter-22; Total loss: 0.9793\n",
      "Iter-23; Total loss: 1.055\n",
      "Iter-24; Total loss: 1.122\n",
      "Iter-25; Total loss: 1.066\n",
      "Iter-26; Total loss: 0.9389\n",
      "Iter-27; Total loss: 1.114\n",
      "Iter-28; Total loss: 1.124\n",
      "Iter-29; Total loss: 0.8391\n",
      "Iter-30; Total loss: 1.129\n",
      "Iter-31; Total loss: 1.012\n",
      "Iter-32; Total loss: 0.8637\n",
      "Iter-33; Total loss: 1.023\n",
      "Iter-34; Total loss: 0.843\n",
      "Iter-35; Total loss: 0.9486\n",
      "Iter-36; Total loss: 0.7061\n",
      "Iter-37; Total loss: 0.9232\n",
      "Iter-38; Total loss: 0.6614\n",
      "Iter-39; Total loss: 1.005\n",
      "Iter-0; Total loss: 0.7534\n",
      "Iter-1; Total loss: 0.7733\n",
      "Iter-2; Total loss: 0.7004\n",
      "Iter-3; Total loss: 0.7408\n",
      "Iter-4; Total loss: 0.7568\n",
      "Iter-5; Total loss: 0.6817\n",
      "Iter-6; Total loss: 0.6747\n",
      "Iter-7; Total loss: 0.7384\n",
      "Iter-8; Total loss: 0.7295\n",
      "Iter-9; Total loss: 0.6711\n",
      "Iter-0; Total loss: 0.7598\n",
      "Iter-1; Total loss: 0.7131\n",
      "Iter-2; Total loss: 0.6577\n",
      "Iter-3; Total loss: 0.6839\n",
      "Iter-4; Total loss: 0.7044\n",
      "Iter-5; Total loss: 0.7558\n",
      "Iter-6; Total loss: 0.6892\n",
      "Iter-7; Total loss: 0.7182\n",
      "Iter-8; Total loss: 0.6699\n",
      "Iter-9; Total loss: 0.681\n",
      "Iter-0; Total loss: 0.7462\n",
      "Iter-1; Total loss: 0.7061\n",
      "Iter-2; Total loss: 0.71\n",
      "Iter-3; Total loss: 0.7461\n",
      "Iter-4; Total loss: 0.7546\n",
      "Iter-5; Total loss: 0.728\n",
      "Iter-6; Total loss: 0.6834\n",
      "Iter-7; Total loss: 0.7234\n",
      "Iter-8; Total loss: 0.6127\n",
      "Iter-9; Total loss: 0.6881\n",
      "Iter-0; Total loss: 0.8158\n",
      "Iter-1; Total loss: 0.7262\n",
      "Iter-2; Total loss: 0.7653\n",
      "Iter-3; Total loss: 0.7386\n",
      "Iter-4; Total loss: 0.7032\n",
      "Iter-5; Total loss: 0.6669\n",
      "Iter-6; Total loss: 0.7224\n",
      "Iter-7; Total loss: 0.722\n",
      "Iter-8; Total loss: 0.699\n",
      "Iter-9; Total loss: 0.6729\n",
      "Iter-0; Total loss: 0.7613\n",
      "Iter-1; Total loss: 0.7532\n",
      "Iter-2; Total loss: 0.7192\n",
      "Iter-3; Total loss: 0.7363\n",
      "Iter-4; Total loss: 0.7263\n",
      "Iter-5; Total loss: 0.7426\n",
      "Iter-6; Total loss: 0.6866\n",
      "Iter-7; Total loss: 0.6798\n",
      "Iter-8; Total loss: 0.6871\n",
      "Iter-9; Total loss: 0.71\n",
      "Iter-0; Total loss: 1.558\n",
      "Iter-1; Total loss: 1.509\n",
      "Iter-2; Total loss: 1.5\n",
      "Iter-3; Total loss: 1.359\n",
      "Iter-4; Total loss: 1.143\n",
      "Iter-5; Total loss: 1.327\n",
      "Iter-6; Total loss: 1.326\n",
      "Iter-7; Total loss: 1.213\n",
      "Iter-8; Total loss: 1.24\n",
      "Iter-9; Total loss: 1.254\n",
      "Iter-0; Total loss: 1.506\n",
      "Iter-1; Total loss: 1.408\n",
      "Iter-2; Total loss: 1.501\n",
      "Iter-3; Total loss: 1.399\n",
      "Iter-4; Total loss: 1.485\n",
      "Iter-5; Total loss: 1.325\n",
      "Iter-6; Total loss: 1.48\n",
      "Iter-7; Total loss: 1.239\n",
      "Iter-8; Total loss: 1.344\n",
      "Iter-9; Total loss: 1.34\n",
      "Iter-0; Total loss: 1.561\n",
      "Iter-1; Total loss: 1.559\n",
      "Iter-2; Total loss: 1.467\n",
      "Iter-3; Total loss: 1.438\n",
      "Iter-4; Total loss: 1.44\n",
      "Iter-5; Total loss: 1.298\n",
      "Iter-6; Total loss: 1.417\n",
      "Iter-7; Total loss: 1.356\n",
      "Iter-8; Total loss: 1.426\n",
      "Iter-9; Total loss: 1.352\n",
      "Iter-0; Total loss: 1.477\n",
      "Iter-1; Total loss: 1.615\n",
      "Iter-2; Total loss: 1.511\n",
      "Iter-3; Total loss: 1.386\n",
      "Iter-4; Total loss: 1.33\n",
      "Iter-5; Total loss: 1.404\n",
      "Iter-6; Total loss: 1.332\n",
      "Iter-7; Total loss: 1.206\n",
      "Iter-8; Total loss: 1.269\n",
      "Iter-9; Total loss: 1.366\n",
      "Iter-0; Total loss: 1.46\n",
      "Iter-1; Total loss: 1.569\n",
      "Iter-2; Total loss: 1.464\n",
      "Iter-3; Total loss: 1.41\n",
      "Iter-4; Total loss: 1.323\n",
      "Iter-5; Total loss: 1.289\n",
      "Iter-6; Total loss: 1.342\n",
      "Iter-7; Total loss: 1.338\n",
      "Iter-8; Total loss: 1.188\n",
      "Iter-9; Total loss: 1.322\n",
      "Iter-0; Total loss: 0.882\n",
      "Iter-1; Total loss: 0.8685\n",
      "Iter-2; Total loss: 0.7946\n",
      "Iter-3; Total loss: 0.6773\n",
      "Iter-4; Total loss: 0.7397\n",
      "Iter-5; Total loss: 0.7857\n",
      "Iter-6; Total loss: 0.5398\n",
      "Iter-7; Total loss: 0.6751\n",
      "Iter-8; Total loss: 0.5314\n",
      "Iter-9; Total loss: 0.5162\n",
      "Iter-10; Total loss: 0.5216\n",
      "Iter-11; Total loss: 0.5158\n",
      "Iter-12; Total loss: 0.5723\n",
      "Iter-13; Total loss: 0.4485\n",
      "Iter-14; Total loss: 0.5026\n",
      "Iter-15; Total loss: 0.4922\n",
      "Iter-16; Total loss: 0.5743\n",
      "Iter-17; Total loss: 0.4298\n",
      "Iter-18; Total loss: 0.3939\n",
      "Iter-19; Total loss: 0.4342\n",
      "Iter-20; Total loss: 0.5591\n",
      "Iter-21; Total loss: 0.4743\n",
      "Iter-22; Total loss: 0.4569\n",
      "Iter-23; Total loss: 0.4162\n",
      "Iter-24; Total loss: 0.3593\n",
      "Iter-25; Total loss: 0.4746\n",
      "Iter-26; Total loss: 0.4188\n",
      "Iter-27; Total loss: 0.4266\n",
      "Iter-28; Total loss: 0.495\n",
      "Iter-29; Total loss: 0.3462\n",
      "Iter-30; Total loss: 0.4054\n",
      "Iter-31; Total loss: 0.3839\n",
      "Iter-32; Total loss: 0.3154\n",
      "Iter-33; Total loss: 0.3604\n",
      "Iter-34; Total loss: 0.3041\n",
      "Iter-35; Total loss: 0.4497\n",
      "Iter-36; Total loss: 0.448\n",
      "Iter-37; Total loss: 0.477\n",
      "Iter-38; Total loss: 0.4601\n",
      "Iter-39; Total loss: 0.4508\n",
      "Iter-40; Total loss: 0.3815\n",
      "Iter-41; Total loss: 0.372\n",
      "Iter-42; Total loss: 0.3138\n",
      "Iter-43; Total loss: 0.4799\n",
      "Iter-44; Total loss: 0.4216\n",
      "Iter-45; Total loss: 0.3066\n",
      "Iter-46; Total loss: 0.3687\n",
      "Iter-47; Total loss: 0.3394\n",
      "Iter-48; Total loss: 0.3592\n",
      "Iter-49; Total loss: 0.3004\n",
      "Iter-50; Total loss: 0.3368\n",
      "Iter-51; Total loss: 0.4256\n",
      "Iter-52; Total loss: 0.3392\n",
      "Iter-53; Total loss: 0.2334\n",
      "Iter-54; Total loss: 0.2444\n",
      "Iter-55; Total loss: 0.3712\n",
      "Iter-56; Total loss: 0.2686\n",
      "Iter-57; Total loss: 0.5463\n",
      "Iter-58; Total loss: 0.4347\n",
      "Iter-59; Total loss: 0.3319\n",
      "Iter-60; Total loss: 0.5353\n",
      "Iter-61; Total loss: 0.3657\n",
      "Iter-62; Total loss: 0.3583\n",
      "Iter-63; Total loss: 0.2958\n",
      "Iter-64; Total loss: 0.305\n",
      "Iter-65; Total loss: 0.2516\n",
      "Iter-66; Total loss: 0.3235\n",
      "Iter-67; Total loss: 0.3814\n",
      "Iter-68; Total loss: 0.3516\n",
      "Iter-69; Total loss: 0.4258\n",
      "Iter-0; Total loss: 0.8637\n",
      "Iter-1; Total loss: 0.8352\n",
      "Iter-2; Total loss: 0.7656\n",
      "Iter-3; Total loss: 0.7134\n",
      "Iter-4; Total loss: 0.6997\n",
      "Iter-5; Total loss: 0.6423\n",
      "Iter-6; Total loss: 0.5055\n",
      "Iter-7; Total loss: 0.5423\n",
      "Iter-8; Total loss: 0.518\n",
      "Iter-9; Total loss: 0.4957\n",
      "Iter-10; Total loss: 0.5041\n",
      "Iter-11; Total loss: 0.5474\n",
      "Iter-12; Total loss: 0.5999\n",
      "Iter-13; Total loss: 0.4824\n",
      "Iter-14; Total loss: 0.5229\n",
      "Iter-15; Total loss: 0.6204\n",
      "Iter-16; Total loss: 0.6031\n",
      "Iter-17; Total loss: 0.4602\n",
      "Iter-18; Total loss: 0.4376\n",
      "Iter-19; Total loss: 0.418\n",
      "Iter-20; Total loss: 0.4227\n",
      "Iter-21; Total loss: 0.4241\n",
      "Iter-22; Total loss: 0.3904\n",
      "Iter-23; Total loss: 0.4978\n",
      "Iter-24; Total loss: 0.3723\n",
      "Iter-25; Total loss: 0.5292\n",
      "Iter-26; Total loss: 0.4463\n",
      "Iter-27; Total loss: 0.3303\n",
      "Iter-28; Total loss: 0.4631\n",
      "Iter-29; Total loss: 0.4078\n",
      "Iter-30; Total loss: 0.4176\n",
      "Iter-31; Total loss: 0.3042\n",
      "Iter-32; Total loss: 0.4231\n",
      "Iter-33; Total loss: 0.4439\n",
      "Iter-34; Total loss: 0.3524\n",
      "Iter-35; Total loss: 0.4043\n",
      "Iter-36; Total loss: 0.4905\n",
      "Iter-37; Total loss: 0.4987\n",
      "Iter-38; Total loss: 0.3715\n",
      "Iter-39; Total loss: 0.3645\n",
      "Iter-40; Total loss: 0.3293\n",
      "Iter-41; Total loss: 0.2968\n",
      "Iter-42; Total loss: 0.2708\n",
      "Iter-43; Total loss: 0.4287\n",
      "Iter-44; Total loss: 0.3722\n",
      "Iter-45; Total loss: 0.4787\n",
      "Iter-46; Total loss: 0.3869\n",
      "Iter-47; Total loss: 0.5328\n",
      "Iter-48; Total loss: 0.3966\n",
      "Iter-49; Total loss: 0.299\n",
      "Iter-50; Total loss: 0.3843\n",
      "Iter-51; Total loss: 0.4306\n",
      "Iter-52; Total loss: 0.3771\n",
      "Iter-53; Total loss: 0.453\n",
      "Iter-54; Total loss: 0.3292\n",
      "Iter-55; Total loss: 0.2216\n",
      "Iter-56; Total loss: 0.4316\n",
      "Iter-57; Total loss: 0.352\n",
      "Iter-58; Total loss: 0.3472\n",
      "Iter-59; Total loss: 0.3291\n",
      "Iter-60; Total loss: 0.4494\n",
      "Iter-61; Total loss: 0.3407\n",
      "Iter-62; Total loss: 0.2743\n",
      "Iter-63; Total loss: 0.3087\n",
      "Iter-64; Total loss: 0.4341\n",
      "Iter-65; Total loss: 0.4086\n",
      "Iter-66; Total loss: 0.3428\n",
      "Iter-67; Total loss: 0.3618\n",
      "Iter-68; Total loss: 0.3022\n",
      "Iter-69; Total loss: 0.1553\n",
      "Iter-0; Total loss: 0.9551\n",
      "Iter-1; Total loss: 0.8763\n",
      "Iter-2; Total loss: 0.7443\n",
      "Iter-3; Total loss: 0.5501\n",
      "Iter-4; Total loss: 0.6703\n",
      "Iter-5; Total loss: 0.6932\n",
      "Iter-6; Total loss: 0.5738\n",
      "Iter-7; Total loss: 0.629\n",
      "Iter-8; Total loss: 0.5119\n",
      "Iter-9; Total loss: 0.5988\n",
      "Iter-10; Total loss: 0.5301\n",
      "Iter-11; Total loss: 0.4419\n",
      "Iter-12; Total loss: 0.4159\n",
      "Iter-13; Total loss: 0.424\n",
      "Iter-14; Total loss: 0.3541\n",
      "Iter-15; Total loss: 0.3563\n",
      "Iter-16; Total loss: 0.3759\n",
      "Iter-17; Total loss: 0.4525\n",
      "Iter-18; Total loss: 0.3973\n",
      "Iter-19; Total loss: 0.5386\n",
      "Iter-20; Total loss: 0.4556\n",
      "Iter-21; Total loss: 0.5159\n",
      "Iter-22; Total loss: 0.4021\n",
      "Iter-23; Total loss: 0.314\n",
      "Iter-24; Total loss: 0.4461\n",
      "Iter-25; Total loss: 0.513\n",
      "Iter-26; Total loss: 0.4967\n",
      "Iter-27; Total loss: 0.3888\n",
      "Iter-28; Total loss: 0.3817\n",
      "Iter-29; Total loss: 0.2613\n",
      "Iter-30; Total loss: 0.4365\n",
      "Iter-31; Total loss: 0.3684\n",
      "Iter-32; Total loss: 0.3322\n",
      "Iter-33; Total loss: 0.4012\n",
      "Iter-34; Total loss: 0.3952\n",
      "Iter-35; Total loss: 0.3534\n",
      "Iter-36; Total loss: 0.3689\n",
      "Iter-37; Total loss: 0.4169\n",
      "Iter-38; Total loss: 0.316\n",
      "Iter-39; Total loss: 0.3689\n",
      "Iter-40; Total loss: 0.3538\n",
      "Iter-41; Total loss: 0.3078\n",
      "Iter-42; Total loss: 0.4473\n",
      "Iter-43; Total loss: 0.4039\n",
      "Iter-44; Total loss: 0.3004\n",
      "Iter-45; Total loss: 0.2753\n",
      "Iter-46; Total loss: 0.3893\n",
      "Iter-47; Total loss: 0.4145\n",
      "Iter-48; Total loss: 0.3944\n",
      "Iter-49; Total loss: 0.3434\n",
      "Iter-50; Total loss: 0.4132\n",
      "Iter-51; Total loss: 0.3776\n",
      "Iter-52; Total loss: 0.3509\n",
      "Iter-53; Total loss: 0.3291\n",
      "Iter-54; Total loss: 0.3282\n",
      "Iter-55; Total loss: 0.4013\n",
      "Iter-56; Total loss: 0.3214\n",
      "Iter-57; Total loss: 0.2752\n",
      "Iter-58; Total loss: 0.2467\n",
      "Iter-59; Total loss: 0.3107\n",
      "Iter-60; Total loss: 0.4721\n",
      "Iter-61; Total loss: 0.3821\n",
      "Iter-62; Total loss: 0.4055\n",
      "Iter-63; Total loss: 0.4037\n",
      "Iter-64; Total loss: 0.2589\n",
      "Iter-65; Total loss: 0.356\n",
      "Iter-66; Total loss: 0.4087\n",
      "Iter-67; Total loss: 0.3301\n",
      "Iter-68; Total loss: 0.3081\n",
      "Iter-69; Total loss: 0.3124\n",
      "Iter-0; Total loss: 0.821\n",
      "Iter-1; Total loss: 0.7792\n",
      "Iter-2; Total loss: 0.7369\n",
      "Iter-3; Total loss: 0.6521\n",
      "Iter-4; Total loss: 0.6999\n",
      "Iter-5; Total loss: 0.6394\n",
      "Iter-6; Total loss: 0.5744\n",
      "Iter-7; Total loss: 0.5917\n",
      "Iter-8; Total loss: 0.5011\n",
      "Iter-9; Total loss: 0.5914\n",
      "Iter-10; Total loss: 0.5936\n",
      "Iter-11; Total loss: 0.4379\n",
      "Iter-12; Total loss: 0.5596\n",
      "Iter-13; Total loss: 0.6722\n",
      "Iter-14; Total loss: 0.582\n",
      "Iter-15; Total loss: 0.4945\n",
      "Iter-16; Total loss: 0.4491\n",
      "Iter-17; Total loss: 0.5501\n",
      "Iter-18; Total loss: 0.474\n",
      "Iter-19; Total loss: 0.4096\n",
      "Iter-20; Total loss: 0.4009\n",
      "Iter-21; Total loss: 0.4519\n",
      "Iter-22; Total loss: 0.3643\n",
      "Iter-23; Total loss: 0.3818\n",
      "Iter-24; Total loss: 0.4111\n",
      "Iter-25; Total loss: 0.3394\n",
      "Iter-26; Total loss: 0.3517\n",
      "Iter-27; Total loss: 0.4231\n",
      "Iter-28; Total loss: 0.4753\n",
      "Iter-29; Total loss: 0.4563\n",
      "Iter-30; Total loss: 0.4131\n",
      "Iter-31; Total loss: 0.3702\n",
      "Iter-32; Total loss: 0.4977\n",
      "Iter-33; Total loss: 0.3769\n",
      "Iter-34; Total loss: 0.2492\n",
      "Iter-35; Total loss: 0.3047\n",
      "Iter-36; Total loss: 0.419\n",
      "Iter-37; Total loss: 0.3508\n",
      "Iter-38; Total loss: 0.3389\n",
      "Iter-39; Total loss: 0.5328\n",
      "Iter-40; Total loss: 0.4096\n",
      "Iter-41; Total loss: 0.4548\n",
      "Iter-42; Total loss: 0.4294\n",
      "Iter-43; Total loss: 0.3653\n",
      "Iter-44; Total loss: 0.455\n",
      "Iter-45; Total loss: 0.2504\n",
      "Iter-46; Total loss: 0.3127\n",
      "Iter-47; Total loss: 0.3851\n",
      "Iter-48; Total loss: 0.417\n",
      "Iter-49; Total loss: 0.476\n",
      "Iter-50; Total loss: 0.4794\n",
      "Iter-51; Total loss: 0.4792\n",
      "Iter-52; Total loss: 0.2683\n",
      "Iter-53; Total loss: 0.3501\n",
      "Iter-54; Total loss: 0.2577\n",
      "Iter-55; Total loss: 0.3507\n",
      "Iter-56; Total loss: 0.3972\n",
      "Iter-57; Total loss: 0.2833\n",
      "Iter-58; Total loss: 0.3362\n",
      "Iter-59; Total loss: 0.369\n",
      "Iter-60; Total loss: 0.3665\n",
      "Iter-61; Total loss: 0.4076\n",
      "Iter-62; Total loss: 0.2532\n",
      "Iter-63; Total loss: 0.2871\n",
      "Iter-64; Total loss: 0.3511\n",
      "Iter-65; Total loss: 0.4382\n",
      "Iter-66; Total loss: 0.3439\n",
      "Iter-67; Total loss: 0.3834\n",
      "Iter-68; Total loss: 0.4128\n",
      "Iter-69; Total loss: 0.2793\n",
      "Iter-0; Total loss: 0.9895\n",
      "Iter-1; Total loss: 0.9155\n",
      "Iter-2; Total loss: 0.6963\n",
      "Iter-3; Total loss: 0.7418\n",
      "Iter-4; Total loss: 0.699\n",
      "Iter-5; Total loss: 0.6169\n",
      "Iter-6; Total loss: 0.6135\n",
      "Iter-7; Total loss: 0.4896\n",
      "Iter-8; Total loss: 0.4552\n",
      "Iter-9; Total loss: 0.4947\n",
      "Iter-10; Total loss: 0.37\n",
      "Iter-11; Total loss: 0.458\n",
      "Iter-12; Total loss: 0.549\n",
      "Iter-13; Total loss: 0.5071\n",
      "Iter-14; Total loss: 0.5024\n",
      "Iter-15; Total loss: 0.5931\n",
      "Iter-16; Total loss: 0.5257\n",
      "Iter-17; Total loss: 0.3775\n",
      "Iter-18; Total loss: 0.4077\n",
      "Iter-19; Total loss: 0.5096\n",
      "Iter-20; Total loss: 0.5155\n",
      "Iter-21; Total loss: 0.4038\n",
      "Iter-22; Total loss: 0.4275\n",
      "Iter-23; Total loss: 0.3647\n",
      "Iter-24; Total loss: 0.4259\n",
      "Iter-25; Total loss: 0.3977\n",
      "Iter-26; Total loss: 0.3307\n",
      "Iter-27; Total loss: 0.2936\n",
      "Iter-28; Total loss: 0.3312\n",
      "Iter-29; Total loss: 0.3994\n",
      "Iter-30; Total loss: 0.4405\n",
      "Iter-31; Total loss: 0.4209\n",
      "Iter-32; Total loss: 0.352\n",
      "Iter-33; Total loss: 0.5551\n",
      "Iter-34; Total loss: 0.4259\n",
      "Iter-35; Total loss: 0.3194\n",
      "Iter-36; Total loss: 0.3709\n",
      "Iter-37; Total loss: 0.3038\n",
      "Iter-38; Total loss: 0.3395\n",
      "Iter-39; Total loss: 0.3592\n",
      "Iter-40; Total loss: 0.3895\n",
      "Iter-41; Total loss: 0.3874\n",
      "Iter-42; Total loss: 0.3443\n",
      "Iter-43; Total loss: 0.3609\n",
      "Iter-44; Total loss: 0.3258\n",
      "Iter-45; Total loss: 0.328\n",
      "Iter-46; Total loss: 0.4369\n",
      "Iter-47; Total loss: 0.2924\n",
      "Iter-48; Total loss: 0.417\n",
      "Iter-49; Total loss: 0.2914\n",
      "Iter-50; Total loss: 0.2364\n",
      "Iter-51; Total loss: 0.3929\n",
      "Iter-52; Total loss: 0.3385\n",
      "Iter-53; Total loss: 0.3967\n",
      "Iter-54; Total loss: 0.3583\n",
      "Iter-55; Total loss: 0.3396\n",
      "Iter-56; Total loss: 0.3328\n",
      "Iter-57; Total loss: 0.2999\n",
      "Iter-58; Total loss: 0.3418\n",
      "Iter-59; Total loss: 0.3187\n",
      "Iter-60; Total loss: 0.3319\n",
      "Iter-61; Total loss: 0.3579\n",
      "Iter-62; Total loss: 0.3595\n",
      "Iter-63; Total loss: 0.3787\n",
      "Iter-64; Total loss: 0.3201\n",
      "Iter-65; Total loss: 0.3211\n",
      "Iter-66; Total loss: 0.3741\n",
      "Iter-67; Total loss: 0.391\n",
      "Iter-68; Total loss: 0.3805\n",
      "Iter-69; Total loss: 0.3134\n",
      "Iter-0; Total loss: 1.054\n",
      "Iter-1; Total loss: 1.091\n",
      "Iter-2; Total loss: 0.9844\n",
      "Iter-3; Total loss: 0.9587\n",
      "Iter-4; Total loss: 0.9561\n",
      "Iter-5; Total loss: 0.9369\n",
      "Iter-6; Total loss: 0.9806\n",
      "Iter-7; Total loss: 0.8888\n",
      "Iter-8; Total loss: 0.8362\n",
      "Iter-9; Total loss: 0.8356\n",
      "Iter-10; Total loss: 0.9614\n",
      "Iter-11; Total loss: 0.7899\n",
      "Iter-12; Total loss: 0.7891\n",
      "Iter-13; Total loss: 0.7918\n",
      "Iter-14; Total loss: 0.8018\n",
      "Iter-15; Total loss: 0.8715\n",
      "Iter-16; Total loss: 0.7048\n",
      "Iter-17; Total loss: 0.7004\n",
      "Iter-18; Total loss: 0.7784\n",
      "Iter-19; Total loss: 0.7865\n",
      "Iter-20; Total loss: 0.7767\n",
      "Iter-21; Total loss: 0.7565\n",
      "Iter-22; Total loss: 0.5474\n",
      "Iter-23; Total loss: 0.7445\n",
      "Iter-24; Total loss: 0.7374\n",
      "Iter-25; Total loss: 0.8295\n",
      "Iter-26; Total loss: 0.7303\n",
      "Iter-27; Total loss: 0.6488\n",
      "Iter-28; Total loss: 0.8188\n",
      "Iter-29; Total loss: 0.5962\n",
      "Iter-30; Total loss: 0.7278\n",
      "Iter-31; Total loss: 0.6955\n",
      "Iter-32; Total loss: 0.7914\n",
      "Iter-33; Total loss: 0.7247\n",
      "Iter-34; Total loss: 0.6147\n",
      "Iter-35; Total loss: 0.6852\n",
      "Iter-36; Total loss: 0.5557\n",
      "Iter-37; Total loss: 0.7035\n",
      "Iter-38; Total loss: 0.6541\n",
      "Iter-39; Total loss: 0.7606\n",
      "Iter-40; Total loss: 0.7563\n",
      "Iter-41; Total loss: 0.6117\n",
      "Iter-42; Total loss: 0.5991\n",
      "Iter-43; Total loss: 0.7826\n",
      "Iter-44; Total loss: 0.778\n",
      "Iter-45; Total loss: 0.5698\n",
      "Iter-46; Total loss: 0.6618\n",
      "Iter-47; Total loss: 0.75\n",
      "Iter-48; Total loss: 0.7002\n",
      "Iter-49; Total loss: 0.5773\n",
      "Iter-50; Total loss: 0.6998\n",
      "Iter-51; Total loss: 0.6145\n",
      "Iter-52; Total loss: 0.4885\n",
      "Iter-53; Total loss: 0.5811\n",
      "Iter-54; Total loss: 0.7755\n",
      "Iter-55; Total loss: 0.5961\n",
      "Iter-56; Total loss: 0.7247\n",
      "Iter-57; Total loss: 0.5694\n",
      "Iter-58; Total loss: 0.717\n",
      "Iter-59; Total loss: 0.5848\n",
      "Iter-0; Total loss: 1.095\n",
      "Iter-1; Total loss: 1.036\n",
      "Iter-2; Total loss: 1.002\n",
      "Iter-3; Total loss: 1.022\n",
      "Iter-4; Total loss: 0.9179\n",
      "Iter-5; Total loss: 1.026\n",
      "Iter-6; Total loss: 0.752\n",
      "Iter-7; Total loss: 0.9392\n",
      "Iter-8; Total loss: 0.8127\n",
      "Iter-9; Total loss: 0.8213\n",
      "Iter-10; Total loss: 0.9247\n",
      "Iter-11; Total loss: 0.8089\n",
      "Iter-12; Total loss: 0.8021\n",
      "Iter-13; Total loss: 0.9062\n",
      "Iter-14; Total loss: 0.6721\n",
      "Iter-15; Total loss: 0.8878\n",
      "Iter-16; Total loss: 0.7198\n",
      "Iter-17; Total loss: 0.7591\n",
      "Iter-18; Total loss: 0.8284\n",
      "Iter-19; Total loss: 0.8634\n",
      "Iter-20; Total loss: 0.7466\n",
      "Iter-21; Total loss: 0.7842\n",
      "Iter-22; Total loss: 0.7133\n",
      "Iter-23; Total loss: 0.8433\n",
      "Iter-24; Total loss: 0.6845\n",
      "Iter-25; Total loss: 0.6918\n",
      "Iter-26; Total loss: 0.7713\n",
      "Iter-27; Total loss: 0.7742\n",
      "Iter-28; Total loss: 0.6604\n",
      "Iter-29; Total loss: 0.7381\n",
      "Iter-30; Total loss: 0.7834\n",
      "Iter-31; Total loss: 0.6958\n",
      "Iter-32; Total loss: 0.6225\n",
      "Iter-33; Total loss: 0.5132\n",
      "Iter-34; Total loss: 0.603\n",
      "Iter-35; Total loss: 0.5642\n",
      "Iter-36; Total loss: 0.684\n",
      "Iter-37; Total loss: 0.8363\n",
      "Iter-38; Total loss: 0.6928\n",
      "Iter-39; Total loss: 0.6327\n",
      "Iter-40; Total loss: 0.5737\n",
      "Iter-41; Total loss: 0.7221\n",
      "Iter-42; Total loss: 0.5618\n",
      "Iter-43; Total loss: 0.6323\n",
      "Iter-44; Total loss: 0.709\n",
      "Iter-45; Total loss: 0.797\n",
      "Iter-46; Total loss: 0.629\n",
      "Iter-47; Total loss: 0.7526\n",
      "Iter-48; Total loss: 0.5784\n",
      "Iter-49; Total loss: 0.6051\n",
      "Iter-50; Total loss: 0.6618\n",
      "Iter-51; Total loss: 0.4947\n",
      "Iter-52; Total loss: 0.7359\n",
      "Iter-53; Total loss: 0.6118\n",
      "Iter-54; Total loss: 0.624\n",
      "Iter-55; Total loss: 0.6614\n",
      "Iter-56; Total loss: 0.7532\n",
      "Iter-57; Total loss: 0.6376\n",
      "Iter-58; Total loss: 0.7227\n",
      "Iter-59; Total loss: 0.5818\n",
      "Iter-0; Total loss: 1.063\n",
      "Iter-1; Total loss: 1.124\n",
      "Iter-2; Total loss: 1.188\n",
      "Iter-3; Total loss: 0.9617\n",
      "Iter-4; Total loss: 0.9479\n",
      "Iter-5; Total loss: 0.9609\n",
      "Iter-6; Total loss: 0.8008\n",
      "Iter-7; Total loss: 0.8973\n",
      "Iter-8; Total loss: 0.8898\n",
      "Iter-9; Total loss: 0.8438\n",
      "Iter-10; Total loss: 0.8719\n",
      "Iter-11; Total loss: 0.7888\n",
      "Iter-12; Total loss: 0.8688\n",
      "Iter-13; Total loss: 0.6566\n",
      "Iter-14; Total loss: 0.7359\n",
      "Iter-15; Total loss: 0.775\n",
      "Iter-16; Total loss: 0.7167\n",
      "Iter-17; Total loss: 0.8396\n",
      "Iter-18; Total loss: 0.7484\n",
      "Iter-19; Total loss: 0.784\n",
      "Iter-20; Total loss: 0.7106\n",
      "Iter-21; Total loss: 0.7572\n",
      "Iter-22; Total loss: 0.6129\n",
      "Iter-23; Total loss: 0.5972\n",
      "Iter-24; Total loss: 0.6582\n",
      "Iter-25; Total loss: 0.7713\n",
      "Iter-26; Total loss: 0.6982\n",
      "Iter-27; Total loss: 0.7712\n",
      "Iter-28; Total loss: 0.6855\n",
      "Iter-29; Total loss: 0.6042\n",
      "Iter-30; Total loss: 0.6733\n",
      "Iter-31; Total loss: 0.8057\n",
      "Iter-32; Total loss: 0.826\n",
      "Iter-33; Total loss: 0.6992\n",
      "Iter-34; Total loss: 0.5571\n",
      "Iter-35; Total loss: 0.5953\n",
      "Iter-36; Total loss: 0.5399\n",
      "Iter-37; Total loss: 0.579\n",
      "Iter-38; Total loss: 0.7583\n",
      "Iter-39; Total loss: 0.4633\n",
      "Iter-40; Total loss: 0.6389\n",
      "Iter-41; Total loss: 0.6036\n",
      "Iter-42; Total loss: 0.6733\n",
      "Iter-43; Total loss: 0.7147\n",
      "Iter-44; Total loss: 0.6924\n",
      "Iter-45; Total loss: 0.7497\n",
      "Iter-46; Total loss: 0.5448\n",
      "Iter-47; Total loss: 0.4601\n",
      "Iter-48; Total loss: 0.5317\n",
      "Iter-49; Total loss: 0.6188\n",
      "Iter-50; Total loss: 0.7694\n",
      "Iter-51; Total loss: 0.6478\n",
      "Iter-52; Total loss: 0.6593\n",
      "Iter-53; Total loss: 0.6536\n",
      "Iter-54; Total loss: 0.7062\n",
      "Iter-55; Total loss: 0.5603\n",
      "Iter-56; Total loss: 0.5494\n",
      "Iter-57; Total loss: 0.6358\n",
      "Iter-58; Total loss: 0.6242\n",
      "Iter-59; Total loss: 0.7171\n",
      "Iter-0; Total loss: 1.096\n",
      "Iter-1; Total loss: 1.113\n",
      "Iter-2; Total loss: 0.9872\n",
      "Iter-3; Total loss: 1.101\n",
      "Iter-4; Total loss: 0.9101\n",
      "Iter-5; Total loss: 0.9811\n",
      "Iter-6; Total loss: 0.888\n",
      "Iter-7; Total loss: 0.7152\n",
      "Iter-8; Total loss: 0.8644\n",
      "Iter-9; Total loss: 0.9109\n",
      "Iter-10; Total loss: 0.7831\n",
      "Iter-11; Total loss: 0.7243\n",
      "Iter-12; Total loss: 0.8217\n",
      "Iter-13; Total loss: 0.9537\n",
      "Iter-14; Total loss: 0.7503\n",
      "Iter-15; Total loss: 0.8368\n",
      "Iter-16; Total loss: 0.7532\n",
      "Iter-17; Total loss: 0.7945\n",
      "Iter-18; Total loss: 0.6838\n",
      "Iter-19; Total loss: 0.797\n",
      "Iter-20; Total loss: 0.8298\n",
      "Iter-21; Total loss: 0.8684\n",
      "Iter-22; Total loss: 0.7782\n",
      "Iter-23; Total loss: 0.6961\n",
      "Iter-24; Total loss: 0.5559\n",
      "Iter-25; Total loss: 0.6839\n",
      "Iter-26; Total loss: 0.7256\n",
      "Iter-27; Total loss: 0.736\n",
      "Iter-28; Total loss: 0.6828\n",
      "Iter-29; Total loss: 0.5994\n",
      "Iter-30; Total loss: 0.6889\n",
      "Iter-31; Total loss: 0.7048\n",
      "Iter-32; Total loss: 0.6862\n",
      "Iter-33; Total loss: 0.6299\n",
      "Iter-34; Total loss: 0.7446\n",
      "Iter-35; Total loss: 0.6302\n",
      "Iter-36; Total loss: 0.6506\n",
      "Iter-37; Total loss: 0.7888\n",
      "Iter-38; Total loss: 0.6845\n",
      "Iter-39; Total loss: 0.6509\n",
      "Iter-40; Total loss: 0.6433\n",
      "Iter-41; Total loss: 0.6153\n",
      "Iter-42; Total loss: 0.7352\n",
      "Iter-43; Total loss: 0.7169\n",
      "Iter-44; Total loss: 0.6411\n",
      "Iter-45; Total loss: 0.6485\n",
      "Iter-46; Total loss: 0.634\n",
      "Iter-47; Total loss: 0.6955\n",
      "Iter-48; Total loss: 0.7288\n",
      "Iter-49; Total loss: 0.6026\n",
      "Iter-50; Total loss: 0.6783\n",
      "Iter-51; Total loss: 0.8031\n",
      "Iter-52; Total loss: 0.6264\n",
      "Iter-53; Total loss: 0.6357\n",
      "Iter-54; Total loss: 0.4688\n",
      "Iter-55; Total loss: 0.5247\n",
      "Iter-56; Total loss: 0.5976\n",
      "Iter-57; Total loss: 0.5183\n",
      "Iter-58; Total loss: 0.6765\n",
      "Iter-59; Total loss: 0.6818\n",
      "Iter-0; Total loss: 1.041\n",
      "Iter-1; Total loss: 1.09\n",
      "Iter-2; Total loss: 0.9618\n",
      "Iter-3; Total loss: 0.9157\n",
      "Iter-4; Total loss: 0.9326\n",
      "Iter-5; Total loss: 0.9479\n",
      "Iter-6; Total loss: 0.8779\n",
      "Iter-7; Total loss: 0.8867\n",
      "Iter-8; Total loss: 0.9014\n",
      "Iter-9; Total loss: 0.8287\n",
      "Iter-10; Total loss: 0.6637\n",
      "Iter-11; Total loss: 0.8733\n",
      "Iter-12; Total loss: 0.9739\n",
      "Iter-13; Total loss: 0.7241\n",
      "Iter-14; Total loss: 0.7618\n",
      "Iter-15; Total loss: 0.8684\n",
      "Iter-16; Total loss: 0.7586\n",
      "Iter-17; Total loss: 0.519\n",
      "Iter-18; Total loss: 0.8496\n",
      "Iter-19; Total loss: 0.8688\n",
      "Iter-20; Total loss: 0.8018\n",
      "Iter-21; Total loss: 0.7537\n",
      "Iter-22; Total loss: 0.763\n",
      "Iter-23; Total loss: 0.8176\n",
      "Iter-24; Total loss: 0.6865\n",
      "Iter-25; Total loss: 0.7032\n",
      "Iter-26; Total loss: 0.7477\n",
      "Iter-27; Total loss: 0.8576\n",
      "Iter-28; Total loss: 0.5861\n",
      "Iter-29; Total loss: 0.6706\n",
      "Iter-30; Total loss: 0.6876\n",
      "Iter-31; Total loss: 0.6095\n",
      "Iter-32; Total loss: 0.7678\n",
      "Iter-33; Total loss: 0.6101\n",
      "Iter-34; Total loss: 0.6696\n",
      "Iter-35; Total loss: 0.6421\n",
      "Iter-36; Total loss: 0.7128\n",
      "Iter-37; Total loss: 0.6749\n",
      "Iter-38; Total loss: 0.6384\n",
      "Iter-39; Total loss: 0.6448\n",
      "Iter-40; Total loss: 0.6872\n",
      "Iter-41; Total loss: 0.6569\n",
      "Iter-42; Total loss: 0.5863\n",
      "Iter-43; Total loss: 0.6533\n",
      "Iter-44; Total loss: 0.5682\n",
      "Iter-45; Total loss: 0.7198\n",
      "Iter-46; Total loss: 0.7153\n",
      "Iter-47; Total loss: 0.7409\n",
      "Iter-48; Total loss: 0.6461\n",
      "Iter-49; Total loss: 0.594\n",
      "Iter-50; Total loss: 0.6873\n",
      "Iter-51; Total loss: 0.6843\n",
      "Iter-52; Total loss: 0.6344\n",
      "Iter-53; Total loss: 0.6073\n",
      "Iter-54; Total loss: 0.5275\n",
      "Iter-55; Total loss: 0.6763\n",
      "Iter-56; Total loss: 0.7856\n",
      "Iter-57; Total loss: 0.5063\n",
      "Iter-58; Total loss: 0.6767\n",
      "Iter-59; Total loss: 0.759\n",
      "Iter-0; Total loss: 1.261\n",
      "Iter-1; Total loss: 0.7564\n",
      "Iter-2; Total loss: 0.8009\n",
      "Iter-3; Total loss: 0.8618\n",
      "Iter-4; Total loss: 0.888\n",
      "Iter-5; Total loss: 0.776\n",
      "Iter-6; Total loss: 0.8378\n",
      "Iter-7; Total loss: 0.7093\n",
      "Iter-8; Total loss: 0.7494\n",
      "Iter-9; Total loss: 0.6262\n",
      "Iter-0; Total loss: 1.057\n",
      "Iter-1; Total loss: 0.9232\n",
      "Iter-2; Total loss: 0.9684\n",
      "Iter-3; Total loss: 0.8236\n",
      "Iter-4; Total loss: 0.6897\n",
      "Iter-5; Total loss: 0.7227\n",
      "Iter-6; Total loss: 0.755\n",
      "Iter-7; Total loss: 0.5829\n",
      "Iter-8; Total loss: 0.6178\n",
      "Iter-9; Total loss: 0.6788\n",
      "Iter-0; Total loss: 0.9085\n",
      "Iter-1; Total loss: 0.9926\n",
      "Iter-2; Total loss: 0.8374\n",
      "Iter-3; Total loss: 0.7888\n",
      "Iter-4; Total loss: 0.8263\n",
      "Iter-5; Total loss: 0.7213\n",
      "Iter-6; Total loss: 0.7061\n",
      "Iter-7; Total loss: 0.7609\n",
      "Iter-8; Total loss: 0.8129\n",
      "Iter-9; Total loss: 0.6263\n",
      "Iter-0; Total loss: 1.144\n",
      "Iter-1; Total loss: 0.9788\n",
      "Iter-2; Total loss: 0.979\n",
      "Iter-3; Total loss: 0.8863\n",
      "Iter-4; Total loss: 0.9909\n",
      "Iter-5; Total loss: 0.6888\n",
      "Iter-6; Total loss: 0.6745\n",
      "Iter-7; Total loss: 0.5469\n",
      "Iter-8; Total loss: 0.8276\n",
      "Iter-9; Total loss: 0.7369\n",
      "Iter-0; Total loss: 1.043\n",
      "Iter-1; Total loss: 1.062\n",
      "Iter-2; Total loss: 0.7966\n",
      "Iter-3; Total loss: 0.9898\n",
      "Iter-4; Total loss: 0.8459\n",
      "Iter-5; Total loss: 0.7324\n",
      "Iter-6; Total loss: 0.6802\n",
      "Iter-7; Total loss: 0.7177\n",
      "Iter-8; Total loss: 0.709\n",
      "Iter-9; Total loss: 0.6048\n",
      "Iter-0; Total loss: 1.737\n",
      "Iter-1; Total loss: 1.624\n",
      "Iter-2; Total loss: 1.825\n",
      "Iter-3; Total loss: 1.69\n",
      "Iter-4; Total loss: 1.772\n",
      "Iter-5; Total loss: 1.733\n",
      "Iter-6; Total loss: 1.665\n",
      "Iter-7; Total loss: 1.631\n",
      "Iter-8; Total loss: 1.716\n",
      "Iter-9; Total loss: 1.564\n",
      "Iter-10; Total loss: 1.671\n",
      "Iter-11; Total loss: 1.709\n",
      "Iter-12; Total loss: 1.623\n",
      "Iter-13; Total loss: 1.695\n",
      "Iter-14; Total loss: 1.672\n",
      "Iter-15; Total loss: 1.499\n",
      "Iter-16; Total loss: 1.608\n",
      "Iter-17; Total loss: 1.865\n",
      "Iter-18; Total loss: 1.601\n",
      "Iter-19; Total loss: 1.49\n",
      "Iter-20; Total loss: 1.617\n",
      "Iter-21; Total loss: 1.611\n",
      "Iter-22; Total loss: 1.584\n",
      "Iter-23; Total loss: 1.574\n",
      "Iter-24; Total loss: 1.629\n",
      "Iter-25; Total loss: 1.649\n",
      "Iter-26; Total loss: 1.5\n",
      "Iter-27; Total loss: 1.62\n",
      "Iter-28; Total loss: 1.498\n",
      "Iter-29; Total loss: 1.509\n",
      "Iter-30; Total loss: 1.694\n",
      "Iter-31; Total loss: 1.5\n",
      "Iter-32; Total loss: 1.428\n",
      "Iter-33; Total loss: 1.59\n",
      "Iter-34; Total loss: 1.457\n",
      "Iter-35; Total loss: 1.512\n",
      "Iter-36; Total loss: 1.398\n",
      "Iter-37; Total loss: 1.609\n",
      "Iter-38; Total loss: 1.451\n",
      "Iter-39; Total loss: 1.461\n",
      "Iter-40; Total loss: 1.591\n",
      "Iter-41; Total loss: 1.389\n",
      "Iter-42; Total loss: 1.482\n",
      "Iter-43; Total loss: 1.516\n",
      "Iter-44; Total loss: 1.554\n",
      "Iter-45; Total loss: 1.471\n",
      "Iter-46; Total loss: 1.496\n",
      "Iter-47; Total loss: 1.456\n",
      "Iter-48; Total loss: 1.529\n",
      "Iter-49; Total loss: 1.49\n",
      "Iter-50; Total loss: 1.345\n",
      "Iter-51; Total loss: 1.434\n",
      "Iter-52; Total loss: 1.444\n",
      "Iter-53; Total loss: 1.424\n",
      "Iter-54; Total loss: 1.541\n",
      "Iter-55; Total loss: 1.384\n",
      "Iter-56; Total loss: 1.407\n",
      "Iter-57; Total loss: 1.6\n",
      "Iter-58; Total loss: 1.516\n",
      "Iter-59; Total loss: 1.374\n",
      "Iter-0; Total loss: 1.755\n",
      "Iter-1; Total loss: 1.677\n",
      "Iter-2; Total loss: 1.954\n",
      "Iter-3; Total loss: 1.816\n",
      "Iter-4; Total loss: 1.835\n",
      "Iter-5; Total loss: 1.776\n",
      "Iter-6; Total loss: 1.749\n",
      "Iter-7; Total loss: 1.514\n",
      "Iter-8; Total loss: 1.789\n",
      "Iter-9; Total loss: 1.742\n",
      "Iter-10; Total loss: 1.656\n",
      "Iter-11; Total loss: 1.668\n",
      "Iter-12; Total loss: 1.688\n",
      "Iter-13; Total loss: 1.558\n",
      "Iter-14; Total loss: 1.674\n",
      "Iter-15; Total loss: 1.616\n",
      "Iter-16; Total loss: 1.608\n",
      "Iter-17; Total loss: 1.642\n",
      "Iter-18; Total loss: 1.561\n",
      "Iter-19; Total loss: 1.542\n",
      "Iter-20; Total loss: 1.401\n",
      "Iter-21; Total loss: 1.479\n",
      "Iter-22; Total loss: 1.566\n",
      "Iter-23; Total loss: 1.552\n",
      "Iter-24; Total loss: 1.682\n",
      "Iter-25; Total loss: 1.641\n",
      "Iter-26; Total loss: 1.554\n",
      "Iter-27; Total loss: 1.378\n",
      "Iter-28; Total loss: 1.401\n",
      "Iter-29; Total loss: 1.516\n",
      "Iter-30; Total loss: 1.59\n",
      "Iter-31; Total loss: 1.538\n",
      "Iter-32; Total loss: 1.513\n",
      "Iter-33; Total loss: 1.438\n",
      "Iter-34; Total loss: 1.615\n",
      "Iter-35; Total loss: 1.382\n",
      "Iter-36; Total loss: 1.533\n",
      "Iter-37; Total loss: 1.521\n",
      "Iter-38; Total loss: 1.45\n",
      "Iter-39; Total loss: 1.359\n",
      "Iter-40; Total loss: 1.521\n",
      "Iter-41; Total loss: 1.606\n",
      "Iter-42; Total loss: 1.578\n",
      "Iter-43; Total loss: 1.428\n",
      "Iter-44; Total loss: 1.36\n",
      "Iter-45; Total loss: 1.529\n",
      "Iter-46; Total loss: 1.612\n",
      "Iter-47; Total loss: 1.447\n",
      "Iter-48; Total loss: 1.458\n",
      "Iter-49; Total loss: 1.534\n",
      "Iter-50; Total loss: 1.574\n",
      "Iter-51; Total loss: 1.607\n",
      "Iter-52; Total loss: 1.434\n",
      "Iter-53; Total loss: 1.363\n",
      "Iter-54; Total loss: 1.542\n",
      "Iter-55; Total loss: 1.332\n",
      "Iter-56; Total loss: 1.399\n",
      "Iter-57; Total loss: 1.269\n",
      "Iter-58; Total loss: 1.435\n",
      "Iter-59; Total loss: 1.344\n",
      "Iter-0; Total loss: 1.791\n",
      "Iter-1; Total loss: 1.747\n",
      "Iter-2; Total loss: 1.817\n",
      "Iter-3; Total loss: 1.772\n",
      "Iter-4; Total loss: 1.782\n",
      "Iter-5; Total loss: 1.724\n",
      "Iter-6; Total loss: 1.683\n",
      "Iter-7; Total loss: 1.654\n",
      "Iter-8; Total loss: 1.654\n",
      "Iter-9; Total loss: 1.672\n",
      "Iter-10; Total loss: 1.652\n",
      "Iter-11; Total loss: 1.707\n",
      "Iter-12; Total loss: 1.569\n",
      "Iter-13; Total loss: 1.501\n",
      "Iter-14; Total loss: 1.653\n",
      "Iter-15; Total loss: 1.553\n",
      "Iter-16; Total loss: 1.527\n",
      "Iter-17; Total loss: 1.458\n",
      "Iter-18; Total loss: 1.519\n",
      "Iter-19; Total loss: 1.506\n",
      "Iter-20; Total loss: 1.55\n",
      "Iter-21; Total loss: 1.445\n",
      "Iter-22; Total loss: 1.578\n",
      "Iter-23; Total loss: 1.527\n",
      "Iter-24; Total loss: 1.535\n",
      "Iter-25; Total loss: 1.517\n",
      "Iter-26; Total loss: 1.543\n",
      "Iter-27; Total loss: 1.485\n",
      "Iter-28; Total loss: 1.528\n",
      "Iter-29; Total loss: 1.549\n",
      "Iter-30; Total loss: 1.584\n",
      "Iter-31; Total loss: 1.627\n",
      "Iter-32; Total loss: 1.504\n",
      "Iter-33; Total loss: 1.606\n",
      "Iter-34; Total loss: 1.56\n",
      "Iter-35; Total loss: 1.604\n",
      "Iter-36; Total loss: 1.45\n",
      "Iter-37; Total loss: 1.568\n",
      "Iter-38; Total loss: 1.428\n",
      "Iter-39; Total loss: 1.526\n",
      "Iter-40; Total loss: 1.552\n",
      "Iter-41; Total loss: 1.476\n",
      "Iter-42; Total loss: 1.427\n",
      "Iter-43; Total loss: 1.377\n",
      "Iter-44; Total loss: 1.399\n",
      "Iter-45; Total loss: 1.402\n",
      "Iter-46; Total loss: 1.471\n",
      "Iter-47; Total loss: 1.484\n",
      "Iter-48; Total loss: 1.576\n",
      "Iter-49; Total loss: 1.428\n",
      "Iter-50; Total loss: 1.398\n",
      "Iter-51; Total loss: 1.542\n",
      "Iter-52; Total loss: 1.513\n",
      "Iter-53; Total loss: 1.418\n",
      "Iter-54; Total loss: 1.508\n",
      "Iter-55; Total loss: 1.287\n",
      "Iter-56; Total loss: 1.32\n",
      "Iter-57; Total loss: 1.348\n",
      "Iter-58; Total loss: 1.214\n",
      "Iter-59; Total loss: 1.336\n",
      "Iter-0; Total loss: 1.791\n",
      "Iter-1; Total loss: 1.732\n",
      "Iter-2; Total loss: 1.87\n",
      "Iter-3; Total loss: 1.743\n",
      "Iter-4; Total loss: 1.623\n",
      "Iter-5; Total loss: 1.793\n",
      "Iter-6; Total loss: 1.718\n",
      "Iter-7; Total loss: 1.598\n",
      "Iter-8; Total loss: 1.806\n",
      "Iter-9; Total loss: 1.605\n",
      "Iter-10; Total loss: 1.819\n",
      "Iter-11; Total loss: 1.556\n",
      "Iter-12; Total loss: 1.611\n",
      "Iter-13; Total loss: 1.495\n",
      "Iter-14; Total loss: 1.571\n",
      "Iter-15; Total loss: 1.689\n",
      "Iter-16; Total loss: 1.529\n",
      "Iter-17; Total loss: 1.604\n",
      "Iter-18; Total loss: 1.665\n",
      "Iter-19; Total loss: 1.579\n",
      "Iter-20; Total loss: 1.543\n",
      "Iter-21; Total loss: 1.584\n",
      "Iter-22; Total loss: 1.654\n",
      "Iter-23; Total loss: 1.672\n",
      "Iter-24; Total loss: 1.614\n",
      "Iter-25; Total loss: 1.434\n",
      "Iter-26; Total loss: 1.579\n",
      "Iter-27; Total loss: 1.497\n",
      "Iter-28; Total loss: 1.391\n",
      "Iter-29; Total loss: 1.605\n",
      "Iter-30; Total loss: 1.477\n",
      "Iter-31; Total loss: 1.521\n",
      "Iter-32; Total loss: 1.369\n",
      "Iter-33; Total loss: 1.352\n",
      "Iter-34; Total loss: 1.7\n",
      "Iter-35; Total loss: 1.556\n",
      "Iter-36; Total loss: 1.644\n",
      "Iter-37; Total loss: 1.455\n",
      "Iter-38; Total loss: 1.694\n",
      "Iter-39; Total loss: 1.213\n",
      "Iter-40; Total loss: 1.57\n",
      "Iter-41; Total loss: 1.357\n",
      "Iter-42; Total loss: 1.497\n",
      "Iter-43; Total loss: 1.419\n",
      "Iter-44; Total loss: 1.498\n",
      "Iter-45; Total loss: 1.568\n",
      "Iter-46; Total loss: 1.631\n",
      "Iter-47; Total loss: 1.445\n",
      "Iter-48; Total loss: 1.54\n",
      "Iter-49; Total loss: 1.384\n",
      "Iter-50; Total loss: 1.334\n",
      "Iter-51; Total loss: 1.485\n",
      "Iter-52; Total loss: 1.631\n",
      "Iter-53; Total loss: 1.444\n",
      "Iter-54; Total loss: 1.582\n",
      "Iter-55; Total loss: 1.5\n",
      "Iter-56; Total loss: 1.433\n",
      "Iter-57; Total loss: 1.276\n",
      "Iter-58; Total loss: 1.535\n",
      "Iter-59; Total loss: 1.464\n",
      "Iter-0; Total loss: 1.811\n",
      "Iter-1; Total loss: 1.741\n",
      "Iter-2; Total loss: 1.566\n",
      "Iter-3; Total loss: 1.694\n",
      "Iter-4; Total loss: 1.764\n",
      "Iter-5; Total loss: 1.706\n",
      "Iter-6; Total loss: 1.534\n",
      "Iter-7; Total loss: 1.701\n",
      "Iter-8; Total loss: 1.612\n",
      "Iter-9; Total loss: 1.703\n",
      "Iter-10; Total loss: 1.792\n",
      "Iter-11; Total loss: 1.656\n",
      "Iter-12; Total loss: 1.648\n",
      "Iter-13; Total loss: 1.73\n",
      "Iter-14; Total loss: 1.511\n",
      "Iter-15; Total loss: 1.673\n",
      "Iter-16; Total loss: 1.746\n",
      "Iter-17; Total loss: 1.502\n",
      "Iter-18; Total loss: 1.636\n",
      "Iter-19; Total loss: 1.527\n",
      "Iter-20; Total loss: 1.726\n",
      "Iter-21; Total loss: 1.602\n",
      "Iter-22; Total loss: 1.583\n",
      "Iter-23; Total loss: 1.478\n",
      "Iter-24; Total loss: 1.684\n",
      "Iter-25; Total loss: 1.539\n",
      "Iter-26; Total loss: 1.559\n",
      "Iter-27; Total loss: 1.481\n",
      "Iter-28; Total loss: 1.428\n",
      "Iter-29; Total loss: 1.724\n",
      "Iter-30; Total loss: 1.501\n",
      "Iter-31; Total loss: 1.47\n",
      "Iter-32; Total loss: 1.641\n",
      "Iter-33; Total loss: 1.545\n",
      "Iter-34; Total loss: 1.419\n",
      "Iter-35; Total loss: 1.474\n",
      "Iter-36; Total loss: 1.488\n",
      "Iter-37; Total loss: 1.598\n",
      "Iter-38; Total loss: 1.526\n",
      "Iter-39; Total loss: 1.564\n",
      "Iter-40; Total loss: 1.528\n",
      "Iter-41; Total loss: 1.384\n",
      "Iter-42; Total loss: 1.788\n",
      "Iter-43; Total loss: 1.443\n",
      "Iter-44; Total loss: 1.393\n",
      "Iter-45; Total loss: 1.497\n",
      "Iter-46; Total loss: 1.495\n",
      "Iter-47; Total loss: 1.534\n",
      "Iter-48; Total loss: 1.427\n",
      "Iter-49; Total loss: 1.402\n",
      "Iter-50; Total loss: 1.45\n",
      "Iter-51; Total loss: 1.498\n",
      "Iter-52; Total loss: 1.406\n",
      "Iter-53; Total loss: 1.396\n",
      "Iter-54; Total loss: 1.595\n",
      "Iter-55; Total loss: 1.544\n",
      "Iter-56; Total loss: 1.386\n",
      "Iter-57; Total loss: 1.244\n",
      "Iter-58; Total loss: 1.503\n",
      "Iter-59; Total loss: 1.424\n",
      "Iter-0; Total loss: 1.349\n",
      "Iter-1; Total loss: 1.381\n",
      "Iter-2; Total loss: 1.351\n",
      "Iter-3; Total loss: 1.304\n",
      "Iter-4; Total loss: 1.163\n",
      "Iter-5; Total loss: 1.108\n",
      "Iter-6; Total loss: 1.185\n",
      "Iter-7; Total loss: 1.013\n",
      "Iter-8; Total loss: 1.041\n",
      "Iter-9; Total loss: 0.8654\n",
      "Iter-10; Total loss: 1.213\n",
      "Iter-11; Total loss: 0.964\n",
      "Iter-12; Total loss: 0.8782\n",
      "Iter-13; Total loss: 0.8986\n",
      "Iter-14; Total loss: 0.8896\n",
      "Iter-15; Total loss: 0.7089\n",
      "Iter-16; Total loss: 0.7306\n",
      "Iter-17; Total loss: 0.6945\n",
      "Iter-18; Total loss: 0.7636\n",
      "Iter-19; Total loss: 0.6438\n",
      "Iter-20; Total loss: 0.6916\n",
      "Iter-21; Total loss: 0.6295\n",
      "Iter-22; Total loss: 0.7878\n",
      "Iter-23; Total loss: 0.5776\n",
      "Iter-24; Total loss: 0.7856\n",
      "Iter-25; Total loss: 0.5837\n",
      "Iter-26; Total loss: 0.8575\n",
      "Iter-27; Total loss: 0.8284\n",
      "Iter-28; Total loss: 0.6131\n",
      "Iter-29; Total loss: 0.6473\n",
      "Iter-30; Total loss: 0.6492\n",
      "Iter-31; Total loss: 0.533\n",
      "Iter-32; Total loss: 0.7776\n",
      "Iter-33; Total loss: 0.6206\n",
      "Iter-34; Total loss: 0.5501\n",
      "Iter-35; Total loss: 0.6912\n",
      "Iter-36; Total loss: 0.6212\n",
      "Iter-37; Total loss: 0.6149\n",
      "Iter-38; Total loss: 0.6295\n",
      "Iter-39; Total loss: 0.633\n",
      "Iter-40; Total loss: 0.4834\n",
      "Iter-41; Total loss: 0.5908\n",
      "Iter-42; Total loss: 0.6565\n",
      "Iter-43; Total loss: 0.5727\n",
      "Iter-44; Total loss: 0.5748\n",
      "Iter-45; Total loss: 0.4822\n",
      "Iter-46; Total loss: 0.7194\n",
      "Iter-47; Total loss: 0.8143\n",
      "Iter-48; Total loss: 0.7136\n",
      "Iter-49; Total loss: 0.5363\n",
      "Iter-50; Total loss: 0.4223\n",
      "Iter-51; Total loss: 0.712\n",
      "Iter-52; Total loss: 0.5963\n",
      "Iter-53; Total loss: 0.607\n",
      "Iter-54; Total loss: 0.5108\n",
      "Iter-55; Total loss: 0.5309\n",
      "Iter-56; Total loss: 0.3866\n",
      "Iter-57; Total loss: 0.5743\n",
      "Iter-58; Total loss: 0.4652\n",
      "Iter-59; Total loss: 0.5998\n",
      "Iter-60; Total loss: 0.652\n",
      "Iter-61; Total loss: 0.6037\n",
      "Iter-62; Total loss: 0.734\n",
      "Iter-63; Total loss: 0.573\n",
      "Iter-64; Total loss: 0.6117\n",
      "Iter-65; Total loss: 0.3807\n",
      "Iter-66; Total loss: 0.5134\n",
      "Iter-67; Total loss: 0.7066\n",
      "Iter-68; Total loss: 0.4925\n",
      "Iter-69; Total loss: 0.559\n",
      "Iter-70; Total loss: 0.5693\n",
      "Iter-71; Total loss: 0.6815\n",
      "Iter-72; Total loss: 0.4892\n",
      "Iter-73; Total loss: 0.5669\n",
      "Iter-74; Total loss: 0.4525\n",
      "Iter-75; Total loss: 0.6646\n",
      "Iter-76; Total loss: 0.5357\n",
      "Iter-77; Total loss: 0.5979\n",
      "Iter-78; Total loss: 0.67\n",
      "Iter-79; Total loss: 0.6711\n",
      "Iter-0; Total loss: 1.344\n",
      "Iter-1; Total loss: 1.444\n",
      "Iter-2; Total loss: 1.382\n",
      "Iter-3; Total loss: 1.3\n",
      "Iter-4; Total loss: 0.9191\n",
      "Iter-5; Total loss: 0.7701\n",
      "Iter-6; Total loss: 0.8694\n",
      "Iter-7; Total loss: 1.065\n",
      "Iter-8; Total loss: 0.9268\n",
      "Iter-9; Total loss: 0.7928\n",
      "Iter-10; Total loss: 1.167\n",
      "Iter-11; Total loss: 0.634\n",
      "Iter-12; Total loss: 0.7401\n",
      "Iter-13; Total loss: 0.7726\n",
      "Iter-14; Total loss: 0.6834\n",
      "Iter-15; Total loss: 0.835\n",
      "Iter-16; Total loss: 0.8543\n",
      "Iter-17; Total loss: 0.7231\n",
      "Iter-18; Total loss: 0.5848\n",
      "Iter-19; Total loss: 0.8042\n",
      "Iter-20; Total loss: 0.8513\n",
      "Iter-21; Total loss: 0.6849\n",
      "Iter-22; Total loss: 0.7485\n",
      "Iter-23; Total loss: 0.6016\n",
      "Iter-24; Total loss: 0.8108\n",
      "Iter-25; Total loss: 0.7809\n",
      "Iter-26; Total loss: 0.4554\n",
      "Iter-27; Total loss: 0.8792\n",
      "Iter-28; Total loss: 0.863\n",
      "Iter-29; Total loss: 0.663\n",
      "Iter-30; Total loss: 0.6574\n",
      "Iter-31; Total loss: 0.5995\n",
      "Iter-32; Total loss: 0.6235\n",
      "Iter-33; Total loss: 0.5107\n",
      "Iter-34; Total loss: 0.5876\n",
      "Iter-35; Total loss: 0.5125\n",
      "Iter-36; Total loss: 0.6389\n",
      "Iter-37; Total loss: 0.79\n",
      "Iter-38; Total loss: 0.5007\n",
      "Iter-39; Total loss: 0.7297\n",
      "Iter-40; Total loss: 0.578\n",
      "Iter-41; Total loss: 0.5823\n",
      "Iter-42; Total loss: 0.7018\n",
      "Iter-43; Total loss: 0.6158\n",
      "Iter-44; Total loss: 0.48\n",
      "Iter-45; Total loss: 0.614\n",
      "Iter-46; Total loss: 0.4801\n",
      "Iter-47; Total loss: 0.7455\n",
      "Iter-48; Total loss: 0.799\n",
      "Iter-49; Total loss: 0.6124\n",
      "Iter-50; Total loss: 0.7486\n",
      "Iter-51; Total loss: 0.5658\n",
      "Iter-52; Total loss: 0.515\n",
      "Iter-53; Total loss: 0.5072\n",
      "Iter-54; Total loss: 0.4936\n",
      "Iter-55; Total loss: 0.504\n",
      "Iter-56; Total loss: 0.3389\n",
      "Iter-57; Total loss: 0.4671\n",
      "Iter-58; Total loss: 0.5356\n",
      "Iter-59; Total loss: 0.7827\n",
      "Iter-60; Total loss: 0.4565\n",
      "Iter-61; Total loss: 0.5504\n",
      "Iter-62; Total loss: 0.4775\n",
      "Iter-63; Total loss: 0.7085\n",
      "Iter-64; Total loss: 0.6424\n",
      "Iter-65; Total loss: 0.5121\n",
      "Iter-66; Total loss: 0.5777\n",
      "Iter-67; Total loss: 0.6654\n",
      "Iter-68; Total loss: 0.4685\n",
      "Iter-69; Total loss: 0.6602\n",
      "Iter-70; Total loss: 0.6264\n",
      "Iter-71; Total loss: 0.4457\n",
      "Iter-72; Total loss: 0.4997\n",
      "Iter-73; Total loss: 0.6233\n",
      "Iter-74; Total loss: 0.5269\n",
      "Iter-75; Total loss: 0.642\n",
      "Iter-76; Total loss: 0.3802\n",
      "Iter-77; Total loss: 0.5427\n",
      "Iter-78; Total loss: 0.6025\n",
      "Iter-79; Total loss: 0.7262\n",
      "Iter-0; Total loss: 1.471\n",
      "Iter-1; Total loss: 1.078\n",
      "Iter-2; Total loss: 1.403\n",
      "Iter-3; Total loss: 1.146\n",
      "Iter-4; Total loss: 1.113\n",
      "Iter-5; Total loss: 1.01\n",
      "Iter-6; Total loss: 0.9346\n",
      "Iter-7; Total loss: 0.986\n",
      "Iter-8; Total loss: 0.9693\n",
      "Iter-9; Total loss: 0.8007\n",
      "Iter-10; Total loss: 0.8107\n",
      "Iter-11; Total loss: 0.7084\n",
      "Iter-12; Total loss: 0.9196\n",
      "Iter-13; Total loss: 0.8106\n",
      "Iter-14; Total loss: 0.9895\n",
      "Iter-15; Total loss: 0.5825\n",
      "Iter-16; Total loss: 0.7866\n",
      "Iter-17; Total loss: 0.8347\n",
      "Iter-18; Total loss: 0.7129\n",
      "Iter-19; Total loss: 0.603\n",
      "Iter-20; Total loss: 0.6246\n",
      "Iter-21; Total loss: 0.7032\n",
      "Iter-22; Total loss: 0.9099\n",
      "Iter-23; Total loss: 0.7663\n",
      "Iter-24; Total loss: 0.5355\n",
      "Iter-25; Total loss: 0.75\n",
      "Iter-26; Total loss: 0.6979\n",
      "Iter-27; Total loss: 0.6255\n",
      "Iter-28; Total loss: 0.7947\n",
      "Iter-29; Total loss: 0.5546\n",
      "Iter-30; Total loss: 0.7107\n",
      "Iter-31; Total loss: 1.036\n",
      "Iter-32; Total loss: 0.7416\n",
      "Iter-33; Total loss: 0.6987\n",
      "Iter-34; Total loss: 0.6237\n",
      "Iter-35; Total loss: 0.6245\n",
      "Iter-36; Total loss: 0.6746\n",
      "Iter-37; Total loss: 0.6134\n",
      "Iter-38; Total loss: 0.6516\n",
      "Iter-39; Total loss: 0.6093\n",
      "Iter-40; Total loss: 0.5434\n",
      "Iter-41; Total loss: 0.4423\n",
      "Iter-42; Total loss: 0.7405\n",
      "Iter-43; Total loss: 0.7067\n",
      "Iter-44; Total loss: 0.4791\n",
      "Iter-45; Total loss: 0.7759\n",
      "Iter-46; Total loss: 0.6468\n",
      "Iter-47; Total loss: 0.6086\n",
      "Iter-48; Total loss: 0.6934\n",
      "Iter-49; Total loss: 0.5966\n",
      "Iter-50; Total loss: 0.471\n",
      "Iter-51; Total loss: 0.5667\n",
      "Iter-52; Total loss: 0.5151\n",
      "Iter-53; Total loss: 0.4855\n",
      "Iter-54; Total loss: 0.5862\n",
      "Iter-55; Total loss: 0.6235\n",
      "Iter-56; Total loss: 0.4966\n",
      "Iter-57; Total loss: 0.8165\n",
      "Iter-58; Total loss: 0.5579\n",
      "Iter-59; Total loss: 0.5543\n",
      "Iter-60; Total loss: 0.5293\n",
      "Iter-61; Total loss: 0.658\n",
      "Iter-62; Total loss: 0.5272\n",
      "Iter-63; Total loss: 0.5601\n",
      "Iter-64; Total loss: 0.5223\n",
      "Iter-65; Total loss: 0.5044\n",
      "Iter-66; Total loss: 0.4657\n",
      "Iter-67; Total loss: 0.3848\n",
      "Iter-68; Total loss: 0.5111\n",
      "Iter-69; Total loss: 0.6153\n",
      "Iter-70; Total loss: 0.5196\n",
      "Iter-71; Total loss: 0.6234\n",
      "Iter-72; Total loss: 0.4233\n",
      "Iter-73; Total loss: 0.5758\n",
      "Iter-74; Total loss: 0.6509\n",
      "Iter-75; Total loss: 0.6133\n",
      "Iter-76; Total loss: 0.6361\n",
      "Iter-77; Total loss: 0.4825\n",
      "Iter-78; Total loss: 0.4718\n",
      "Iter-79; Total loss: 0.6252\n",
      "Iter-0; Total loss: 1.371\n",
      "Iter-1; Total loss: 1.07\n",
      "Iter-2; Total loss: 1.284\n",
      "Iter-3; Total loss: 0.9607\n",
      "Iter-4; Total loss: 0.8625\n",
      "Iter-5; Total loss: 0.993\n",
      "Iter-6; Total loss: 1.149\n",
      "Iter-7; Total loss: 0.9932\n",
      "Iter-8; Total loss: 1.131\n",
      "Iter-9; Total loss: 0.9413\n",
      "Iter-10; Total loss: 0.7979\n",
      "Iter-11; Total loss: 0.8921\n",
      "Iter-12; Total loss: 0.7127\n",
      "Iter-13; Total loss: 0.7094\n",
      "Iter-14; Total loss: 0.8506\n",
      "Iter-15; Total loss: 0.7113\n",
      "Iter-16; Total loss: 0.9925\n",
      "Iter-17; Total loss: 0.8227\n",
      "Iter-18; Total loss: 1.017\n",
      "Iter-19; Total loss: 0.7476\n",
      "Iter-20; Total loss: 0.8911\n",
      "Iter-21; Total loss: 0.6073\n",
      "Iter-22; Total loss: 0.8613\n",
      "Iter-23; Total loss: 0.5977\n",
      "Iter-24; Total loss: 0.5277\n",
      "Iter-25; Total loss: 0.6544\n",
      "Iter-26; Total loss: 0.5479\n",
      "Iter-27; Total loss: 0.8716\n",
      "Iter-28; Total loss: 0.7755\n",
      "Iter-29; Total loss: 0.5854\n",
      "Iter-30; Total loss: 0.6303\n",
      "Iter-31; Total loss: 0.6898\n",
      "Iter-32; Total loss: 0.5901\n",
      "Iter-33; Total loss: 0.4841\n",
      "Iter-34; Total loss: 0.7995\n",
      "Iter-35; Total loss: 0.6025\n",
      "Iter-36; Total loss: 0.6745\n",
      "Iter-37; Total loss: 0.6099\n",
      "Iter-38; Total loss: 0.819\n",
      "Iter-39; Total loss: 0.6176\n",
      "Iter-40; Total loss: 0.6186\n",
      "Iter-41; Total loss: 0.4671\n",
      "Iter-42; Total loss: 0.5977\n",
      "Iter-43; Total loss: 0.758\n",
      "Iter-44; Total loss: 0.6287\n",
      "Iter-45; Total loss: 0.5077\n",
      "Iter-46; Total loss: 0.7366\n",
      "Iter-47; Total loss: 0.7744\n",
      "Iter-48; Total loss: 0.6046\n",
      "Iter-49; Total loss: 0.7126\n",
      "Iter-50; Total loss: 0.5851\n",
      "Iter-51; Total loss: 0.4074\n",
      "Iter-52; Total loss: 0.644\n",
      "Iter-53; Total loss: 0.6016\n",
      "Iter-54; Total loss: 0.5234\n",
      "Iter-55; Total loss: 0.6929\n",
      "Iter-56; Total loss: 0.6374\n",
      "Iter-57; Total loss: 0.6162\n",
      "Iter-58; Total loss: 0.5668\n",
      "Iter-59; Total loss: 0.5728\n",
      "Iter-60; Total loss: 0.6001\n",
      "Iter-61; Total loss: 0.7284\n",
      "Iter-62; Total loss: 0.6527\n",
      "Iter-63; Total loss: 0.5019\n",
      "Iter-64; Total loss: 0.5688\n",
      "Iter-65; Total loss: 0.4997\n",
      "Iter-66; Total loss: 0.6956\n",
      "Iter-67; Total loss: 0.6541\n",
      "Iter-68; Total loss: 0.5627\n",
      "Iter-69; Total loss: 0.5965\n",
      "Iter-70; Total loss: 0.5504\n",
      "Iter-71; Total loss: 0.6423\n",
      "Iter-72; Total loss: 0.6791\n",
      "Iter-73; Total loss: 0.327\n",
      "Iter-74; Total loss: 0.363\n",
      "Iter-75; Total loss: 0.4801\n",
      "Iter-76; Total loss: 0.4311\n",
      "Iter-77; Total loss: 0.5278\n",
      "Iter-78; Total loss: 0.5904\n",
      "Iter-79; Total loss: 0.5276\n",
      "Iter-0; Total loss: 1.398\n",
      "Iter-1; Total loss: 1.355\n",
      "Iter-2; Total loss: 1.025\n",
      "Iter-3; Total loss: 1.172\n",
      "Iter-4; Total loss: 1.061\n",
      "Iter-5; Total loss: 1.002\n",
      "Iter-6; Total loss: 1.187\n",
      "Iter-7; Total loss: 1.072\n",
      "Iter-8; Total loss: 0.8468\n",
      "Iter-9; Total loss: 0.886\n",
      "Iter-10; Total loss: 0.9025\n",
      "Iter-11; Total loss: 0.8706\n",
      "Iter-12; Total loss: 0.699\n",
      "Iter-13; Total loss: 0.8495\n",
      "Iter-14; Total loss: 0.6553\n",
      "Iter-15; Total loss: 0.6178\n",
      "Iter-16; Total loss: 0.7691\n",
      "Iter-17; Total loss: 0.6751\n",
      "Iter-18; Total loss: 0.8572\n",
      "Iter-19; Total loss: 0.7632\n",
      "Iter-20; Total loss: 0.8462\n",
      "Iter-21; Total loss: 0.6714\n",
      "Iter-22; Total loss: 0.8196\n",
      "Iter-23; Total loss: 0.7303\n",
      "Iter-24; Total loss: 0.7112\n",
      "Iter-25; Total loss: 0.5205\n",
      "Iter-26; Total loss: 0.8297\n",
      "Iter-27; Total loss: 0.5684\n",
      "Iter-28; Total loss: 0.431\n",
      "Iter-29; Total loss: 0.6906\n",
      "Iter-30; Total loss: 0.53\n",
      "Iter-31; Total loss: 0.5553\n",
      "Iter-32; Total loss: 0.4972\n",
      "Iter-33; Total loss: 0.4523\n",
      "Iter-34; Total loss: 0.6214\n",
      "Iter-35; Total loss: 0.8173\n",
      "Iter-36; Total loss: 0.6641\n",
      "Iter-37; Total loss: 0.5677\n",
      "Iter-38; Total loss: 0.6182\n",
      "Iter-39; Total loss: 0.8078\n",
      "Iter-40; Total loss: 0.799\n",
      "Iter-41; Total loss: 0.4992\n",
      "Iter-42; Total loss: 0.6535\n",
      "Iter-43; Total loss: 0.5\n",
      "Iter-44; Total loss: 0.7124\n",
      "Iter-45; Total loss: 0.6374\n",
      "Iter-46; Total loss: 0.6143\n",
      "Iter-47; Total loss: 0.5186\n",
      "Iter-48; Total loss: 0.4739\n",
      "Iter-49; Total loss: 0.5723\n",
      "Iter-50; Total loss: 0.6389\n",
      "Iter-51; Total loss: 0.5301\n",
      "Iter-52; Total loss: 0.5708\n",
      "Iter-53; Total loss: 0.5973\n",
      "Iter-54; Total loss: 0.5258\n",
      "Iter-55; Total loss: 0.6123\n",
      "Iter-56; Total loss: 0.5059\n",
      "Iter-57; Total loss: 0.5113\n",
      "Iter-58; Total loss: 0.6146\n",
      "Iter-59; Total loss: 0.488\n",
      "Iter-60; Total loss: 0.5291\n",
      "Iter-61; Total loss: 0.5449\n",
      "Iter-62; Total loss: 0.7827\n",
      "Iter-63; Total loss: 0.5348\n",
      "Iter-64; Total loss: 0.5283\n",
      "Iter-65; Total loss: 0.4248\n",
      "Iter-66; Total loss: 0.5356\n",
      "Iter-67; Total loss: 0.6388\n",
      "Iter-68; Total loss: 0.5394\n",
      "Iter-69; Total loss: 0.6019\n",
      "Iter-70; Total loss: 0.6708\n",
      "Iter-71; Total loss: 0.5786\n",
      "Iter-72; Total loss: 0.5881\n",
      "Iter-73; Total loss: 0.519\n",
      "Iter-74; Total loss: 0.3252\n",
      "Iter-75; Total loss: 0.7211\n",
      "Iter-76; Total loss: 0.4775\n",
      "Iter-77; Total loss: 0.5114\n",
      "Iter-78; Total loss: 0.417\n",
      "Iter-79; Total loss: 0.6566\n",
      "Iter-0; Total loss: 0.8273\n",
      "Iter-1; Total loss: 0.8605\n",
      "Iter-2; Total loss: 0.7981\n",
      "Iter-3; Total loss: 0.8187\n",
      "Iter-4; Total loss: 0.7751\n",
      "Iter-5; Total loss: 0.7177\n",
      "Iter-6; Total loss: 0.8052\n",
      "Iter-7; Total loss: 0.7293\n",
      "Iter-8; Total loss: 0.7766\n",
      "Iter-9; Total loss: 0.7536\n",
      "Iter-10; Total loss: 0.7048\n",
      "Iter-11; Total loss: 0.6323\n",
      "Iter-12; Total loss: 0.7292\n",
      "Iter-13; Total loss: 0.8238\n",
      "Iter-14; Total loss: 0.7665\n",
      "Iter-15; Total loss: 0.7648\n",
      "Iter-16; Total loss: 0.6409\n",
      "Iter-17; Total loss: 0.599\n",
      "Iter-18; Total loss: 0.8011\n",
      "Iter-19; Total loss: 0.6461\n",
      "Iter-20; Total loss: 0.6548\n",
      "Iter-21; Total loss: 0.727\n",
      "Iter-22; Total loss: 0.7972\n",
      "Iter-23; Total loss: 0.7345\n",
      "Iter-24; Total loss: 0.5982\n",
      "Iter-25; Total loss: 0.691\n",
      "Iter-26; Total loss: 0.7682\n",
      "Iter-27; Total loss: 0.6341\n",
      "Iter-28; Total loss: 0.6402\n",
      "Iter-29; Total loss: 0.7501\n",
      "Iter-30; Total loss: 0.6431\n",
      "Iter-31; Total loss: 0.6455\n",
      "Iter-32; Total loss: 0.566\n",
      "Iter-33; Total loss: 0.59\n",
      "Iter-34; Total loss: 0.8086\n",
      "Iter-35; Total loss: 0.6051\n",
      "Iter-36; Total loss: 0.6594\n",
      "Iter-37; Total loss: 0.7457\n",
      "Iter-38; Total loss: 0.5392\n",
      "Iter-39; Total loss: 0.7819\n",
      "Iter-40; Total loss: 0.7111\n",
      "Iter-41; Total loss: 0.6765\n",
      "Iter-42; Total loss: 0.5922\n",
      "Iter-43; Total loss: 0.6885\n",
      "Iter-44; Total loss: 0.6242\n",
      "Iter-45; Total loss: 0.4933\n",
      "Iter-46; Total loss: 0.6944\n",
      "Iter-47; Total loss: 0.696\n",
      "Iter-48; Total loss: 0.5189\n",
      "Iter-49; Total loss: 0.629\n",
      "Iter-50; Total loss: 0.7131\n",
      "Iter-51; Total loss: 0.6164\n",
      "Iter-52; Total loss: 0.5475\n",
      "Iter-53; Total loss: 0.7625\n",
      "Iter-54; Total loss: 0.5591\n",
      "Iter-55; Total loss: 0.5436\n",
      "Iter-56; Total loss: 0.6474\n",
      "Iter-57; Total loss: 0.5637\n",
      "Iter-58; Total loss: 0.6291\n",
      "Iter-59; Total loss: 0.6228\n",
      "Iter-60; Total loss: 0.5904\n",
      "Iter-61; Total loss: 0.6091\n",
      "Iter-62; Total loss: 0.3944\n",
      "Iter-63; Total loss: 0.5515\n",
      "Iter-64; Total loss: 0.6351\n",
      "Iter-65; Total loss: 0.6475\n",
      "Iter-66; Total loss: 0.5226\n",
      "Iter-67; Total loss: 0.4839\n",
      "Iter-68; Total loss: 0.6402\n",
      "Iter-69; Total loss: 0.6578\n",
      "Iter-70; Total loss: 0.5321\n",
      "Iter-71; Total loss: 0.5822\n",
      "Iter-72; Total loss: 0.5767\n",
      "Iter-73; Total loss: 0.6154\n",
      "Iter-74; Total loss: 0.6638\n",
      "Iter-75; Total loss: 0.5259\n",
      "Iter-76; Total loss: 0.7458\n",
      "Iter-77; Total loss: 0.6499\n",
      "Iter-78; Total loss: 0.5491\n",
      "Iter-79; Total loss: 0.5383\n",
      "Iter-80; Total loss: 0.6422\n",
      "Iter-81; Total loss: 0.5823\n",
      "Iter-82; Total loss: 0.6714\n",
      "Iter-83; Total loss: 0.6946\n",
      "Iter-84; Total loss: 0.6612\n",
      "Iter-85; Total loss: 0.6003\n",
      "Iter-86; Total loss: 0.628\n",
      "Iter-87; Total loss: 0.5803\n",
      "Iter-88; Total loss: 0.6191\n",
      "Iter-89; Total loss: 0.6882\n",
      "Iter-0; Total loss: 0.8242\n",
      "Iter-1; Total loss: 0.9839\n",
      "Iter-2; Total loss: 0.8112\n",
      "Iter-3; Total loss: 0.8774\n",
      "Iter-4; Total loss: 0.6945\n",
      "Iter-5; Total loss: 0.9189\n",
      "Iter-6; Total loss: 0.7616\n",
      "Iter-7; Total loss: 0.7524\n",
      "Iter-8; Total loss: 0.8067\n",
      "Iter-9; Total loss: 0.7206\n",
      "Iter-10; Total loss: 0.7691\n",
      "Iter-11; Total loss: 0.7402\n",
      "Iter-12; Total loss: 0.8609\n",
      "Iter-13; Total loss: 0.7253\n",
      "Iter-14; Total loss: 0.6989\n",
      "Iter-15; Total loss: 0.7784\n",
      "Iter-16; Total loss: 0.743\n",
      "Iter-17; Total loss: 0.7119\n",
      "Iter-18; Total loss: 0.8048\n",
      "Iter-19; Total loss: 0.7079\n",
      "Iter-20; Total loss: 0.6399\n",
      "Iter-21; Total loss: 0.6413\n",
      "Iter-22; Total loss: 0.6161\n",
      "Iter-23; Total loss: 0.5592\n",
      "Iter-24; Total loss: 0.685\n",
      "Iter-25; Total loss: 0.5919\n",
      "Iter-26; Total loss: 0.6786\n",
      "Iter-27; Total loss: 0.6751\n",
      "Iter-28; Total loss: 0.4731\n",
      "Iter-29; Total loss: 0.6279\n",
      "Iter-30; Total loss: 0.5414\n",
      "Iter-31; Total loss: 0.5933\n",
      "Iter-32; Total loss: 0.6867\n",
      "Iter-33; Total loss: 0.6262\n",
      "Iter-34; Total loss: 0.6709\n",
      "Iter-35; Total loss: 0.602\n",
      "Iter-36; Total loss: 0.6753\n",
      "Iter-37; Total loss: 0.6187\n",
      "Iter-38; Total loss: 0.6605\n",
      "Iter-39; Total loss: 0.6867\n",
      "Iter-40; Total loss: 0.5951\n",
      "Iter-41; Total loss: 0.6257\n",
      "Iter-42; Total loss: 0.7017\n",
      "Iter-43; Total loss: 0.6064\n",
      "Iter-44; Total loss: 0.6445\n",
      "Iter-45; Total loss: 0.5733\n",
      "Iter-46; Total loss: 0.6288\n",
      "Iter-47; Total loss: 0.6709\n",
      "Iter-48; Total loss: 0.5528\n",
      "Iter-49; Total loss: 0.7031\n",
      "Iter-50; Total loss: 0.7598\n",
      "Iter-51; Total loss: 0.6663\n",
      "Iter-52; Total loss: 0.765\n",
      "Iter-53; Total loss: 0.5098\n",
      "Iter-54; Total loss: 0.636\n",
      "Iter-55; Total loss: 0.6875\n",
      "Iter-56; Total loss: 0.5513\n",
      "Iter-57; Total loss: 0.6411\n",
      "Iter-58; Total loss: 0.6989\n",
      "Iter-59; Total loss: 0.5933\n",
      "Iter-60; Total loss: 0.5349\n",
      "Iter-61; Total loss: 0.5698\n",
      "Iter-62; Total loss: 0.5666\n",
      "Iter-63; Total loss: 0.6005\n",
      "Iter-64; Total loss: 0.5578\n",
      "Iter-65; Total loss: 0.6398\n",
      "Iter-66; Total loss: 0.5905\n",
      "Iter-67; Total loss: 0.6317\n",
      "Iter-68; Total loss: 0.623\n",
      "Iter-69; Total loss: 0.5535\n",
      "Iter-70; Total loss: 0.6097\n",
      "Iter-71; Total loss: 0.5844\n",
      "Iter-72; Total loss: 0.587\n",
      "Iter-73; Total loss: 0.559\n",
      "Iter-74; Total loss: 0.6508\n",
      "Iter-75; Total loss: 0.6094\n",
      "Iter-76; Total loss: 0.6884\n",
      "Iter-77; Total loss: 0.5194\n",
      "Iter-78; Total loss: 0.6852\n",
      "Iter-79; Total loss: 0.5024\n",
      "Iter-80; Total loss: 0.6612\n",
      "Iter-81; Total loss: 0.5455\n",
      "Iter-82; Total loss: 0.4828\n",
      "Iter-83; Total loss: 0.6112\n",
      "Iter-84; Total loss: 0.6263\n",
      "Iter-85; Total loss: 0.4552\n",
      "Iter-86; Total loss: 0.5277\n",
      "Iter-87; Total loss: 0.5546\n",
      "Iter-88; Total loss: 0.5899\n",
      "Iter-89; Total loss: 0.6486\n",
      "Iter-0; Total loss: 0.9577\n",
      "Iter-1; Total loss: 0.8715\n",
      "Iter-2; Total loss: 0.8808\n",
      "Iter-3; Total loss: 0.8392\n",
      "Iter-4; Total loss: 0.8171\n",
      "Iter-5; Total loss: 0.9276\n",
      "Iter-6; Total loss: 0.86\n",
      "Iter-7; Total loss: 0.8549\n",
      "Iter-8; Total loss: 0.8227\n",
      "Iter-9; Total loss: 0.8578\n",
      "Iter-10; Total loss: 0.6146\n",
      "Iter-11; Total loss: 0.818\n",
      "Iter-12; Total loss: 0.6751\n",
      "Iter-13; Total loss: 0.6906\n",
      "Iter-14; Total loss: 0.7304\n",
      "Iter-15; Total loss: 0.747\n",
      "Iter-16; Total loss: 0.5699\n",
      "Iter-17; Total loss: 0.5896\n",
      "Iter-18; Total loss: 0.8295\n",
      "Iter-19; Total loss: 0.7826\n",
      "Iter-20; Total loss: 0.7604\n",
      "Iter-21; Total loss: 0.6312\n",
      "Iter-22; Total loss: 0.6512\n",
      "Iter-23; Total loss: 0.7524\n",
      "Iter-24; Total loss: 0.4907\n",
      "Iter-25; Total loss: 0.5574\n",
      "Iter-26; Total loss: 0.5521\n",
      "Iter-27; Total loss: 0.7034\n",
      "Iter-28; Total loss: 0.652\n",
      "Iter-29; Total loss: 0.7259\n",
      "Iter-30; Total loss: 0.6907\n",
      "Iter-31; Total loss: 0.7335\n",
      "Iter-32; Total loss: 0.6696\n",
      "Iter-33; Total loss: 0.6749\n",
      "Iter-34; Total loss: 0.6644\n",
      "Iter-35; Total loss: 0.4831\n",
      "Iter-36; Total loss: 0.6429\n",
      "Iter-37; Total loss: 0.6831\n",
      "Iter-38; Total loss: 0.6546\n",
      "Iter-39; Total loss: 0.6774\n",
      "Iter-40; Total loss: 0.6155\n",
      "Iter-41; Total loss: 0.6183\n",
      "Iter-42; Total loss: 0.6312\n",
      "Iter-43; Total loss: 0.6953\n",
      "Iter-44; Total loss: 0.6331\n",
      "Iter-45; Total loss: 0.6583\n",
      "Iter-46; Total loss: 0.7003\n",
      "Iter-47; Total loss: 0.5886\n",
      "Iter-48; Total loss: 0.6672\n",
      "Iter-49; Total loss: 0.695\n",
      "Iter-50; Total loss: 0.5345\n",
      "Iter-51; Total loss: 0.5556\n",
      "Iter-52; Total loss: 0.6466\n",
      "Iter-53; Total loss: 0.6439\n",
      "Iter-54; Total loss: 0.6323\n",
      "Iter-55; Total loss: 0.6398\n",
      "Iter-56; Total loss: 0.6057\n",
      "Iter-57; Total loss: 0.648\n",
      "Iter-58; Total loss: 0.6028\n",
      "Iter-59; Total loss: 0.7213\n",
      "Iter-60; Total loss: 0.5954\n",
      "Iter-61; Total loss: 0.605\n",
      "Iter-62; Total loss: 0.5336\n",
      "Iter-63; Total loss: 0.5907\n",
      "Iter-64; Total loss: 0.6962\n",
      "Iter-65; Total loss: 0.5969\n",
      "Iter-66; Total loss: 0.5873\n",
      "Iter-67; Total loss: 0.6106\n",
      "Iter-68; Total loss: 0.6753\n",
      "Iter-69; Total loss: 0.661\n",
      "Iter-70; Total loss: 0.6189\n",
      "Iter-71; Total loss: 0.6461\n",
      "Iter-72; Total loss: 0.5506\n",
      "Iter-73; Total loss: 0.5883\n",
      "Iter-74; Total loss: 0.6197\n",
      "Iter-75; Total loss: 0.5489\n",
      "Iter-76; Total loss: 0.5152\n",
      "Iter-77; Total loss: 0.4647\n",
      "Iter-78; Total loss: 0.623\n",
      "Iter-79; Total loss: 0.5389\n",
      "Iter-80; Total loss: 0.5568\n",
      "Iter-81; Total loss: 0.6868\n",
      "Iter-82; Total loss: 0.5668\n",
      "Iter-83; Total loss: 0.6503\n",
      "Iter-84; Total loss: 0.5121\n",
      "Iter-85; Total loss: 0.7241\n",
      "Iter-86; Total loss: 0.6393\n",
      "Iter-87; Total loss: 0.679\n",
      "Iter-88; Total loss: 0.5858\n",
      "Iter-89; Total loss: 0.5669\n",
      "Iter-0; Total loss: 0.903\n",
      "Iter-1; Total loss: 0.757\n",
      "Iter-2; Total loss: 0.8863\n",
      "Iter-3; Total loss: 0.9507\n",
      "Iter-4; Total loss: 0.8246\n",
      "Iter-5; Total loss: 0.7499\n",
      "Iter-6; Total loss: 0.7609\n",
      "Iter-7; Total loss: 0.8848\n",
      "Iter-8; Total loss: 0.7734\n",
      "Iter-9; Total loss: 0.7381\n",
      "Iter-10; Total loss: 0.7178\n",
      "Iter-11; Total loss: 0.6626\n",
      "Iter-12; Total loss: 0.6586\n",
      "Iter-13; Total loss: 0.84\n",
      "Iter-14; Total loss: 0.7101\n",
      "Iter-15; Total loss: 0.7302\n",
      "Iter-16; Total loss: 0.658\n",
      "Iter-17; Total loss: 0.7302\n",
      "Iter-18; Total loss: 0.737\n",
      "Iter-19; Total loss: 0.6742\n",
      "Iter-20; Total loss: 0.5662\n",
      "Iter-21; Total loss: 0.6014\n",
      "Iter-22; Total loss: 0.6656\n",
      "Iter-23; Total loss: 0.7209\n",
      "Iter-24; Total loss: 0.7203\n",
      "Iter-25; Total loss: 0.6459\n",
      "Iter-26; Total loss: 0.6465\n",
      "Iter-27; Total loss: 0.6025\n",
      "Iter-28; Total loss: 0.6931\n",
      "Iter-29; Total loss: 0.6398\n",
      "Iter-30; Total loss: 0.47\n",
      "Iter-31; Total loss: 0.6818\n",
      "Iter-32; Total loss: 0.5874\n",
      "Iter-33; Total loss: 0.6014\n",
      "Iter-34; Total loss: 0.6552\n",
      "Iter-35; Total loss: 0.7248\n",
      "Iter-36; Total loss: 0.5973\n",
      "Iter-37; Total loss: 0.6225\n",
      "Iter-38; Total loss: 0.681\n",
      "Iter-39; Total loss: 0.6319\n",
      "Iter-40; Total loss: 0.7538\n",
      "Iter-41; Total loss: 0.6699\n",
      "Iter-42; Total loss: 0.7191\n",
      "Iter-43; Total loss: 0.6918\n",
      "Iter-44; Total loss: 0.5979\n",
      "Iter-45; Total loss: 0.6508\n",
      "Iter-46; Total loss: 0.7152\n",
      "Iter-47; Total loss: 0.7052\n",
      "Iter-48; Total loss: 0.6217\n",
      "Iter-49; Total loss: 0.7513\n",
      "Iter-50; Total loss: 0.6266\n",
      "Iter-51; Total loss: 0.6919\n",
      "Iter-52; Total loss: 0.6237\n",
      "Iter-53; Total loss: 0.7241\n",
      "Iter-54; Total loss: 0.6118\n",
      "Iter-55; Total loss: 0.6911\n",
      "Iter-56; Total loss: 0.6159\n",
      "Iter-57; Total loss: 0.7032\n",
      "Iter-58; Total loss: 0.6316\n",
      "Iter-59; Total loss: 0.6846\n",
      "Iter-60; Total loss: 0.5287\n",
      "Iter-61; Total loss: 0.6085\n",
      "Iter-62; Total loss: 0.6945\n",
      "Iter-63; Total loss: 0.5256\n",
      "Iter-64; Total loss: 0.6664\n",
      "Iter-65; Total loss: 0.5659\n",
      "Iter-66; Total loss: 0.4847\n",
      "Iter-67; Total loss: 0.6143\n",
      "Iter-68; Total loss: 0.7054\n",
      "Iter-69; Total loss: 0.7101\n",
      "Iter-70; Total loss: 0.6313\n",
      "Iter-71; Total loss: 0.6174\n",
      "Iter-72; Total loss: 0.6912\n",
      "Iter-73; Total loss: 0.6949\n",
      "Iter-74; Total loss: 0.6756\n",
      "Iter-75; Total loss: 0.6687\n",
      "Iter-76; Total loss: 0.5509\n",
      "Iter-77; Total loss: 0.4549\n",
      "Iter-78; Total loss: 0.6468\n",
      "Iter-79; Total loss: 0.6917\n",
      "Iter-80; Total loss: 0.5882\n",
      "Iter-81; Total loss: 0.7227\n",
      "Iter-82; Total loss: 0.6261\n",
      "Iter-83; Total loss: 0.5813\n",
      "Iter-84; Total loss: 0.4982\n",
      "Iter-85; Total loss: 0.7209\n",
      "Iter-86; Total loss: 0.6225\n",
      "Iter-87; Total loss: 0.6625\n",
      "Iter-88; Total loss: 0.5514\n",
      "Iter-89; Total loss: 0.6475\n",
      "Iter-0; Total loss: 0.9331\n",
      "Iter-1; Total loss: 1.001\n",
      "Iter-2; Total loss: 0.972\n",
      "Iter-3; Total loss: 0.9011\n",
      "Iter-4; Total loss: 0.7951\n",
      "Iter-5; Total loss: 0.8927\n",
      "Iter-6; Total loss: 0.7977\n",
      "Iter-7; Total loss: 0.7884\n",
      "Iter-8; Total loss: 0.6807\n",
      "Iter-9; Total loss: 0.8724\n",
      "Iter-10; Total loss: 0.7081\n",
      "Iter-11; Total loss: 0.8426\n",
      "Iter-12; Total loss: 0.8152\n",
      "Iter-13; Total loss: 0.7303\n",
      "Iter-14; Total loss: 0.7072\n",
      "Iter-15; Total loss: 0.6754\n",
      "Iter-16; Total loss: 0.5979\n",
      "Iter-17; Total loss: 0.7676\n",
      "Iter-18; Total loss: 0.7315\n",
      "Iter-19; Total loss: 0.6629\n",
      "Iter-20; Total loss: 0.7361\n",
      "Iter-21; Total loss: 0.6929\n",
      "Iter-22; Total loss: 0.7458\n",
      "Iter-23; Total loss: 0.6715\n",
      "Iter-24; Total loss: 0.711\n",
      "Iter-25; Total loss: 0.6788\n",
      "Iter-26; Total loss: 0.6119\n",
      "Iter-27; Total loss: 0.5956\n",
      "Iter-28; Total loss: 0.6974\n",
      "Iter-29; Total loss: 0.6552\n",
      "Iter-30; Total loss: 0.7656\n",
      "Iter-31; Total loss: 0.5028\n",
      "Iter-32; Total loss: 0.5677\n",
      "Iter-33; Total loss: 0.6864\n",
      "Iter-34; Total loss: 0.6385\n",
      "Iter-35; Total loss: 0.7371\n",
      "Iter-36; Total loss: 0.6033\n",
      "Iter-37; Total loss: 0.6303\n",
      "Iter-38; Total loss: 0.6208\n",
      "Iter-39; Total loss: 0.7129\n",
      "Iter-40; Total loss: 0.5332\n",
      "Iter-41; Total loss: 0.7109\n",
      "Iter-42; Total loss: 0.6736\n",
      "Iter-43; Total loss: 0.6477\n",
      "Iter-44; Total loss: 0.6963\n",
      "Iter-45; Total loss: 0.6683\n",
      "Iter-46; Total loss: 0.4856\n",
      "Iter-47; Total loss: 0.6303\n",
      "Iter-48; Total loss: 0.6271\n",
      "Iter-49; Total loss: 0.5967\n",
      "Iter-50; Total loss: 0.6868\n",
      "Iter-51; Total loss: 0.5947\n",
      "Iter-52; Total loss: 0.4657\n",
      "Iter-53; Total loss: 0.4824\n",
      "Iter-54; Total loss: 0.6033\n",
      "Iter-55; Total loss: 0.6393\n",
      "Iter-56; Total loss: 0.6898\n",
      "Iter-57; Total loss: 0.6878\n",
      "Iter-58; Total loss: 0.5965\n",
      "Iter-59; Total loss: 0.5722\n",
      "Iter-60; Total loss: 0.6419\n",
      "Iter-61; Total loss: 0.7088\n",
      "Iter-62; Total loss: 0.5385\n",
      "Iter-63; Total loss: 0.6881\n",
      "Iter-64; Total loss: 0.651\n",
      "Iter-65; Total loss: 0.6153\n",
      "Iter-66; Total loss: 0.5777\n",
      "Iter-67; Total loss: 0.5793\n",
      "Iter-68; Total loss: 0.6275\n",
      "Iter-69; Total loss: 0.5113\n",
      "Iter-70; Total loss: 0.6392\n",
      "Iter-71; Total loss: 0.5866\n",
      "Iter-72; Total loss: 0.5977\n",
      "Iter-73; Total loss: 0.6604\n",
      "Iter-74; Total loss: 0.5163\n",
      "Iter-75; Total loss: 0.611\n",
      "Iter-76; Total loss: 0.618\n",
      "Iter-77; Total loss: 0.643\n",
      "Iter-78; Total loss: 0.5823\n",
      "Iter-79; Total loss: 0.6489\n",
      "Iter-80; Total loss: 0.5948\n",
      "Iter-81; Total loss: 0.5203\n",
      "Iter-82; Total loss: 0.5607\n",
      "Iter-83; Total loss: 0.6195\n",
      "Iter-84; Total loss: 0.5689\n",
      "Iter-85; Total loss: 0.463\n",
      "Iter-86; Total loss: 0.576\n",
      "Iter-87; Total loss: 0.7039\n",
      "Iter-88; Total loss: 0.5459\n",
      "Iter-89; Total loss: 0.6517\n"
     ]
    }
   ],
   "source": [
    "for iters in range(89, max_iter):\n",
    "    k = 0\n",
    "    mbs = 30\n",
    "    hdm1 = random.choice(ls_h_dim)\n",
    "    hdm2 = random.choice(ls_h_dim)\n",
    "    hdm3 = random.choice(ls_h_dim) \n",
    "    mrg = random.choice(ls_marg)\n",
    "    lre = random.choice(ls_lr)\n",
    "    lrm = random.choice(ls_lr)\n",
    "    lrc = random.choice(ls_lr)\n",
    "    lrCL = random.choice(ls_lr)\n",
    "    epch = random.choice(ls_epoch)\n",
    "    rate1 = random.choice(ls_rate)\n",
    "    rate2 = random.choice(ls_rate)\n",
    "    rate3 = random.choice(ls_rate)\n",
    "    rate4 = random.choice(ls_rate)    \n",
    "    wd = random.choice(ls_wd)   \n",
    "    lam = random.choice(ls_lam)   \n",
    "\n",
    "    for train_index, test_index in skf.split(GDSCE.values, Y):\n",
    "        k = k + 1\n",
    "        X_trainE = GDSCE.values[train_index,:]\n",
    "        X_testE =  GDSCE.values[test_index,:]\n",
    "        X_trainM = GDSCM.values[train_index,:]\n",
    "        X_testM = GDSCM.values[test_index,:]\n",
    "        X_trainC = GDSCC.values[train_index,:]\n",
    "        X_testC = GDSCC.values[test_index,:]\n",
    "        y_trainE = Y[train_index]\n",
    "        y_testE = Y[test_index]\n",
    "        \n",
    "        scalerGDSC = sk.StandardScaler()\n",
    "        scalerGDSC.fit(X_trainE)\n",
    "        X_trainE = scalerGDSC.transform(X_trainE)\n",
    "        X_testE = scalerGDSC.transform(X_testE)\n",
    "        # Notice that only expression data is standardized\n",
    "        # This is as the mutation and the CNA data used here are binary\n",
    "\n",
    "        X_trainM = np.nan_to_num(X_trainM)\n",
    "        X_trainC = np.nan_to_num(X_trainC)\n",
    "        X_testM = np.nan_to_num(X_testM)\n",
    "        X_testC = np.nan_to_num(X_testC)\n",
    "        # np.nan_to_numpy Replace NaN with zero and infinity with large finite numbers\n",
    "        \n",
    "        TX_testE = torch.FloatTensor(X_testE)\n",
    "        TX_testM = torch.FloatTensor(X_testM)\n",
    "        TX_testC = torch.FloatTensor(X_testC)\n",
    "        ty_testE = torch.FloatTensor(y_testE.astype(int))\n",
    "        \n",
    "        #Train\n",
    "        class_sample_count = np.array([len(np.where(y_trainE==t)[0]) for t in np.unique(y_trainE)])\n",
    "        weight = 1. / class_sample_count\n",
    "        samples_weight = np.array([weight[t] for t in y_trainE])\n",
    "\n",
    "        samples_weight = torch.from_numpy(samples_weight)\n",
    "        sampler = WeightedRandomSampler(samples_weight.type('torch.DoubleTensor'), len(samples_weight), replacement=True)\n",
    "         # The sampler is created to artificially augment the number of positive classes inside each minibatch, as the number of positive classes is very low.\n",
    "        mb_size = mbs\n",
    "\n",
    "        trainDataset = torch.utils.data.TensorDataset(torch.FloatTensor(X_trainE), torch.FloatTensor(X_trainM), \n",
    "                                                      torch.FloatTensor(X_trainC), torch.FloatTensor(y_trainE.astype(int)))\n",
    "\n",
    "        trainLoader = torch.utils.data.DataLoader(dataset = trainDataset, batch_size=mb_size, shuffle=False, num_workers=1, sampler = sampler)\n",
    "\n",
    "        n_sampE, IE_dim = X_trainE.shape\n",
    "        n_sampM, IM_dim = X_trainM.shape\n",
    "        n_sampC, IC_dim = X_trainC.shape\n",
    "\n",
    "        h_dim1 = hdm1\n",
    "        h_dim2 = hdm2\n",
    "        h_dim3 = hdm3        \n",
    "        Z_in = h_dim1 + h_dim2 + h_dim3\n",
    "        marg = mrg\n",
    "        lrE = lre\n",
    "        lrM = lrm\n",
    "        lrC = lrc\n",
    "        epoch = epch\n",
    "\n",
    "        costtr = []\n",
    "        auctr = []\n",
    "        costts = []\n",
    "        aucts = []\n",
    "\n",
    "        triplet_selector = RandomNegativeTripletSelector(marg)\n",
    "        triplet_selector2 = AllTripletSelector()\n",
    "\n",
    "        class AEE(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(AEE, self).__init__()\n",
    "                self.EnE = torch.nn.Sequential(\n",
    "                    nn.Linear(IE_dim, h_dim1),\n",
    "                    nn.BatchNorm1d(h_dim1),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(rate1))\n",
    "            def forward(self, x):\n",
    "                output = self.EnE(x)\n",
    "                return output\n",
    "\n",
    "        class AEM(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(AEM, self).__init__()\n",
    "                self.EnM = torch.nn.Sequential(\n",
    "                    nn.Linear(IM_dim, h_dim2),\n",
    "                    nn.BatchNorm1d(h_dim2),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(rate2))\n",
    "            def forward(self, x):\n",
    "                output = self.EnM(x)\n",
    "                return output    \n",
    "\n",
    "\n",
    "        class AEC(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(AEC, self).__init__()\n",
    "                self.EnC = torch.nn.Sequential(\n",
    "                    nn.Linear(IM_dim, h_dim3),\n",
    "                    nn.BatchNorm1d(h_dim3),\n",
    "                    nn.ReLU(),\n",
    "                    nn.Dropout(rate3))\n",
    "            def forward(self, x):\n",
    "                output = self.EnC(x)\n",
    "                return output    \n",
    "\n",
    "        class OnlineTriplet(nn.Module):\n",
    "            def __init__(self, marg, triplet_selector):\n",
    "                super(OnlineTriplet, self).__init__()\n",
    "                self.marg = marg\n",
    "                self.triplet_selector = triplet_selector\n",
    "            def forward(self, embeddings, target):\n",
    "                triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "                return triplets\n",
    "\n",
    "        class OnlineTestTriplet(nn.Module):\n",
    "            def __init__(self, marg, triplet_selector):\n",
    "                super(OnlineTestTriplet, self).__init__()\n",
    "                self.marg = marg\n",
    "                self.triplet_selector = triplet_selector\n",
    "            def forward(self, embeddings, target):\n",
    "                triplets = self.triplet_selector.get_triplets(embeddings, target)\n",
    "                return triplets    \n",
    "\n",
    "        class Classifier(nn.Module):\n",
    "            def __init__(self):\n",
    "                super(Classifier, self).__init__()\n",
    "                self.FC = torch.nn.Sequential(\n",
    "                    nn.Linear(Z_in, 1),\n",
    "                    nn.Dropout(rate4),\n",
    "                    nn.Sigmoid())\n",
    "            def forward(self, x):\n",
    "                return self.FC(x)\n",
    "\n",
    "        torch.cuda.manual_seed_all(42)\n",
    "\n",
    "        AutoencoderE = AEE()\n",
    "        AutoencoderM = AEM()\n",
    "        AutoencoderC = AEC()\n",
    "\n",
    "        solverE = optim.Adagrad(AutoencoderE.parameters(), lr=lrE)\n",
    "        solverM = optim.Adagrad(AutoencoderM.parameters(), lr=lrM)\n",
    "        solverC = optim.Adagrad(AutoencoderC.parameters(), lr=lrC)\n",
    "\n",
    "        trip_criterion = torch.nn.TripletMarginLoss(margin=marg, p=2)\n",
    "        TripSel = OnlineTriplet(marg, triplet_selector)\n",
    "        TripSel2 = OnlineTestTriplet(marg, triplet_selector2)\n",
    "\n",
    "        Clas = Classifier()\n",
    "        SolverClass = optim.Adagrad(Clas.parameters(), lr=lrCL, weight_decay = wd)\n",
    "        C_loss = torch.nn.BCELoss()\n",
    "\n",
    "        for it in range(epoch):\n",
    "\n",
    "            epoch_cost4 = 0\n",
    "            epoch_cost3 = []\n",
    "            num_minibatches = int(n_sampE / mb_size) \n",
    "\n",
    "            for i, (dataE, dataM, dataC, target) in enumerate(trainLoader):\n",
    "                flag = 0\n",
    "                AutoencoderE.train()\n",
    "                AutoencoderM.train()\n",
    "                AutoencoderC.train()\n",
    "                Clas.train()\n",
    "\n",
    "                if torch.mean(target)!=0. and torch.mean(target)!=1.: \n",
    "                    ZEX = AutoencoderE(dataE)\n",
    "                    ZMX = AutoencoderM(dataM)\n",
    "                    ZCX = AutoencoderC(dataC)\n",
    "\n",
    "                    ZT = torch.cat((ZEX, ZMX, ZCX), 1)\n",
    "                    ZT = F.normalize(ZT, p=2, dim=0)\n",
    "                    Pred = Clas(ZT)\n",
    "\n",
    "                    Triplets = TripSel2(ZT, target)\n",
    "                    loss = lam * trip_criterion(ZT[Triplets[:,0],:],ZT[Triplets[:,1],:],ZT[Triplets[:,2],:]) + C_loss(Pred,target.view(-1,1))     \n",
    "\n",
    "                    y_true = target.view(-1,1)\n",
    "                    y_pred = Pred\n",
    "                    AUC = roc_auc_score(y_true.detach().numpy(),y_pred.detach().numpy()) \n",
    "\n",
    "                    solverE.zero_grad()\n",
    "                    solverM.zero_grad()\n",
    "                    solverC.zero_grad()\n",
    "                    SolverClass.zero_grad()\n",
    "\n",
    "                    loss.backward()\n",
    "\n",
    "                    solverE.step()\n",
    "                    solverM.step()\n",
    "                    solverC.step()\n",
    "                    SolverClass.step()\n",
    "\n",
    "                    epoch_cost4 = epoch_cost4 + (loss / num_minibatches)\n",
    "                    epoch_cost3.append(AUC)\n",
    "                    flag = 1\n",
    "\n",
    "            if flag == 1:\n",
    "                costtr.append(torch.mean(epoch_cost4))\n",
    "                auctr.append(np.mean(epoch_cost3))\n",
    "                print('Iter-{}; Total loss: {:.4}'.format(it, loss))\n",
    "\n",
    "            with torch.no_grad():\n",
    "\n",
    "                AutoencoderE.eval()\n",
    "                AutoencoderM.eval()\n",
    "                AutoencoderC.eval()\n",
    "                Clas.eval()\n",
    "\n",
    "                ZET = AutoencoderE(TX_testE)\n",
    "                ZMT = AutoencoderM(TX_testM)\n",
    "                ZCT = AutoencoderC(TX_testC)\n",
    "\n",
    "                ZTT = torch.cat((ZET, ZMT, ZCT), 1)\n",
    "                ZTT = F.normalize(ZTT, p=2, dim=0)\n",
    "                PredT = Clas(ZTT)\n",
    "\n",
    "                TripletsT = TripSel2(ZTT, ty_testE)\n",
    "                lossT = lam * trip_criterion(ZTT[TripletsT[:,0],:], ZTT[TripletsT[:,1],:], ZTT[TripletsT[:,2],:]) + C_loss(PredT,ty_testE.view(-1,1))\n",
    "\n",
    "                y_truet = ty_testE.view(-1,1)\n",
    "                y_predt = PredT\n",
    "                AUCt = roc_auc_score(y_truet.detach().numpy(),y_predt.detach().numpy())        \n",
    "\n",
    "                costts.append(lossT)\n",
    "                aucts.append(AUCt)\n",
    "\n",
    "                \n",
    "        costtr_vals = []\n",
    "        for iiii in costtr:\n",
    "            costtr_vals.append(iiii.item())\n",
    "            \n",
    "        plt.plot(np.squeeze(costtr_vals), '-r',np.squeeze(costts), '-b')\n",
    "        plt.ylabel('Total cost')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "\n",
    "        title = 'Cost Cetuximab iter = {}, fold = {}, mb_size = {},  h_dim[1,2,3] = ({},{},{}), marg = {}, lr[E,M,C] = ({}, {}, {}), epoch = {}, rate[1,2,3,4] = ({},{},{},{}), wd = {}, lrCL = {}, lam = {}'.\\\n",
    "                      format(iters, k, mbs, hdm1, hdm2, hdm3, mrg, lre, lrm, lrc, epch, rate1, rate2, rate3, rate4, wd, lrCL, lam)\n",
    "\n",
    "        plt.suptitle(title)\n",
    "        plt.savefig(save_results_to + title + '.png', dpi = 150)\n",
    "        plt.close()\n",
    "\n",
    "        plt.plot(np.squeeze(auctr), '-r',np.squeeze(aucts), '-b')\n",
    "        plt.ylabel('AUC')\n",
    "        plt.xlabel('iterations (per tens)')\n",
    "\n",
    "        title = 'AUC Cetuximab iter = {}, fold = {}, mb_size = {},  h_dim[1,2,3] = ({},{},{}), marg = {}, lr[E,M,C] = ({}, {}, {}), epoch = {}, rate[1,2,3,4] = ({},{},{},{}), wd = {}, lrCL = {}, lam = {}'.\\\n",
    "                      format(iters, k, mbs, hdm1, hdm2, hdm3, mrg, lre, lrm, lrc, epch, rate1, rate2, rate3, rate4, wd, lrCL, lam)        \n",
    "\n",
    "        plt.suptitle(title)\n",
    "        plt.savefig(save_results_to + title + '.png', dpi = 150)\n",
    "        plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7650217a-3371-4686-b373-69439f1b358f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch GPU 1.13 (py39)",
   "language": "python",
   "name": "pytorch-gpu-1.13-py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
